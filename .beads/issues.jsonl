{"id":"remote_compilation_helper-0dl","title":"Implement idempotent first-run detection and configuration","description":"## Overview\n\nImplement idempotent state detection and configuration primitives that underpin ALL setup, install, and configuration commands. This is a **foundational bead** with no dependencies - it provides the building blocks that xi5 (Agent Detection), 3d1 (Setup Wizard), and other beads rely on.\n\nThe core principle: **any RCH command can be run repeatedly without side effects or data loss**.\n\n## Goals\n\n1. **State Detection Layer**: Unified detection of RCH configuration state\n2. **Idempotent Primitives**: Reusable functions for safe file operations\n3. **Exit Code Contract**: Consistent exit codes for automation\n4. **Source Tracking**: Track where each config value came from\n5. **Lock File Support**: Prevent concurrent configuration modifications\n\n## State Detection Model\n\n```rust\n// rch/src/state/mod.rs\n\nuse std::path::PathBuf;\nuse serde::{Deserialize, Serialize};\n\n/// Complete RCH installation state\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RchState {\n    /// Global state assessment\n    pub status: InstallStatus,\n\n    /// Individual component states\n    pub components: ComponentStates,\n\n    /// Detected issues with remediation hints\n    pub issues: Vec\u003cStateIssue\u003e,\n\n    /// Timestamp of state detection\n    pub detected_at: chrono::DateTime\u003cchrono::Utc\u003e,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum InstallStatus {\n    /// Fully configured and operational\n    Ready,\n    /// Partially configured, needs setup\n    NeedsSetup,\n    /// Not installed or critically broken\n    NotInstalled,\n    /// Running but with warnings\n    Degraded,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ComponentStates {\n    pub user_config: ConfigState,\n    pub project_config: ConfigState,\n    pub workers: WorkersState,\n    pub daemon: DaemonState,\n    pub hooks: Vec\u003cAgentHookState\u003e,\n    pub binaries: BinaryState,\n}\n```\n\n## Idempotent Primitives\n\n```rust\n// rch/src/state/primitives.rs\n\n/// Result of an idempotent operation\n#[derive(Debug, Clone)]\npub enum IdempotentResult {\n    Created,\n    AlreadyExists,\n    Updated,\n    DryRun,\n}\n\n/// Create a file only if it doesn't exist\npub fn create_if_missing(path: \u0026Path, content: \u0026str) -\u003e Result\u003cIdempotentResult\u003e;\n\n/// Update a file only if content differs (with backup)\npub fn update_if_changed(path: \u0026Path, new_content: \u0026str, backup: bool) -\u003e Result\u003cIdempotentResult\u003e;\n\n/// Ensure a symlink points to the correct target\npub fn ensure_symlink(link: \u0026Path, target: \u0026Path) -\u003e Result\u003cIdempotentResult\u003e;\n\n/// Append to file only if line doesn't exist (for PATH updates)\npub fn append_line_if_missing(path: \u0026Path, line: \u0026str) -\u003e Result\u003cIdempotentResult\u003e;\n```\n\n## Lock File Support\n\n```rust\n// rch/src/state/lock.rs\npub struct ConfigLock { /* file handle + path */ }\n\nimpl ConfigLock {\n    pub fn acquire(lock_path: \u0026Path) -\u003e Result\u003cSelf\u003e;\n}\n\nimpl Drop for ConfigLock {\n    fn drop(\u0026mut self) { /* release lock, remove file */ }\n}\n```\n\n## Exit Code Contract\n\n```rust\npub mod exit_codes {\n    pub const OK: i32 = 0;\n    pub const ERROR: i32 = 1;\n    pub const USAGE: i32 = 64;\n    pub const CONFIG: i32 = 78;\n    pub const NEEDS_SETUP: i32 = 100;\n    pub const DAEMON_DOWN: i32 = 101;\n    pub const NO_WORKERS: i32 = 102;\n    pub const ALREADY_CURRENT: i32 = 103;\n    pub const LOCKED: i32 = 104;\n}\n```\n\n## CLI Integration\n\n```\nrch state                      # Show current state (human-readable)\nrch state --json               # JSON output for scripting\nrch state --check              # Exit code only (0=ready, 100=needs setup)\nrch config init --if-missing   # Create only if missing (idempotent)\nrch setup --check              # Validate setup, report issues\n```\n\n## Implementation Files\n\n```\nrch/src/\n├── state/\n│   ├── mod.rs              # State types and RchState\n│   ├── detect.rs           # State detection logic\n│   ├── primitives.rs       # Idempotent file operations\n│   ├── lock.rs             # Lock file management\n│   └── exit_codes.rs       # Exit code constants\n├── commands/\n│   └── state.rs            # `rch state` command\n```\n\n## Testing Requirements\n\n### Unit Tests (rch/src/state/tests/)\n\n**primitives_test.rs**: Test create_if_missing, update_if_changed, ensure_symlink, append_line_if_missing with tempfile\n**detect_test.rs**: Test state detection with mock environments\n**lock_test.rs**: Test lock acquisition, release, and concurrent access prevention\n\n### Integration Tests (rch/tests/state_integration.rs)\n\n- test_rch_state_shows_not_installed\n- test_rch_state_check_exit_code\n- test_rch_state_json_output\n- test_config_init_if_missing_idempotent\n\n### E2E Test Script (scripts/e2e_state_test.sh)\n\n1. Fresh install detection (expects NotInstalled)\n2. Exit code contract (expects 100 for unconfigured)\n3. Idempotent config init (first creates, second skips)\n4. Lock file prevents concurrent operations\n5. JSON output is parseable\n\n## Logging Requirements\n\n- DEBUG: Log each state component detection step\n- INFO: Log final state summary\n- WARN: Log detected issues\n- ERROR: Log failures with remediation hints\n\n## Success Criteria\n\n- [ ] State detection covers all components\n- [ ] All file operations are atomic and idempotent\n- [ ] Lock file prevents concurrent modifications\n- [ ] Exit codes follow documented contract\n- [ ] JSON output matches schema\n- [ ] Unit test coverage \u003e 80%\n- [ ] All E2E tests pass\n\n## Dependencies\n\nNone - this is a foundational bead.\n\n## Blocks\n\n- remote_compilation_helper-xi5 (Agent Detection)\n- remote_compilation_helper-3d1 (First-Run Setup Wizard)\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:55:58.909900279-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:24:45.729683258-05:00"}
{"id":"remote_compilation_helper-0lo","title":"Implement toolchain verification and installation on worker","description":"## Parent Epic: Automatic Toolchain Synchronization (remote_compilation_helper-ayn)\n\n## Overview\n\nImplement toolchain verification and automatic installation on the worker agent. Before executing a compilation command, the worker ensures the required toolchain is available, installing it via rustup if necessary.\n\n## Flow\n\n1. Worker receives ExecutionRequest with toolchain\n2. Check if toolchain is already available\n3. If not available, install via rustup\n4. Execute command with rustup run \u003ctoolchain\u003e \u003ccommand\u003e\n5. Cache toolchain availability for future requests\n\n## Implementation\n\n- `rch-wkr/src/toolchain.rs` with a thread‑safe cache\n- `ensure_toolchain` uses rustup minimal profile\n- Executor wraps commands with `rustup run` when toolchain specified\n\n## Tests\n\n- Unit: cache operations\n- Unit: toolchain parsing + strip target triple\n- Integration: mock rustup output and install failures\n- E2E: add to `scripts/e2e_test.sh` scenario that simulates missing toolchain and logs install flow; ensure fall‑open behavior on install failure\n\n## Logging\n\n- Log toolchain resolution, install attempts, and fall‑open decisions with worker id\n\n## Acceptance Criteria\n\n- Toolchain availability cached correctly\n- Missing toolchains installed automatically\n- Failures fall back to local execution\n- E2E logs show toolchain decision path\n\n## Dependencies\n\n- Protocol changes to include toolchain (remote_compilation_helper-o9s)\n\n## Blocks\n\n- Toolchain sync tests (remote_compilation_helper-mio)\n\n","status":"in_progress","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:13:33.233869712-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:22:09.43900314-05:00","dependencies":[{"issue_id":"remote_compilation_helper-0lo","depends_on_id":"remote_compilation_helper-o9s","type":"blocks","created_at":"2026-01-16T12:14:49.436995369-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-17q","title":"Fix broken 'rch config set' command","description":"commands.rs:726-730 prints 'not fully implemented' instead of actually setting config values. Either implement the feature properly or remove the command from the CLI until ready.","status":"closed","priority":2,"issue_type":"bug","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:37:06.154251039-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T11:53:10.653219201-05:00","closed_at":"2026-01-16T11:53:10.653223119-05:00"}
{"id":"remote_compilation_helper-1f5","title":"Add shell completion generation (bash/zsh/fish)","description":"## Overview\n\nAdd shell completion generation for bash/zsh/fish using clap’s built‑in completion output. Provide install instructions and optional `rch completions` command.\n\n## Goals\n\n1. Generate completions for bash, zsh, fish\n2. Provide `rch completions \u003cshell\u003e` command\n3. Include docs + install hints\n\n## Tests\n\n- Unit: completion generation does not error\n- Integration: generate each shell completion and verify non‑empty\n- E2E: `rch completions bash` writes output and exits 0\n\n## Acceptance Criteria\n\n- Completions generate for all shells\n- Output is deterministic and not empty\n\n## Logging\n\n- E2E logs should include completion output size and first lines for each shell.\n","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:37:04.972457231-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.13417185-05:00"}
{"id":"remote_compilation_helper-20k","title":"Add terminal hyperlinks (OSC 8) for clickable URLs","description":"## Overview\n\nAdd terminal hyperlinks using OSC 8 for clickable URLs in supported terminals. Provide safe fallbacks for non‑TTY and opt‑out control.\n\n## Goals\n\n1. OSC‑8 links when supported\n2. Fallback to plain text URLs\n3. Config/env toggle (RCH_LINKS=0)\n4. Avoid OSC‑8 in JSON/plain modes\n\n## Implementation\n\n- Detect TTY + TERM support\n- Wrap URLs as `\\x1b]8;;URL\\x1b\\\\TEXT\\x1b]8;;\\x1b\\\\`\n- Provide `link(text, url)` helper in UI module\n\n## Tests\n\n- Unit: OSC‑8 formatting\n- Unit: fallback in non‑TTY\n- Integration: ensure no OSC‑8 when `--json` or `RCH_LINKS=0`\n- E2E: `scripts/e2e_test.sh` runs a command that emits help links and logs whether OSC‑8 was emitted in TTY vs non‑TTY modes\n\n## Logging\n\n- E2E logs should explicitly show link rendering decisions\n\n## Acceptance Criteria\n\n- Links clickable in supported terminals\n- No OSC‑8 in logs or JSON output\n\n## Dependencies\n\n- Output abstraction layer (remote_compilation_helper-u0v)\n\n","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:24:50.333718999-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:22:59.237186081-05:00","labels":["ux"],"dependencies":[{"issue_id":"remote_compilation_helper-20k","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T12:27:11.328989527-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-2ug","title":"Integrate hook with remote transfer pipeline","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T08:58:30.199568598-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:03:44.627509668-05:00","closed_at":"2026-01-16T09:03:44.627509668-05:00","close_reason":"Integrated hook with remote transfer pipeline"}
{"id":"remote_compilation_helper-3d1","title":"Epic: First-Run Setup Wizard with Validation","description":"## Overview\n\nImplement an interactive setup experience that guides new users through RCH configuration: discovering/adding workers, testing SSH connectivity, validating the setup, and installing hooks for detected agents. The wizard ensures users have a working setup before they try to use RCH.\n\n## Goals\n\n1. Single command to go from \"installed\" to \"working\"\n2. Interactive prompts guide user through configuration\n3. Validate everything before declaring success\n4. Auto‑detect worker capabilities where possible\n5. Install hooks for supported agents (Claude/Gemini) automatically\n6. Test end‑to‑end with a real (or simulated) build\n\n## CLI Interface\n\n```\nrch setup                     # Full interactive wizard\nrch setup --quick             # Minimal prompts\nrch setup --worker \u003chost\u003e     # Add single worker non‑interactively\nrch setup --validate          # Validate existing config only\nrch setup --install-deps      # Auto‑install local deps (with confirmation)\n```\n\n## Wizard Flow (Updated)\n\n1. Local prerequisites\n2. Worker configuration\n3. Config files\n4. Daemon setup\n5. Agent hooks\n6. Verification build\n\n## Tests\n\n- Unit: prerequisite detection\n- Integration: wizard with mock inputs\n- E2E: setup flow in mock mode with detailed logging of each step\n\n## Logging\n\n- Each step should log start/end + elapsed time\n- E2E logs capture the full wizard transcript\n\n## Acceptance Criteria\n\n- Wizard completes on a fully configured system\n- Missing deps are detected and guidance shown\n- Hooks installed for Claude and Gemini when present\n- End‑to‑end verification build succeeds in mock mode\n\n## Dependencies\n\n- Agent detection epic (remote_compilation_helper-xi5)\n- Toolchain sync epic (remote_compilation_helper-ayn)\n- Status API + status command (remote_compilation_helper-3sy, remote_compilation_helper-7ds)\n- Idempotent setup (remote_compilation_helper-0dl)\n\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:07:37.661350839-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:09:53.470694017-05:00","dependencies":[{"issue_id":"remote_compilation_helper-3d1","depends_on_id":"remote_compilation_helper-xi5","type":"blocks","created_at":"2026-01-16T15:22:38.170291678-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-3d1","depends_on_id":"remote_compilation_helper-0dl","type":"blocks","created_at":"2026-01-16T15:22:38.954365297-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-3n1","title":"Implement artifact return from workers","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:20:09.410470904-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:30:55.108000517-05:00","closed_at":"2026-01-16T03:30:55.108000517-05:00","close_reason":"Artifact return already implemented in rch/src/transfer.rs::retrieve_artifacts() - uses rsync with zstd compression to pull back target/debug/**, target/release/**, etc. Tested via parse_rsync_bytes test."}
{"id":"remote_compilation_helper-3nq","title":"Enhance help text with examples and env var documentation","description":"## Overview\n\nExpand CLI help text to be comprehensive, example‑rich, and self‑teaching. Include environment variables, hook behavior, and new commands (agents, setup, doctor, update, install).\n\n## Goals\n\n1. Main help includes examples + env var docs\n2. Subcommand help includes focused examples\n3. Hook mode documented clearly\n4. Help fits 80‑column width\n\n## Updates Needed\n\n- Add examples for:\n  - `rch setup`\n  - `rch agents`\n  - `rch update`\n  - `rch install --fleet`\n  - `rch doctor`\n- Document env vars from `remote_compilation_helper-srd`\n- Explain hook mode: stdin JSON input, silent allow\n\n## Tests\n\n- Unit: help output contains EXAMPLES section\n- Unit: env vars are documented\n- Integration: subcommand help contains examples\n- E2E: help output length and sections in `scripts/e2e_test.sh`\n\n## Acceptance Criteria\n\n- Users can learn all core features from `--help`\n- Help covers env vars + hook mode\n\n## Dependencies\n\n- Env var overrides (remote_compilation_helper-srd)\n- JSON output (remote_compilation_helper-b9p)\n\n## Logging\n\n- E2E logs should report which help sections were detected and any width/format checks.\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:37:07.353322307-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.174856845-05:00"}
{"id":"remote_compilation_helper-3sy","title":"Add /status API endpoint to daemon","description":"## Overview\n\nAdd `/status` endpoint to the daemon API to expose daemon health, worker state (including circuit state), and recent build history. This is the authoritative data source for `rch status`, the TUI, and the web dashboard.\n\n## Goals\n\n1. Provide a structured JSON status response\n2. Include worker slots, health, circuit, speed, and last check\n3. Include recent build history (last N builds)\n4. Include daemon metadata (pid, uptime, version, socket path)\n5. Provide clear error responses when daemon is unavailable\n\n## Response Schema\n\n```rust\nstruct StatusResponse {\n  daemon: DaemonStatus,\n  workers: Vec\u003cWorkerStatusInfo\u003e,\n  recent_builds: Vec\u003cBuildRecord\u003e,\n  issues: Vec\u003cIssue\u003e,\n}\n```\n\n### DaemonStatus\n- pid\n- uptime_secs\n- version\n- socket_path\n- started_at\n\n### WorkerStatusInfo\n- id, host, user\n- status (healthy/degraded/unreachable/disabled)\n- circuit_state + last_state_change\n- used_slots / total_slots\n- speed_score\n- last_health_check_ms + last_error\n\n### BuildRecord (from build history)\n- timestamp\n- project_id\n- worker_id\n- command\n- exit_code\n- duration_ms\n\n### Issue\n- severity\n- summary\n- remediation\n\n## Implementation\n\n1. Add `/status` handling in `rchd/src/api.rs`\n2. Add builder function to assemble response from worker pool + history\n3. Serialize as JSON response\n\n## Tests\n\n- Unit: build StatusResponse from mock workers + history\n- Integration: open Unix socket, call `/status`, parse JSON\n- E2E: `rch status` consumes `/status` with mock data\n\n## Logging\n\n- Log `/status` request latency at DEBUG\n- Log serialization errors at WARN\n\n## Acceptance Criteria\n\n- `/status` returns valid JSON with required fields\n- Worker states and circuit states are accurate\n- Recent build list is present and ordered\n- Errors are actionable when daemon unavailable\n\n## Dependencies\n\n- Build history tracking (remote_compilation_helper-qgs)\n- Circuit breaker state (remote_compilation_helper-62v / 52l)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:16:42.809039806-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:04:38.34774158-05:00"}
{"id":"remote_compilation_helper-4ck","title":"Create Cargo workspace scaffold","description":"Set up Cargo.toml workspace with 4 crates: rch, rchd, rch-wkr, rch-common. Include rust-toolchain.toml for nightly 2024. Configure release profile per AGENTS.md.","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:09:00.450176064-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:19:14.337156716-05:00","closed_at":"2026-01-16T03:19:14.337156716-05:00","close_reason":"Created complete Cargo workspace with rch, rchd, rch-wkr, rch-common crates. All tests pass."}
{"id":"remote_compilation_helper-4te","title":"Add markdown rendering for rich help text","description":"## Overview\n\nAdd markdown rendering for rich help text and docs output (e.g., `rch help \u003ctopic\u003e`). Use a safe, minimal renderer for terminal output.\n\n## Goals\n\n1. Render headings, bold/italic, lists, code blocks\n2. No ANSI in non‑TTY\n3. Optional `--plain` to disable styling\n\n## Implementation\n\n- Use `pulldown-cmark` or similar\n- Map markdown elements to terminal styles (bold, underline)\n- Wrap code blocks in fenced monospace without color by default\n\n## Tests\n\n- Unit: render sample markdown to expected text\n- Integration: `rch help topic` renders properly in TTY and non‑TTY\n- E2E: ensure help output does not contain raw markdown\n\n## Acceptance Criteria\n\n- Help text readable and styled\n- Non‑TTY output is clean plain text\n\n## Dependencies\n\n- Output abstraction layer (remote_compilation_helper-u0v)\n\n## Logging\n\n- E2E logs should include raw vs rendered output snippets and confirm no raw markdown leaks.\n","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:24:52.83567223-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.213876565-05:00","labels":["ux"],"dependencies":[{"issue_id":"remote_compilation_helper-4te","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T12:27:14.572889909-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-4te","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T12:27:14.62578096-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-4ur","title":"Add reason field to SelectionResponse for no-worker cases","description":"## Parent Epic: Graceful Local Fallback (remote_compilation_helper-ne8)\n\n## Task Description\n\nExtend the SelectionResponse protocol to include a reason field that explains why no worker was assigned. This enables the hook to provide informative messaging when falling back to local execution.\n\n## Current State\n\n```rust\n// In rch-common/src/protocol.rs (or similar)\npub struct SelectionResponse {\n    pub worker: Option\u003cWorkerConfig\u003e,\n    pub slots_reserved: u32,\n    // ...\n}\n```\n\nWhen no worker is available, `worker` is `None` but there's no indication of WHY.\n\n## Changes Required\n\n### 1. Update SelectionResponse\n```rust\npub struct SelectionResponse {\n    pub worker: Option\u003cWorkerConfig\u003e,\n    pub slots_reserved: u32,\n    pub reason: Option\u003cSelectionReason\u003e,  // NEW\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum SelectionReason {\n    /// Worker assigned successfully\n    Success,\n    /// No workers configured in workers.toml\n    NoWorkersConfigured,\n    /// All workers are unreachable\n    AllWorkersUnreachable,\n    /// All workers have circuits open (after circuit breaker epic)\n    AllCircuitsOpen,\n    /// All workers are at capacity (no available slots)\n    AllWorkersBusy,\n    /// No workers match required tags/preferences\n    NoMatchingWorkers,\n    /// Internal error during selection\n    SelectionError(String),\n}\n```\n\n### 2. Update selection.rs\n```rust\npub async fn select_worker(...) -\u003e SelectionResponse {\n    if workers.is_empty() {\n        return SelectionResponse {\n            worker: None,\n            slots_reserved: 0,\n            reason: Some(SelectionReason::NoWorkersConfigured),\n        };\n    }\n    \n    let healthy = workers.iter().filter(|w| w.is_healthy()).collect::\u003cVec\u003c_\u003e\u003e();\n    if healthy.is_empty() {\n        return SelectionResponse {\n            worker: None,\n            slots_reserved: 0,\n            reason: Some(SelectionReason::AllWorkersUnreachable),\n        };\n    }\n    \n    // ... selection logic ...\n    \n    if selected.is_none() {\n        return SelectionResponse {\n            worker: None,\n            slots_reserved: 0,\n            reason: Some(SelectionReason::AllWorkersBusy),\n        };\n    }\n    \n    SelectionResponse {\n        worker: selected,\n        slots_reserved: cores,\n        reason: Some(SelectionReason::Success),\n    }\n}\n```\n\n### 3. Update API serialization\nEnsure the new field is properly serialized in the HTTP response from daemon.\n\n## Files to Modify\n- `rch-common/src/protocol.rs` or `rch-common/src/types.rs`\n- `rchd/src/selection.rs`\n- `rchd/src/api.rs`\n\n## Testing\n\nAdd tests for each SelectionReason case:\n```rust\n#[test]\nfn test_selection_response_no_workers() {\n    // Empty pool returns NoWorkersConfigured\n}\n\n#[test]\nfn test_selection_response_all_unreachable() {\n    // All workers Unreachable returns AllWorkersUnreachable\n}\n\n#[test]\nfn test_selection_response_all_busy() {\n    // All slots used returns AllWorkersBusy\n}\n```\n\n## Acceptance Criteria\n- [ ] SelectionReason enum defined with all cases\n- [ ] SelectionResponse includes reason field\n- [ ] selection.rs populates reason correctly for each case\n- [ ] API serializes reason in JSON response\n- [ ] Unit tests cover all reason variants\n- [ ] Existing tests updated/pass\n\n## Estimated Effort: 2-3 hours","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:07:57.468294764-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T12:50:20.390359561-05:00","closed_at":"2026-01-16T12:50:20.390359561-05:00","close_reason":"Implementation complete: Added SelectionReason enum, SelectedWorker struct, updated API to return structured reasons, updated hook for graceful fallback, and added comprehensive unit tests. All 115 tests pass."}
{"id":"remote_compilation_helper-52l","title":"Integrate circuit state into WorkerHealth and health check loop","description":"## Overview\n\nIntegrate circuit state into WorkerHealth and the health check loop. This ensures worker availability reflects recent failure patterns and applies open/half‑open logic consistently.\n\n## Goals\n\n1. Extend `WorkerHealth` to carry `CircuitState` + `CircuitStats`\n2. Drive circuit transitions based on health check outcomes\n3. Expose circuit state in worker status + status API\n4. Ensure transitions are logged + observable\n\n## Implementation Plan\n\n1. Add `circuit: CircuitStats` to `WorkerHealth`\n2. Update health check loop:\n   - On successful health check: `record_success`\n   - On failed health check: `record_failure`\n3. When circuit is `Open`, mark worker as `Unreachable`/`Degraded` for selection\n4. When circuit is `HalfOpen`, allow limited probes (from config)\n\n## Edge Cases\n\n- Worker status “Healthy” but circuit open: selection should exclude it\n- Health checks continue even if circuit open (to allow recovery)\n\n## Tests\n\n- Unit: `WorkerHealth` updates with successive failures/successes\n- Unit: circuit state transitions integrated with health logic\n- Integration: simulate failing worker for N cycles -\u003e circuit opens\n- E2E: mock health checks with deterministic timing, verify state in `/status`\n\n## Logging\n\n- Log state transitions with worker id, prior state, reason\n- Log half‑open probe usage at DEBUG\n\n## Acceptance Criteria\n\n- Circuit state updates on health checks\n- `/status` exposes circuit state + timestamps\n- Selection excludes open circuits\n- Tests cover transition paths\n\n## Dependencies\n\n- Circuit state enum/config (remote_compilation_helper-62v)\n\n## Blocks\n\n- Circuit breaker integration tests (remote_compilation_helper-7nj)\n- Selection integration (remote_compilation_helper-ova)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:10:32.305110642-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:03:38.685429882-05:00","dependencies":[{"issue_id":"remote_compilation_helper-52l","depends_on_id":"remote_compilation_helper-62v","type":"blocks","created_at":"2026-01-16T12:12:01.869594158-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-5cv","title":"Implement rch hook CLI","description":"Create rch binary with main.rs, hook.rs, classify.rs. Parse Claude Code PreToolUse JSON and classify commands.","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:09:02.849264782-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:19:17.532584191-05:00","closed_at":"2026-01-16T03:19:17.532584191-05:00","close_reason":"Implemented rch hook CLI with main.rs, hook.rs, config.rs. Command classification working."}
{"id":"remote_compilation_helper-5te","title":"Add progress indicators for long operations (spinners, progress bars)","description":"## Overview\nAdd visual feedback for long-running operations using spinners, progress bars, and step indicators. Users should never wonder \"is it still working?\"\n\n## Dependencies\n- **BLOCKED BY**: remote_compilation_helper-u0v (UI output abstraction layer)\n- **BLOCKED BY**: remote_compilation_helper-nbo (colors) - progress elements use colors\n\n**Can be worked in PARALLEL with cmj (status indicators) and alo (errors) after nbo completes.**\n\n## Requirements\n\n### Crate Selection: indicatif v0.17+ (2026 Best Practices)\n\nUse `indicatif` crate - the Rust standard for progress indication:\n- Spinners with customizable styles\n- Progress bars with ETA, speed, percentage\n- Multi-progress for parallel operations\n- Built-in non-TTY handling\n- **NEW (2025-2026)**: Full async support with `tokio` and `futures` features\n\n**Cargo.toml addition:**\n\\`\\`\\`toml\n[dependencies]\nindicatif = { version = \"0.17\", features = [\"tokio\", \"futures\"] }\n\\`\\`\\`\n\nThe `tokio` feature enables:\n- Async-aware progress updates\n- Non-blocking tick animations\n- Spawn progress in async contexts without blocking\n\n### Optional: throbber-widgets-tui for ratatui Integration (Future)\n\nFor the future TUI dashboard (remote_compilation_helper-lgy), consider:\n- `throbber-widgets-tui` crate for ratatui-native spinners\n- Seamless integration with ratatui layouts\n- Same spinner styles as indicatif for consistency\n\n### Progress Types\n\n#### 1. Spinner - Unknown Duration Operations\n\\`\\`\\`\n⠋ Connecting to gpu-worker...\n⠙ Probing mock-worker...\n⠹ Starting daemon...\n\\`\\`\\`\n- Style: Braille dots `⠋⠙⠹⠸⠼⠴⠦⠧⠇⠏` (indicatif `Dots` style)\n- Message updates as operation progresses\n- Completes with ✓ or ✗ and final message\n- Use for: SSH connection, daemon startup, single worker probe\n\n**Implementation with tokio feature:**\n\\`\\`\\`rust\nuse indicatif::{ProgressBar, ProgressStyle};\nuse std::time::Duration;\n\npub async fn with_spinner\u003cF, T\u003e(ctx: \u0026OutputContext, message: \u0026str, future: F) -\u003e T \nwhere\n    F: std::future::Future\u003cOutput = T\u003e,\n{\n    if !ctx.colors_enabled || ctx.is_json() || ctx.is_quiet() {\n        return future.await;\n    }\n    \n    let pb = ProgressBar::new_spinner();\n    pb.set_style(ProgressStyle::default_spinner()\n        .tick_strings(\u0026[\"⠋\", \"⠙\", \"⠹\", \"⠸\", \"⠼\", \"⠴\", \"⠦\", \"⠧\", \"⠇\", \"⠏\"])\n        .template(\"{spinner:.cyan} {msg}\")\n        .unwrap());\n    pb.set_message(message.to_string());\n    pb.enable_steady_tick(Duration::from_millis(80));\n    \n    let result = future.await;\n    pb.finish_and_clear();\n    result\n}\n\\`\\`\\`\n\n#### 2. Progress Bar - Known Size Operations\n\\`\\`\\`\nSyncing files   [████████████░░░░░░░░░░░░░] 48% 2.3 MB/s ETA 0:12\n\\`\\`\\`\n- Shows: percentage, transfer speed, ETA\n- Width adapts to terminal\n- Use for: file sync (rsync), artifact retrieval\n\n**Modern template with human-readable bytes:**\n\\`\\`\\`rust\nlet pb = ProgressBar::new(total_bytes);\npb.set_style(ProgressStyle::default_bar()\n    .template(\"{msg} [{bar:40.cyan/blue}] {bytes}/{total_bytes} {bytes_per_sec} ETA {eta}\")\n    .unwrap()\n    .progress_chars(\"█▓░\"));\n\\`\\`\\`\n\n#### 3. Step Indicator - Multi-Phase Operations\n\\`\\`\\`\n[1/3] ✓ Synced files (2.3 MB in 3.2s)\n[2/3] ◐ Compiling on gpu-worker...\n[3/3] ○ Retrieve artifacts\n\\`\\`\\`\n- Show completed, current, pending steps\n- Current step may have nested progress\n- Use for: hook compilation pipeline\n\n#### 4. Multi-Progress - Parallel Operations\n\\`\\`\\`\ngpu-worker   ✓ OK (45ms)\ncpu-worker   ⠹ Connecting...\nbackup       ✗ Connection refused\n\\`\\`\\`\n- Multiple lines, each with own status\n- Updates in place\n- Use for: `workers probe --all`, `workers benchmark`\n\n**Async MultiProgress pattern:**\n\\`\\`\\`rust\nuse indicatif::{MultiProgress, ProgressBar};\nuse futures::stream::{self, StreamExt};\n\npub async fn probe_all_workers(workers: \u0026[WorkerConfig], ctx: \u0026OutputContext) -\u003e Vec\u003cProbeResult\u003e {\n    let m = MultiProgress::new();\n    \n    let handles: Vec\u003c_\u003e = workers.iter().map(|worker| {\n        let pb = m.add(ProgressBar::new_spinner());\n        pb.set_prefix(format!(\"{:12}\", worker.id));\n        pb.enable_steady_tick(Duration::from_millis(80));\n        \n        async move {\n            let result = probe_worker(worker).await;\n            match \u0026result {\n                Ok(_) =\u003e pb.finish_with_message(\"✓ OK\"),\n                Err(e) =\u003e pb.finish_with_message(format!(\"✗ {}\", e)),\n            }\n            result\n        }\n    }).collect();\n    \n    futures::future::join_all(handles).await\n}\n\\`\\`\\`\n\n### Critical: Progress + Streaming Output Coexistence\n\nDuring `execute_remote`, compilation output streams to the terminal. This conflicts with progress indicators.\n\n**Solution: Suspend/Resume Pattern**\n\\`\\`\\`rust\nlet m = MultiProgress::new();\nlet pb = m.add(ProgressBar::new_spinner());\npb.set_message(\"Compiling...\");\n\n// Suspend progress drawing before streaming\nm.set_draw_target(ProgressDrawTarget::hidden());\n\n// Stream compilation output\nexecute_streaming(command, |line| println!(\"{}\", line)).await?;\n\n// Resume progress drawing\nm.set_draw_target(ProgressDrawTarget::stderr());\npb.finish_with_message(\"✓ Compiled\");\n\\`\\`\\`\n\n### rsync Progress Integration\n\nrsync with `--info=progress2` outputs:\n\\`\\`\\`\n    123,456,789 100%   10.50MB/s    0:00:11 (xfr#42, to-chk=0/100)\n\\`\\`\\`\n\n**Parsing approach with async streams:**\n\\`\\`\\`rust\nuse tokio::io::{AsyncBufReadExt, BufReader};\nuse tokio::process::Command;\nuse regex::Regex;\n\npub async fn rsync_with_progress(\n    args: \u0026[\u0026str], \n    pb: \u0026ProgressBar\n) -\u003e Result\u003cSyncResult\u003e {\n    let mut cmd = Command::new(\"rsync\");\n    cmd.args(args)\n        .arg(\"--info=progress2\")\n        .stdout(Stdio::piped())\n        .stderr(Stdio::piped());\n    \n    let mut child = cmd.spawn()?;\n    let stdout = child.stdout.take().unwrap();\n    let mut reader = BufReader::new(stdout).lines();\n    \n    let progress_re = Regex::new(r\"(\\d+)\\s+(\\d+)%\").unwrap();\n    \n    while let Some(line) = reader.next_line().await? {\n        if let Some(caps) = progress_re.captures(\u0026line) {\n            let bytes: u64 = caps[1].replace(\",\", \"\").parse().unwrap_or(0);\n            pb.set_position(bytes);\n        }\n    }\n    \n    let status = child.wait().await?;\n    Ok(SyncResult { success: status.success(), .. })\n}\n\\`\\`\\`\n\n### Operations to Enhance\n\n| Operation | Current | Enhancement | Progress Type |\n|-----------|---------|-------------|---------------|\n| `workers probe` (single) | Silent | Spinner | Spinner |\n| `workers probe --all` | \"Probing N workers...\" | Multi-line status | MultiProgress |\n| `workers benchmark` | \"Running benchmarks...\" | Per-worker progress | MultiProgress |\n| `daemon start` | Silent 2s wait | Spinner | Spinner |\n| `sync_to_remote` | Silent | Progress bar | ProgressBar |\n| `execute_remote` | Silent stream | Step + region | StepIndicator |\n| `retrieve_artifacts` | Silent | Progress bar | ProgressBar |\n\n### Mode-Specific Behavior\n\n| Mode | Behavior |\n|------|----------|\n| Human (TTY) | Full animated progress |\n| Plain (no color) | Static text updates: \"Syncing... 50%\" |\n| JSON | No progress display; optional progress events |\n| Quiet | No progress display |\n| Non-TTY (piped) | Line-based updates only |\n\n**Detection code:**\n\\`\\`\\`rust\nfn should_show_progress(ctx: \u0026OutputContext) -\u003e bool {\n    ctx.colors_enabled \n        \u0026\u0026 !ctx.is_json() \n        \u0026\u0026 !ctx.is_quiet() \n        \u0026\u0026 std::io::stderr().is_terminal()\n}\n\\`\\`\\`\n\n### JSON Progress Events (Optional Enhancement)\nFor scripting that needs progress info:\n\\`\\`\\`bash\nrch --json sync 2\u003e\u00261 | while read line; do\n  echo \"$line\" | jq -r '.progress.percent // empty'\ndone\n\\`\\`\\`\n\\`\\`\\`json\n{\"event\": \"progress\", \"phase\": \"sync\", \"percent\": 50, \"bytes\": 1234567}\n{\"event\": \"complete\", \"phase\": \"sync\", \"duration_ms\": 3200}\n\\`\\`\\`\n\n### Cancellation Handling (Ctrl+C)\n\nUse tokio's signal handling:\n\\`\\`\\`rust\nuse tokio::signal;\nuse tokio::select;\n\npub async fn with_cancellation\u003cF, T\u003e(pb: \u0026ProgressBar, future: F) -\u003e Result\u003cT\u003e\nwhere\n    F: std::future::Future\u003cOutput = Result\u003cT\u003e\u003e,\n{\n    select! {\n        result = future =\u003e result,\n        _ = signal::ctrl_c() =\u003e {\n            pb.abandon_with_message(\"Cancelled\");\n            anyhow::bail!(\"Operation cancelled by user\")\n        }\n    }\n}\n\\`\\`\\`\n\n### Performance Considerations\n- Update progress at most 10x/second (100ms debounce)\n- Don't update on every byte - batch updates\n- Spinner tick rate: 80ms (12.5 fps) - smooth without CPU waste\n- Use `enable_steady_tick()` for automatic animation\n\n### Files to Modify\n- `rch/src/ui/progress.rs` - new module wrapping indicatif\n- `rch/src/commands.rs` - add progress to probe, benchmark, daemon commands\n- `rch/src/transfer.rs` - add ProgressCallback parameter to sync functions\n- `rch/src/hook.rs` - add pipeline step indicators\n- `Cargo.toml` (rch) - add indicatif dependency with tokio feature\n\n### Progress Module API\n\\`\\`\\`rust\n// rch/src/ui/progress.rs\n\nuse indicatif::{MultiProgress, ProgressBar, ProgressStyle, ProgressDrawTarget};\nuse std::time::Duration;\n\n/// Spinner for unknown-duration operations\npub struct Spinner {\n    inner: ProgressBar,\n    ctx: OutputContext,\n}\n\nimpl Spinner {\n    pub fn new(ctx: \u0026OutputContext, message: \u0026str) -\u003e Self {\n        if !should_show_progress(ctx) {\n            return Self { inner: ProgressBar::hidden(), ctx: ctx.clone() };\n        }\n        \n        let pb = ProgressBar::new_spinner();\n        pb.set_style(ProgressStyle::default_spinner()\n            .tick_strings(\u0026[\"⠋\", \"⠙\", \"⠹\", \"⠸\", \"⠼\", \"⠴\", \"⠦\", \"⠧\", \"⠇\", \"⠏\"])\n            .template(\"{spinner:.cyan} {msg}\")\n            .unwrap());\n        pb.set_message(message.to_string());\n        pb.enable_steady_tick(Duration::from_millis(80));\n        \n        Self { inner: pb, ctx: ctx.clone() }\n    }\n    \n    pub fn set_message(\u0026self, msg: \u0026str) {\n        self.inner.set_message(msg.to_string());\n    }\n    \n    pub fn finish_success(\u0026self, msg: \u0026str) {\n        self.inner.finish_with_message(format!(\"✓ {}\", msg));\n    }\n    \n    pub fn finish_error(\u0026self, msg: \u0026str) {\n        self.inner.finish_with_message(format!(\"✗ {}\", msg));\n    }\n    \n    pub fn finish_warning(\u0026self, msg: \u0026str) {\n        self.inner.finish_with_message(format!(\"⚠ {}\", msg));\n    }\n}\n\n/// Progress bar for known-size operations\npub struct TransferProgress {\n    inner: ProgressBar,\n}\n\nimpl TransferProgress {\n    pub fn new(ctx: \u0026OutputContext, total: u64, label: \u0026str) -\u003e Self {\n        if !should_show_progress(ctx) {\n            return Self { inner: ProgressBar::hidden() };\n        }\n        \n        let pb = ProgressBar::new(total);\n        pb.set_style(ProgressStyle::default_bar()\n            .template(\"{msg:12} [{bar:40.cyan/blue}] {bytes}/{total_bytes} {bytes_per_sec} ETA {eta}\")\n            .unwrap()\n            .progress_chars(\"█▓░\"));\n        pb.set_message(label.to_string());\n        \n        Self { inner: pb }\n    }\n    \n    pub fn set_position(\u0026self, pos: u64) {\n        self.inner.set_position(pos);\n    }\n    \n    pub fn finish(\u0026self) {\n        self.inner.finish_and_clear();\n    }\n}\n\n/// Step progress for multi-phase operations\npub struct StepProgress {\n    steps: Vec\u003cString\u003e,\n    current: usize,\n    ctx: OutputContext,\n}\n\nimpl StepProgress {\n    pub fn new(ctx: \u0026OutputContext, steps: \u0026[\u0026str]) -\u003e Self {\n        Self {\n            steps: steps.iter().map(|s| s.to_string()).collect(),\n            current: 0,\n            ctx: ctx.clone(),\n        }\n    }\n    \n    pub fn start_step(\u0026mut self, idx: usize) {\n        self.current = idx;\n        self.print_steps();\n    }\n    \n    pub fn complete_step(\u0026mut self, idx: usize, message: \u0026str) {\n        // Mark step complete with message\n    }\n    \n    fn print_steps(\u0026self) {\n        // Print step indicators with ✓ ◐ ○\n    }\n}\n\n/// Multi-progress manager for parallel operations\npub struct MultiProgressManager {\n    multi: MultiProgress,\n    ctx: OutputContext,\n}\n\nimpl MultiProgressManager {\n    pub fn new(ctx: \u0026OutputContext) -\u003e Self {\n        let multi = if should_show_progress(ctx) {\n            MultiProgress::new()\n        } else {\n            MultiProgress::with_draw_target(ProgressDrawTarget::hidden())\n        };\n        Self { multi, ctx: ctx.clone() }\n    }\n    \n    pub fn add_spinner(\u0026self, prefix: \u0026str, message: \u0026str) -\u003e Spinner {\n        let pb = self.multi.add(ProgressBar::new_spinner());\n        pb.set_prefix(prefix.to_string());\n        pb.set_message(message.to_string());\n        pb.enable_steady_tick(Duration::from_millis(80));\n        Spinner { inner: pb, ctx: self.ctx.clone() }\n    }\n    \n    pub fn suspend\u003cF, T\u003e(\u0026self, f: F) -\u003e T\n    where\n        F: FnOnce() -\u003e T,\n    {\n        self.multi.suspend(f)\n    }\n}\n\\`\\`\\`\n\n## Testing Requirements\n\n### Unit Tests (\\`rch/src/ui/progress.rs\\`)\n\\`\\`\\`rust\n#[test]\nfn test_spinner_lifecycle() {\n    let ctx = OutputContext::new(false, true); // no color, non-TTY\n    let spinner = Spinner::new(\u0026ctx, \"Testing...\");\n    spinner.finish_success(\"Done\");\n    // Hidden spinner should not panic\n}\n\n#[test]\nfn test_progress_bar_updates() {\n    let ctx = OutputContext::new(false, true);\n    let bar = TransferProgress::new(\u0026ctx, 100, \"test\");\n    bar.set_position(50);\n    bar.finish();\n}\n\n#[test]\nfn test_no_progress_in_quiet_mode() {\n    let ctx = OutputContext::quiet();\n    let spinner = Spinner::new(\u0026ctx, \"Testing...\");\n    // Should use hidden progress bar\n}\n\n#[test]\nfn test_no_progress_in_json_mode() {\n    let ctx = OutputContext::json();\n    let spinner = Spinner::new(\u0026ctx, \"Testing...\");\n    // Should use hidden progress bar\n}\n\\`\\`\\`\n\n### Integration Tests (\\`rch/tests/progress_integration.rs\\`)\n\\`\\`\\`rust\n#[tokio::test]\nasync fn test_probe_shows_progress() {\n    // Start daemon with mock\n    // Run probe command\n    // Verify stderr contains progress indicators\n}\n\n#[tokio::test]\nasync fn test_progress_completes_to_100() {\n    // Simulate transfer with progress callback\n    // Verify progress reaches 100%\n}\n\n#[test]\nfn test_progress_disabled_when_piped() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .env(\"RCH_MOCK_SSH\", \"1\")\n        .args([\"workers\", \"probe\", \"--all\"])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::piped())\n        .output()\n        .unwrap();\n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    assert!(!stderr.contains(\"\\x1b[?25l\")); // No cursor hide (animation)\n}\n\\`\\`\\`\n\n### E2E Test Additions (\\`scripts/e2e_test.sh\\`)\n\\`\\`\\`bash\ntest_progress_indicators() {\n    log \"INFO\" \"PROGRESS\" \"Testing progress indicator behavior...\"\n\n    # Test spinner appears during probe\n    local stderr_file=\"$LOG_DIR/probe_stderr.txt\"\n    RCH_MOCK_SSH=1 \"$RCH\" workers probe mock-worker 2\u003e\"$stderr_file\"\n    if ! grep -q \"mock-worker\" \"$stderr_file\"; then\n        log \"FAIL\" \"PROGRESS\" \"No worker name in progress output\"\n        return 1\n    fi\n    log \"INFO\" \"PROGRESS\" \"Spinner test OK\"\n\n    # Test no animation codes when piped\n    local output\n    output=$(RCH_MOCK_SSH=1 \"$RCH\" workers probe --all 2\u003e\u00261 | cat)\n    if echo \"$output\" | grep -q $'\\x1b\\[?25'; then\n        log \"FAIL\" \"PROGRESS\" \"Animation codes present in piped output\"\n        return 1\n    fi\n    log \"INFO\" \"PROGRESS\" \"Pipe detection OK\"\n\n    # Test progress completes without hanging\n    if ! timeout 10 bash -c 'RCH_MOCK_SSH=1 '\"$RCH\"' workers probe --all 2\u003e\u00261' \u003e /dev/null; then\n        log \"FAIL\" \"PROGRESS\" \"Progress indicators caused hang\"\n        return 1\n    fi\n    log \"INFO\" \"PROGRESS\" \"No hang test OK\"\n}\n\\`\\`\\`\n\n### Manual Testing Checklist\n- [ ] Spinner animates smoothly (12.5 fps, no flicker)\n- [ ] Progress bar shows accurate percentage and speed\n- [ ] ETA is reasonable and updates\n- [ ] Multi-progress renders without flicker\n- [ ] Graceful handling of terminal resize\n- [ ] Ctrl+C cancels cleanly with message\n- [ ] Works correctly with small terminal (\u003c 80 cols)\n- [ ] No visual artifacts on completion\n\n## Acceptance Criteria\n- [ ] All long operations (\u003e500ms) have visual feedback\n- [ ] Spinner/progress bar lifecycle correct (start, update, finish)\n- [ ] indicatif integrated with consistent styling\n- [ ] rsync progress parsing works\n- [ ] Non-TTY mode produces reasonable text output\n- [ ] Quiet and JSON modes suppress progress\n- [ ] Cancellation handled gracefully\n- [ ] No flickering or visual artifacts\n- [ ] Progress + streaming output coexist\n- [ ] Unit test coverage \u003e85% for progress module\n- [ ] Integration tests pass\n- [ ] E2E tests pass including timeout test\n- [ ] Performance: \u003c1% CPU overhead from progress updates\n\n## Logging\n\n- E2E logs should record start/end of each progress scenario, capture whether ANSI animation was used, and log any suspended/resumed output boundaries.\n","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:36:31.800779644-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.25486934-05:00","dependencies":[{"issue_id":"remote_compilation_helper-5te","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T11:58:39.62353985-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-5te","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T11:58:39.692508281-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-62v","title":"Define CircuitState enum and CircuitBreakerConfig","description":"## Overview\n\nDefine the circuit breaker core types and configuration model used across daemon worker selection, health monitoring, and status reporting. This bead establishes the canonical state machine + configuration semantics that all other circuit breaker tasks depend on.\n\n## Goals\n\n1. Define `CircuitState` enum with explicit transitions\n2. Define `CircuitBreakerConfig` with sensible defaults and env overrides\n3. Define `CircuitStats` (rolling counts, timestamps) for decisioning\n4. Provide helper functions for state transitions and eligibility checks\n\n## Circuit Model\n\nStates: Closed / Open / HalfOpen with deterministic transitions and probe limits.\n\n## Helper Functions\n\n- `should_open`, `should_half_open`, `should_close`\n- `record_success`, `record_failure`\n- `can_probe`\n\n## Tests\n\n- Unit: transition logic + rolling window\n- Unit: probe limits\n- Serialization round‑trip\n- E2E: add a lightweight validation to `scripts/e2e_test.sh` that logs default circuit config values from `rch config show --sources` and asserts they’re present (ensures config is wired)\n\n## Logging\n\n- Log state transitions at INFO with worker id + reason\n- E2E logs must show circuit defaults\n\n## Acceptance Criteria\n\n- Circuit state machine is deterministic and well‑tested\n- Config defaults are reasonable and documented\n\n## Blocks\n\n- Integrate circuit state into worker health (remote_compilation_helper-52l)\n- Integrate circuit breaker into selection (remote_compilation_helper-ova)\n- Circuit breaker integration tests (remote_compilation_helper-7nj)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:09:35.732427882-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:22:23.628018527-05:00"}
{"id":"remote_compilation_helper-6qs","title":"Implement local toolchain version detection in hook","description":"## Parent Epic: Automatic Toolchain Synchronization (remote_compilation_helper-ayn)\n\n## Task Description\n\nImplement detection of the local Rust toolchain version in the hook. This version will be sent to the daemon/worker to ensure compilation uses a matching toolchain.\n\n## Design\n\n### Version Detection Approaches\n\n1. **Parse rustc --version output**\n   ```\n   rustc 1.76.0-nightly (abc123def 2024-01-15)\n   rustc 1.75.0 (82e1608df 2023-12-21)\n   ```\n\n2. **Parse rust-toolchain.toml (if present)**\n   ```toml\n   [toolchain]\n   channel = \"nightly-2024-01-15\"\n   ```\n\n3. **Use rustup show active-toolchain**\n   ```\n   nightly-2024-01-15-x86_64-unknown-linux-gnu (overridden by '/project/rust-toolchain.toml')\n   ```\n\n### Implementation\n```rust\n// In rch/src/toolchain.rs (new file) or rch/src/classify.rs\n\nuse std::process::Command;\nuse std::path::Path;\n\n/// Detected Rust toolchain information\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ToolchainInfo {\n    /// The channel: \"stable\", \"beta\", \"nightly\", or specific version\n    pub channel: String,\n    /// Optional date for nightly/beta: \"2024-01-15\"\n    pub date: Option\u003cString\u003e,\n    /// Full version string from rustc --version\n    pub full_version: String,\n}\n\nimpl ToolchainInfo {\n    /// Format for rustup run command\n    pub fn rustup_toolchain(\u0026self) -\u003e String {\n        match \u0026self.date {\n            Some(date) =\u003e format!(\"{}-{}\", self.channel, date),\n            None =\u003e self.channel.clone(),\n        }\n    }\n}\n\n/// Detect the active Rust toolchain for a project\npub fn detect_toolchain(project_root: \u0026Path) -\u003e Result\u003cToolchainInfo, ToolchainError\u003e {\n    // 1. Check for rust-toolchain.toml override\n    let toolchain_file = project_root.join(\"rust-toolchain.toml\");\n    if toolchain_file.exists() {\n        if let Ok(info) = parse_toolchain_file(\u0026toolchain_file) {\n            return Ok(info);\n        }\n    }\n    \n    // 2. Check for rust-toolchain (legacy format)\n    let legacy_file = project_root.join(\"rust-toolchain\");\n    if legacy_file.exists() {\n        if let Ok(info) = parse_legacy_toolchain_file(\u0026legacy_file) {\n            return Ok(info);\n        }\n    }\n    \n    // 3. Fall back to rustc --version\n    detect_from_rustc()\n}\n\nfn parse_toolchain_file(path: \u0026Path) -\u003e Result\u003cToolchainInfo, ToolchainError\u003e {\n    let content = std::fs::read_to_string(path)?;\n    let toml: toml::Value = content.parse()?;\n    \n    let channel = toml\n        .get(\"toolchain\")\n        .and_then(|t| t.get(\"channel\"))\n        .and_then(|c| c.as_str())\n        .ok_or(ToolchainError::InvalidFormat)?;\n    \n    parse_channel_string(channel)\n}\n\nfn parse_channel_string(channel: \u0026str) -\u003e Result\u003cToolchainInfo, ToolchainError\u003e {\n    // Parse: \"nightly-2024-01-15\" or \"stable\" or \"1.75.0\"\n    if channel.starts_with(\"nightly-\") {\n        let date = channel.strip_prefix(\"nightly-\").unwrap();\n        Ok(ToolchainInfo {\n            channel: \"nightly\".to_string(),\n            date: Some(date.to_string()),\n            full_version: channel.to_string(),\n        })\n    } else if channel.starts_with(\"beta-\") {\n        let date = channel.strip_prefix(\"beta-\").unwrap();\n        Ok(ToolchainInfo {\n            channel: \"beta\".to_string(),\n            date: Some(date.to_string()),\n            full_version: channel.to_string(),\n        })\n    } else if channel == \"stable\" || channel == \"beta\" || channel == \"nightly\" {\n        Ok(ToolchainInfo {\n            channel: channel.to_string(),\n            date: None,\n            full_version: channel.to_string(),\n        })\n    } else {\n        // Specific version like \"1.75.0\"\n        Ok(ToolchainInfo {\n            channel: channel.to_string(),\n            date: None,\n            full_version: channel.to_string(),\n        })\n    }\n}\n\nfn detect_from_rustc() -\u003e Result\u003cToolchainInfo, ToolchainError\u003e {\n    let output = Command::new(\"rustc\")\n        .arg(\"--version\")\n        .output()?;\n    \n    let version_str = String::from_utf8_lossy(\u0026output.stdout);\n    // Parse: \"rustc 1.76.0-nightly (abc123def 2024-01-15)\"\n    parse_rustc_version(\u0026version_str)\n}\n\nfn parse_rustc_version(version_str: \u0026str) -\u003e Result\u003cToolchainInfo, ToolchainError\u003e {\n    // Regex: rustc (\\d+\\.\\d+\\.\\d+)(-nightly|-beta)? \\(([a-f0-9]+) (\\d{4}-\\d{2}-\\d{2})\\)\n    let re = regex::Regex::new(\n        r\"rustc (\\d+\\.\\d+\\.\\d+)(-nightly|-beta)? \\(([a-f0-9]+) (\\d{4}-\\d{2}-\\d{2})\\)\"\n    )?;\n    \n    if let Some(caps) = re.captures(version_str) {\n        let version = caps.get(1).unwrap().as_str();\n        let channel_suffix = caps.get(2).map(|m| m.as_str());\n        let date = caps.get(4).map(|m| m.as_str().to_string());\n        \n        let channel = match channel_suffix {\n            Some(\"-nightly\") =\u003e \"nightly\".to_string(),\n            Some(\"-beta\") =\u003e \"beta\".to_string(),\n            None =\u003e \"stable\".to_string(),\n        };\n        \n        Ok(ToolchainInfo {\n            channel,\n            date,\n            full_version: version_str.trim().to_string(),\n        })\n    } else {\n        Err(ToolchainError::ParseError(version_str.to_string()))\n    }\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum ToolchainError {\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n    #[error(\"Invalid toolchain file format\")]\n    InvalidFormat,\n    #[error(\"Failed to parse version: {0}\")]\n    ParseError(String),\n    #[error(\"TOML parse error: {0}\")]\n    Toml(#[from] toml::de::Error),\n    #[error(\"Regex error: {0}\")]\n    Regex(#[from] regex::Error),\n}\n```\n\n## Files to Create/Modify\n- `rch/src/toolchain.rs` (new file)\n- `rch/src/main.rs` or `rch/src/lib.rs` (module declaration)\n- `rch/Cargo.toml` (add toml dependency if not present)\n\n## Testing\n```rust\n#[test]\nfn test_parse_nightly_channel() {\n    let info = parse_channel_string(\"nightly-2024-01-15\").unwrap();\n    assert_eq!(info.channel, \"nightly\");\n    assert_eq!(info.date, Some(\"2024-01-15\".to_string()));\n    assert_eq!(info.rustup_toolchain(), \"nightly-2024-01-15\");\n}\n\n#[test]\nfn test_parse_stable_channel() {\n    let info = parse_channel_string(\"stable\").unwrap();\n    assert_eq!(info.channel, \"stable\");\n    assert_eq!(info.date, None);\n}\n\n#[test]\nfn test_parse_rustc_version_nightly() {\n    let info = parse_rustc_version(\n        \"rustc 1.76.0-nightly (abc123def 2024-01-15)\"\n    ).unwrap();\n    assert_eq!(info.channel, \"nightly\");\n    assert_eq!(info.date, Some(\"2024-01-15\".to_string()));\n}\n\n#[test]\nfn test_parse_rustc_version_stable() {\n    let info = parse_rustc_version(\n        \"rustc 1.75.0 (82e1608df 2023-12-21)\"\n    ).unwrap();\n    assert_eq!(info.channel, \"stable\");\n}\n```\n\n## Acceptance Criteria\n- [ ] ToolchainInfo struct defined\n- [ ] rust-toolchain.toml parsing works\n- [ ] Legacy rust-toolchain file parsing works\n- [ ] rustc --version parsing works\n- [ ] Channel string parsing handles all formats\n- [ ] rustup_toolchain() returns correct format\n- [ ] Tests cover all parsing scenarios\n\n## Estimated Effort: 2-3 hours","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:12:34.073866549-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T13:29:52.417945634-05:00","closed_at":"2026-01-16T13:29:52.417945634-05:00","close_reason":"Toolchain detection fully implemented in toolchain.rs with tests. CLI colored output implemented across all commands using Style system."}
{"id":"remote_compilation_helper-77c","title":"Add dynamic shell completions with clap_complete","description":"## Overview\n\nImplement dynamic shell completions using clap_complete with CompleteEnv for runtime completion generation. Provide seamless tab-completion for all commands, subcommands, flags, and dynamic values like worker IDs.\n\n## Research Findings (2025-2026)\n\n### clap_complete with CompleteEnv\n\nModern clap (v4.5+) supports dynamic completions via CompleteEnv:\n- Runtime completion without pre-generated scripts\n- Completes subcommands, flags, and arguments dynamically\n- Works with bash, zsh, fish, powershell, elvish\n\n**Cargo.toml:**\n```toml\n[dependencies]\nclap = { version = \"4.5\", features = [\"derive\", \"env\"] }\nclap_complete = { version = \"4.5\", features = [\"unstable-dynamic\"] }\n```\n\n### Dynamic Completion Setup\n\n```rust\nuse clap::{Command, Parser};\nuse clap_complete::CompleteEnv;\n\nfn main() {\n    // Handle completion requests before normal execution\n    CompleteEnv::with_factory(Cli::command).complete();\n\n    // Normal CLI execution\n    let cli = Cli::parse();\n    // ...\n}\n```\n\n### Shell Configuration\n\n**Bash (~/.bashrc):**\n```bash\nsource \u003c(COMPLETE=bash rch)\n```\n\n**Zsh (~/.zshrc):**\n```zsh\nsource \u003c(COMPLETE=zsh rch)\n```\n\n**Fish (~/.config/fish/config.fish):**\n```fish\nCOMPLETE=fish rch | source\n```\n\n**PowerShell:**\n```powershell\nInvoke-Expression (\u0026 rch --completions powershell | Out-String)\n```\n\n### Custom Value Completers\n\n```rust\nuse clap::{Arg, ArgAction};\nuse clap_complete::ArgValueCompleter;\n\nfn worker_completer(current: \u0026std::ffi::OsStr) -\u003e Vec\u003cclap_complete::CompletionCandidate\u003e {\n    // Load worker IDs from config\n    let workers = load_worker_ids().unwrap_or_default();\n    workers\n        .into_iter()\n        .filter(|w| w.starts_with(\u0026current.to_string_lossy().as_ref()))\n        .map(|w| clap_complete::CompletionCandidate::new(w))\n        .collect()\n}\n\n#[derive(Parser)]\nstruct Cli {\n    #[command(subcommand)]\n    command: Commands,\n}\n\n#[derive(Subcommand)]\nenum Commands {\n    Workers {\n        #[command(subcommand)]\n        action: WorkerAction,\n    },\n}\n\n#[derive(Subcommand)]\nenum WorkerAction {\n    Probe {\n        #[arg(add = ArgValueCompleter::new(worker_completer))]\n        worker: Option\u003cString\u003e,\n    },\n}\n```\n\n### ValueHint for Common Types\n\n```rust\nuse clap::ValueHint;\n\n#[derive(Parser)]\nstruct Cli {\n    /// Config file path\n    #[arg(long, value_hint = ValueHint::FilePath)]\n    config: Option\u003cPathBuf\u003e,\n\n    /// Working directory\n    #[arg(long, value_hint = ValueHint::DirPath)]\n    workdir: Option\u003cPathBuf\u003e,\n\n    /// Remote host\n    #[arg(long, value_hint = ValueHint::Hostname)]\n    host: Option\u003cString\u003e,\n}\n```\n\n## Implementation\n\n### Main Entry Point Integration\n\n```rust\n// rch/src/main.rs\nuse clap_complete::CompleteEnv;\n\nfn main() {\n    // Handle dynamic completions first (exits if handling completion request)\n    CompleteEnv::with_factory(Cli::command).complete();\n    \n    // Normal execution continues\n    let cli = Cli::parse();\n    run(cli).unwrap_or_else(|e| {\n        eprintln!(\"{:?}\", e);\n        std::process::exit(1);\n    });\n}\n```\n\n### Completion Subcommand (Fallback for Static Scripts)\n\n```rust\n#[derive(Subcommand)]\nenum Commands {\n    /// Generate shell completions (static fallback)\n    Completions {\n        /// Shell to generate for\n        #[arg(value_enum)]\n        shell: clap_complete::Shell,\n    },\n    // ... other commands\n}\n\nfn cmd_completions(shell: clap_complete::Shell) {\n    clap_complete::generate(\n        shell,\n        \u0026mut Cli::command(),\n        \"rch\",\n        \u0026mut std::io::stdout(),\n    );\n}\n```\n\n### Worker ID Completer\n\n```rust\n// rch/src/completions.rs\nuse clap_complete::CompletionCandidate;\nuse std::ffi::OsStr;\n\n/// Complete worker IDs from the config file\npub fn complete_worker_ids(current: \u0026OsStr) -\u003e Vec\u003cCompletionCandidate\u003e {\n    let current = current.to_string_lossy();\n\n    // Try to load config from default location\n    let config_path = match crate::config::default_config_path() {\n        Some(p) =\u003e p,\n        None =\u003e return vec![],\n    };\n    \n    let config = match crate::config::load_config(\u0026config_path) {\n        Ok(c) =\u003e c,\n        Err(_) =\u003e return vec![],\n    };\n\n    config\n        .workers\n        .keys()\n        .filter(|id| id.starts_with(current.as_ref()))\n        .map(|id| {\n            let worker = \u0026config.workers[id];\n            CompletionCandidate::new(id.clone())\n                .help(Some(format!(\"{}@{}\", worker.user, worker.host).into()))\n        })\n        .collect()\n}\n\n/// Complete toolchain names\npub fn complete_toolchains(current: \u0026OsStr) -\u003e Vec\u003cCompletionCandidate\u003e {\n    let current = current.to_string_lossy();\n    \n    // Common Rust toolchains\n    let toolchains = [\n        (\"stable\", \"Latest stable release\"),\n        (\"beta\", \"Beta channel\"),\n        (\"nightly\", \"Nightly channel\"),\n        (\"1.75.0\", \"Specific version\"),\n        (\"1.74.0\", \"Specific version\"),\n    ];\n    \n    toolchains\n        .iter()\n        .filter(|(name, _)| name.starts_with(current.as_ref()))\n        .map(|(name, desc)| {\n            CompletionCandidate::new(*name)\n                .help(Some((*desc).into()))\n        })\n        .collect()\n}\n\n/// Complete log levels\npub fn complete_log_levels(current: \u0026OsStr) -\u003e Vec\u003cCompletionCandidate\u003e {\n    let current = current.to_string_lossy();\n    \n    [\"error\", \"warn\", \"info\", \"debug\", \"trace\"]\n        .iter()\n        .filter(|level| level.starts_with(current.as_ref()))\n        .map(|level| CompletionCandidate::new(*level))\n        .collect()\n}\n```\n\n### CLI Definition with Completers\n\n```rust\n// rch/src/cli.rs\nuse crate::completions::*;\nuse clap::{Parser, Subcommand, ValueHint};\nuse clap_complete::ArgValueCompleter;\n\n#[derive(Parser)]\n#[command(name = \"rch\", about = \"Remote Compilation Helper\")]\npub struct Cli {\n    /// Config file path\n    #[arg(long, short, global = true, value_hint = ValueHint::FilePath)]\n    pub config: Option\u003cPathBuf\u003e,\n    \n    /// Log level\n    #[arg(long, global = true, add = ArgValueCompleter::new(complete_log_levels))]\n    pub log_level: Option\u003cString\u003e,\n    \n    #[command(subcommand)]\n    pub command: Commands,\n}\n\n#[derive(Subcommand)]\npub enum Commands {\n    /// Worker management\n    Workers {\n        #[command(subcommand)]\n        action: WorkerAction,\n    },\n    \n    /// Build commands\n    Build {\n        /// Target worker\n        #[arg(long, add = ArgValueCompleter::new(complete_worker_ids))]\n        worker: Option\u003cString\u003e,\n        \n        /// Rust toolchain\n        #[arg(long, add = ArgValueCompleter::new(complete_toolchains))]\n        toolchain: Option\u003cString\u003e,\n        \n        /// Additional cargo arguments\n        #[arg(trailing_var_arg = true)]\n        args: Vec\u003cString\u003e,\n    },\n    \n    /// Generate shell completions\n    Completions {\n        #[arg(value_enum)]\n        shell: clap_complete::Shell,\n    },\n}\n\n#[derive(Subcommand)]\npub enum WorkerAction {\n    /// List configured workers\n    List,\n    \n    /// Probe worker connectivity\n    Probe {\n        /// Worker ID to probe (or --all)\n        #[arg(add = ArgValueCompleter::new(complete_worker_ids))]\n        worker: Option\u003cString\u003e,\n        \n        /// Probe all workers\n        #[arg(long)]\n        all: bool,\n    },\n    \n    /// Run benchmarks\n    Benchmark {\n        /// Worker ID to benchmark\n        #[arg(add = ArgValueCompleter::new(complete_worker_ids))]\n        worker: Option\u003cString\u003e,\n    },\n}\n```\n\n## Comprehensive Testing Requirements\n\n### Unit Tests (`rch/src/completions.rs` tests module)\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::ffi::OsString;\n    \n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Worker ID Completer Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_worker_completer_empty_prefix() {\n        // With empty input, should return all workers (or empty if no config)\n        let completions = complete_worker_ids(\u0026OsString::from(\"\"));\n        // Note: This may be empty if no config exists during test\n        assert!(completions.len() \u003e= 0);\n    }\n    \n    #[test]\n    fn test_worker_completer_partial_match() {\n        // Create a temp config with known workers\n        let temp_dir = tempfile::TempDir::new().unwrap();\n        let config_path = temp_dir.path().join(\"config.toml\");\n        std::fs::write(\u0026config_path, r#\"\n[daemon]\nport = 7800\n\n[workers.gpu-worker]\nhost = \"192.168.1.100\"\nuser = \"build\"\nidentity_file = \"~/.ssh/id_rsa\"\ntotal_slots = 8\n\n[workers.cpu-worker]\nhost = \"192.168.1.101\"\nuser = \"build\"\nidentity_file = \"~/.ssh/id_rsa\"\ntotal_slots = 16\n\"#).unwrap();\n        \n        std::env::set_var(\"RCH_CONFIG\", config_path.to_str().unwrap());\n        \n        let completions = complete_worker_ids(\u0026OsString::from(\"gpu\"));\n        \n        // Should find gpu-worker\n        let names: Vec\u003c_\u003e = completions.iter()\n            .map(|c| c.get_content().to_string_lossy().to_string())\n            .collect();\n        \n        // Cleanup\n        std::env::remove_var(\"RCH_CONFIG\");\n        \n        // Note: May not find if config loading uses different path\n    }\n    \n    #[test]\n    fn test_worker_completer_no_match() {\n        let completions = complete_worker_ids(\u0026OsString::from(\"nonexistent-prefix-xyz\"));\n        assert!(completions.is_empty(), \"Should return empty for non-matching prefix\");\n    }\n    \n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Toolchain Completer Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_toolchain_completer_stable() {\n        let completions = complete_toolchains(\u0026OsString::from(\"sta\"));\n        let names: Vec\u003c_\u003e = completions.iter()\n            .map(|c| c.get_content().to_string_lossy().to_string())\n            .collect();\n        assert!(names.contains(\u0026\"stable\".to_string()));\n    }\n    \n    #[test]\n    fn test_toolchain_completer_nightly() {\n        let completions = complete_toolchains(\u0026OsString::from(\"nigh\"));\n        let names: Vec\u003c_\u003e = completions.iter()\n            .map(|c| c.get_content().to_string_lossy().to_string())\n            .collect();\n        assert!(names.contains(\u0026\"nightly\".to_string()));\n    }\n    \n    #[test]\n    fn test_toolchain_completer_version() {\n        let completions = complete_toolchains(\u0026OsString::from(\"1.7\"));\n        let names: Vec\u003c_\u003e = completions.iter()\n            .map(|c| c.get_content().to_string_lossy().to_string())\n            .collect();\n        assert!(names.iter().any(|n| n.starts_with(\"1.7\")));\n    }\n    \n    #[test]\n    fn test_toolchain_completer_all_with_empty() {\n        let completions = complete_toolchains(\u0026OsString::from(\"\"));\n        assert!(!completions.is_empty(), \"Should return all toolchains for empty input\");\n    }\n    \n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Log Level Completer Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_log_level_completer_all_levels() {\n        let completions = complete_log_levels(\u0026OsString::from(\"\"));\n        let names: Vec\u003c_\u003e = completions.iter()\n            .map(|c| c.get_content().to_string_lossy().to_string())\n            .collect();\n        \n        assert!(names.contains(\u0026\"error\".to_string()));\n        assert!(names.contains(\u0026\"warn\".to_string()));\n        assert!(names.contains(\u0026\"info\".to_string()));\n        assert!(names.contains(\u0026\"debug\".to_string()));\n        assert!(names.contains(\u0026\"trace\".to_string()));\n    }\n    \n    #[test]\n    fn test_log_level_completer_partial() {\n        let completions = complete_log_levels(\u0026OsString::from(\"de\"));\n        let names: Vec\u003c_\u003e = completions.iter()\n            .map(|c| c.get_content().to_string_lossy().to_string())\n            .collect();\n        \n        assert!(names.contains(\u0026\"debug\".to_string()));\n        assert!(!names.contains(\u0026\"info\".to_string()));\n    }\n    \n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Completion Candidate Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_completion_candidate_has_help() {\n        let completions = complete_toolchains(\u0026OsString::from(\"stable\"));\n        assert!(!completions.is_empty());\n        \n        let stable = \u0026completions[0];\n        assert!(stable.get_help().is_some(), \"Completion should have help text\");\n    }\n}\n```\n\n### Integration Tests (`rch/tests/completion_integration.rs`)\n\n```rust\n//! Integration tests for shell completions\n\nuse std::process::{Command, Stdio};\nuse std::io::Write;\n\n/// Test that COMPLETE=bash generates valid bash completion script\n#[test]\nfn test_bash_completion_generation() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .env(\"COMPLETE\", \"bash\")\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    \n    // Should generate bash completion script\n    assert!(stdout.contains(\"complete\") || stdout.contains(\"_rch\"),\n            \"Should generate bash completion functions\");\n    assert!(stdout.contains(\"rch\"), \"Should reference rch command\");\n}\n\n/// Test that COMPLETE=zsh generates valid zsh completion script\n#[test]\nfn test_zsh_completion_generation() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .env(\"COMPLETE\", \"zsh\")\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    \n    // Should generate zsh completion script\n    assert!(stdout.contains(\"compdef\") || stdout.contains(\"_rch\") || stdout.contains(\"compadd\"),\n            \"Should generate zsh completion functions\");\n}\n\n/// Test that COMPLETE=fish generates valid fish completion script\n#[test]\nfn test_fish_completion_generation() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .env(\"COMPLETE\", \"fish\")\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    \n    // Should generate fish completion script\n    assert!(stdout.contains(\"complete\") \u0026\u0026 stdout.contains(\"rch\"),\n            \"Should generate fish completion commands\");\n}\n\n/// Test fallback completions subcommand\n#[test]\nfn test_completions_subcommand_bash() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"completions\", \"bash\"])\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    assert!(output.status.success(), \"Completions command should succeed\");\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert!(!stdout.is_empty(), \"Should output completion script\");\n}\n\n/// Test completions subcommand with all supported shells\n#[test]\nfn test_completions_subcommand_all_shells() {\n    for shell in [\"bash\", \"zsh\", \"fish\", \"powershell\", \"elvish\"] {\n        let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n            .args([\"completions\", shell])\n            .output()\n            .expect(\u0026format!(\"Failed to execute rch completions {}\", shell));\n        \n        assert!(output.status.success(), \n                \"Completions for {} should succeed\", shell);\n        \n        let stdout = String::from_utf8_lossy(\u0026output.stdout);\n        assert!(!stdout.is_empty(), \n                \"Should output completion script for {}\", shell);\n    }\n}\n\n/// Test that dynamic completion doesn't interfere with normal execution\n#[test]\nfn test_dynamic_completion_no_interference() {\n    // Without COMPLETE env var, should run normally\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"--help\"])\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    assert!(output.status.success());\n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert!(stdout.contains(\"Remote Compilation Helper\") || stdout.contains(\"rch\"),\n            \"Should show normal help output\");\n}\n\n/// Test completion with actual bash (if available)\n#[test]\n#[ignore] // Run with --ignored for shell-specific tests\nfn test_bash_completion_works() {\n    // Check if bash is available\n    let bash_check = Command::new(\"bash\")\n        .args([\"--version\"])\n        .output();\n    \n    if bash_check.is_err() {\n        eprintln!(\"Bash not available, skipping\");\n        return;\n    }\n    \n    // Generate completion script\n    let completion_script = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .env(\"COMPLETE\", \"bash\")\n        .output()\n        .expect(\"Failed to generate completions\")\n        .stdout;\n    \n    // Try to source it in bash (syntax check)\n    let mut bash = Command::new(\"bash\")\n        .args([\"-n\"]) // Syntax check only\n        .stdin(Stdio::piped())\n        .spawn()\n        .expect(\"Failed to start bash\");\n    \n    bash.stdin.as_mut().unwrap().write_all(\u0026completion_script).unwrap();\n    let status = bash.wait().expect(\"Failed to wait for bash\");\n    \n    assert!(status.success(), \"Completion script should be valid bash syntax\");\n}\n\n/// Test that subcommands are completed\n#[test]\nfn test_subcommand_completion_included() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .env(\"COMPLETE\", \"bash\")\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    \n    // Should include main subcommands\n    assert!(stdout.contains(\"workers\") || stdout.contains(\"build\") || stdout.contains(\"daemon\"),\n            \"Should include subcommand completions\");\n}\n```\n\n### E2E Test Script (`scripts/e2e_test.sh` additions)\n\n```bash\n# ═══════════════════════════════════════════════════════════════════════════════════\n# Shell Completion Tests\n# ═══════════════════════════════════════════════════════════════════════════════════\n\ntest_shell_completions() {\n    log \"INFO\" \"COMPLETIONS\" \"Testing shell completion generation...\"\n\n    # Test 1: Bash completion generation via COMPLETE env\n    log \"INFO\" \"COMPLETIONS\" \"Test 1: COMPLETE=bash generates script\"\n    local bash_completions\n    if bash_completions=$(COMPLETE=bash \"$RCH\" 2\u003e\u00261); then\n        if [ -n \"$bash_completions\" ]; then\n            log \"INFO\" \"COMPLETIONS\" \"✓ Bash completions generated (${#bash_completions} bytes)\"\n            \n            # Verify it contains expected patterns\n            if echo \"$bash_completions\" | grep -q \"rch\\|complete\\|_rch\"; then\n                log \"INFO\" \"COMPLETIONS\" \"✓ Bash script contains expected patterns\"\n            else\n                log \"WARN\" \"COMPLETIONS\" \"Bash script may be incomplete\"\n            fi\n        else\n            log \"FAIL\" \"COMPLETIONS\" \"Bash completions empty\"\n            return 1\n        fi\n    else\n        log \"FAIL\" \"COMPLETIONS\" \"Failed to generate bash completions\"\n        return 1\n    fi\n\n    # Test 2: Zsh completion generation\n    log \"INFO\" \"COMPLETIONS\" \"Test 2: COMPLETE=zsh generates script\"\n    local zsh_completions\n    if zsh_completions=$(COMPLETE=zsh \"$RCH\" 2\u003e\u00261); then\n        if [ -n \"$zsh_completions\" ]; then\n            log \"INFO\" \"COMPLETIONS\" \"✓ Zsh completions generated (${#zsh_completions} bytes)\"\n        else\n            log \"FAIL\" \"COMPLETIONS\" \"Zsh completions empty\"\n            return 1\n        fi\n    else\n        log \"FAIL\" \"COMPLETIONS\" \"Failed to generate zsh completions\"\n        return 1\n    fi\n\n    # Test 3: Fish completion generation\n    log \"INFO\" \"COMPLETIONS\" \"Test 3: COMPLETE=fish generates script\"\n    local fish_completions\n    if fish_completions=$(COMPLETE=fish \"$RCH\" 2\u003e\u00261); then\n        if [ -n \"$fish_completions\" ]; then\n            log \"INFO\" \"COMPLETIONS\" \"✓ Fish completions generated (${#fish_completions} bytes)\"\n        else\n            log \"FAIL\" \"COMPLETIONS\" \"Fish completions empty\"\n            return 1\n        fi\n    else\n        log \"FAIL\" \"COMPLETIONS\" \"Failed to generate fish completions\"\n        return 1\n    fi\n\n    # Test 4: Fallback completions subcommand\n    log \"INFO\" \"COMPLETIONS\" \"Test 4: Completions subcommand works\"\n    for shell in bash zsh fish; do\n        if \"$RCH\" completions \"$shell\" \u003e /dev/null 2\u003e\u00261; then\n            log \"INFO\" \"COMPLETIONS\" \"✓ 'rch completions $shell' works\"\n        else\n            log \"FAIL\" \"COMPLETIONS\" \"'rch completions $shell' failed\"\n            return 1\n        fi\n    done\n\n    # Test 5: Bash syntax validation (if bash available)\n    log \"INFO\" \"COMPLETIONS\" \"Test 5: Bash completion script syntax\"\n    if command -v bash \u003e /dev/null 2\u003e\u00261; then\n        if echo \"$bash_completions\" | bash -n 2\u003e/dev/null; then\n            log \"INFO\" \"COMPLETIONS\" \"✓ Bash completion script has valid syntax\"\n        else\n            log \"WARN\" \"COMPLETIONS\" \"Bash syntax check failed (may be expected for some completion formats)\"\n        fi\n    else\n        log \"INFO\" \"COMPLETIONS\" \"Bash not available, skipping syntax check\"\n    fi\n\n    # Test 6: No interference with normal operation\n    log \"INFO\" \"COMPLETIONS\" \"Test 6: Normal operation unaffected\"\n    local help_output\n    if help_output=$(\"$RCH\" --help 2\u003e\u00261); then\n        if echo \"$help_output\" | grep -qi \"remote\\|compilation\\|rch\\|usage\"; then\n            log \"INFO\" \"COMPLETIONS\" \"✓ Normal --help works correctly\"\n        else\n            log \"FAIL\" \"COMPLETIONS\" \"Help output unexpected\"\n            return 1\n        fi\n    else\n        log \"FAIL\" \"COMPLETIONS\" \"Help command failed\"\n        return 1\n    fi\n\n    # Test 7: Completion includes subcommands\n    log \"INFO\" \"COMPLETIONS\" \"Test 7: Completions include subcommands\"\n    local has_subcommands=0\n    for subcmd in workers daemon build status; do\n        if echo \"$bash_completions\" | grep -q \"$subcmd\"; then\n            has_subcommands=1\n            break\n        fi\n    done\n    \n    if [ \"$has_subcommands\" -eq 1 ]; then\n        log \"INFO\" \"COMPLETIONS\" \"✓ Completions include subcommands\"\n    else\n        log \"WARN\" \"COMPLETIONS\" \"Could not verify subcommand completions (format may differ)\"\n    fi\n\n    log \"INFO\" \"COMPLETIONS\" \"Shell completion tests completed\"\n}\n\n# Add to main test suite\nrun_all_tests() {\n    # ... existing tests ...\n    test_shell_completions\n}\n```\n\n### Manual Testing Checklist\n\n```markdown\n## Shell Completion Manual Testing Checklist\n\n### Bash Testing\n- [ ] Source completions: `source \u003c(COMPLETE=bash rch)`\n- [ ] `rch \u003cTAB\u003e` shows subcommands (workers, daemon, build, etc.)\n- [ ] `rch workers \u003cTAB\u003e` shows worker subcommands (list, probe, benchmark)\n- [ ] `rch workers probe \u003cTAB\u003e` shows worker IDs from config\n- [ ] `rch --\u003cTAB\u003e` shows global flags (--config, --json, --log-level)\n- [ ] `rch build --toolchain \u003cTAB\u003e` shows toolchain options\n- [ ] `rch --config \u003cTAB\u003e` completes file paths\n\n### Zsh Testing\n- [ ] Source completions: `source \u003c(COMPLETE=zsh rch)`\n- [ ] All bash tests above work in zsh\n- [ ] Help descriptions shown with completions\n\n### Fish Testing\n- [ ] Source completions: `COMPLETE=fish rch | source`\n- [ ] All completion scenarios work\n- [ ] Descriptions shown in completion menu\n\n### Edge Cases\n- [ ] Completions work with custom config path\n- [ ] Completions don't hang or crash\n- [ ] Large number of workers doesn't slow completion\n- [ ] Works with spaces in paths (--config \"path with spaces/config.toml\")\n```\n\n## Files to Modify\n\n- `rch/Cargo.toml` - Add clap_complete with unstable-dynamic feature\n- `rch/src/main.rs` - Add CompleteEnv::complete() call at start\n- `rch/src/completions.rs` - New module with custom completers\n- `rch/src/cli.rs` - Add ArgValueCompleter and ValueHint annotations\n- `rch/tests/completion_integration.rs` - Integration tests\n- `scripts/e2e_test.sh` - E2E test additions\n\n## Success Criteria\n\n- [ ] Dynamic completions work with CompleteEnv (COMPLETE=bash/zsh/fish)\n- [ ] Worker IDs complete from config file\n- [ ] Toolchain names complete with help text\n- [ ] File paths complete with ValueHint\n- [ ] Subcommands and flags complete correctly\n- [ ] Works in bash, zsh, fish, powershell, elvish\n- [ ] Fallback `rch completions \u003cshell\u003e` command works\n- [ ] Generated scripts have valid syntax\n- [ ] No performance issues with completion generation\n- [ ] Documentation for shell setup in --help or README\n- [ ] Unit test coverage \u003e85% for completion module\n- [ ] Integration tests pass for all shells\n- [ ] E2E tests verify completion generation\n\n## Dependencies\n\n- None (standalone feature)\n\n## Logging\n\n- E2E logs should include completion script sizes per shell and the first 3 lines of each script for quick inspection.\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T15:13:27.117049104-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.296137032-05:00"}
{"id":"remote_compilation_helper-7ds","title":"Epic: Rich rch status Command for Operational Visibility","description":"## Overview\n\nProvide a rich operational `rch status` experience, backed by a daemon `/status` API and build history tracking. This epic covers API, data capture, and CLI rendering.\n\n## Goals\n\n1. `/status` API with daemon + worker + history data\n2. Build history ring buffer + optional persistence\n3. CLI output with tables, warnings, and JSON\n4. Clear remediation guidance when issues detected\n\n## Sub‑Beads\n\n- Add `/status` API endpoint (remote_compilation_helper-3sy)\n- Add build history tracking (remote_compilation_helper-qgs)\n- Implement `rch status` CLI (remote_compilation_helper-wea)\n\n## Testing Requirements\n\n- Integration tests: `/status` JSON shape\n- Unit tests: worker table rendering\n- E2E tests: `rch status` in mock mode prints expected sections\n- Logging: E2E tests output the status payload for troubleshooting\n\n## Acceptance Criteria\n\n- `rch status` reliable and informative\n- `/status` JSON usable for TUI and web UI\n- Error handling is actionable\n\n## Dependencies\n\n- Circuit breaker visibility (remote_compilation_helper-62v, remote_compilation_helper-52l)\n\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:06:19.357573016-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:05:16.80377131-05:00"}
{"id":"remote_compilation_helper-7nj","title":"Add circuit breaker integration tests and E2E scenarios","description":"## Overview\n\nAdd comprehensive integration + E2E tests for circuit breaker behavior, with detailed logging and deterministic timing.\n\n## Goals\n\n1. Test state transitions end‑to‑end\n2. Verify selection exclusion for open circuits\n3. Verify recovery path from open -\u003e half‑open -\u003e closed\n4. Ensure status API surfaces circuit data\n\n## Test Matrix\n\n### Unit\n- transition logic (closed/open/half‑open)\n- probe budgets\n- windowed error rates\n\n### Integration (daemon)\n- simulated worker failures in health loop\n- selection returns `AllCircuitsOpen`\n- selection resumes after cooldown\n\n### E2E (scripts/e2e_test.sh)\n- Start daemon in mock mode\n- Inject failures to open circuits\n- Confirm selection avoids open worker\n- Advance clock or simulate cooldown\n- Confirm half‑open probes and recovery\n\n## Logging\n\n- Tests should log each step with timestamps and worker ids\n- E2E logs must include the exact sequence of circuit states\n\n## Acceptance Criteria\n\n- Tests are deterministic and pass under mock transport\n- E2E logs are human‑readable and include state changes\n\n## Dependencies\n\n- Circuit state definitions (remote_compilation_helper-62v)\n- Health + selection integrations (remote_compilation_helper-52l, remote_compilation_helper-ova)\n- Status API (remote_compilation_helper-3sy)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:11:55.485643153-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:04:06.865851856-05:00","dependencies":[{"issue_id":"remote_compilation_helper-7nj","depends_on_id":"remote_compilation_helper-ova","type":"blocks","created_at":"2026-01-16T12:12:01.998451-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-8ht","title":"Implement rch CLI subcommand handlers","notes":"Expanded CLI epic covers all subcommands; keep this issue as active implementation track. If your current work already implements some subcommands, mark progress there and close corresponding child tasks.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T08:58:31.902861769-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:27:08.659087805-05:00","closed_at":"2026-01-16T09:27:08.659087805-05:00","close_reason":"Duplicate of ei5.3.1 - CLI subcommand handlers implemented","dependencies":[{"issue_id":"remote_compilation_helper-8ht","depends_on_id":"remote_compilation_helper-ei5.3","type":"parent-child","created_at":"2026-01-16T09:13:19.773419586-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-9pw","title":"Epic: Circuit Breaker Pattern with Auto-Recovery","description":"## Overview\n\nImplement a robust circuit breaker system to prevent repeated use of unstable workers and enable automatic recovery. This ensures the system remains responsive and avoids cascading failures when a worker or network path is degraded.\n\n## Goals\n\n1. Per‑worker circuit breakers with clear state machine\n2. Automatic recovery with half‑open probe semantics\n3. Integration with health checks + selection\n4. Visibility in `rch status` + `/status` API\n5. Safe defaults + configuration via config/env\n\n## Design\n\n### Circuit Mechanics\n- Failure signals: health check failures, SSH failures, rsync errors, repeated non‑zero exit codes\n- Success signals: health checks + successful remote compile\n- Rolling window error rate threshold + consecutive failure threshold\n\n### Config\n- `failure_threshold`\n- `success_threshold`\n- `error_rate_threshold`\n- `window_secs`\n- `open_cooldown_secs`\n- `half_open_max_probes`\n\n### Behavior\n- Open circuits are *never* selected\n- Half‑open circuits get limited probes; close on successes\n- Circuit state recorded per worker and included in status reporting\n\n## Tasks (Sub‑Beads)\n\n1. **Define CircuitState + Config** (remote_compilation_helper-62v)\n2. **Integrate into WorkerHealth** (remote_compilation_helper-52l)\n3. **Integrate into Selection** (remote_compilation_helper-ova)\n4. **Add Circuit Tests/E2E** (remote_compilation_helper-7nj)\n\n## Testing Requirements\n\n- Unit tests: state transitions, windows, probe limits\n- Integration tests: health loop -\u003e circuit -\u003e selection\n- E2E tests: full daemon loop with mocked worker failures and recovery\n\n## Acceptance Criteria\n\n- Open circuits are excluded from selection\n- Half‑open probing behavior is correct and limited\n- Circuit state is visible in status outputs\n- Tests cover failure + recovery paths\n\n## Dependencies\n\n- Status API + CLI output (remote_compilation_helper-3sy, remote_compilation_helper-7ds)\n\n## Logging\n\n- E2E logs must capture circuit state transitions with reasons and timestamps.\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:07:00.89564336-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.334430845-05:00"}
{"id":"remote_compilation_helper-9zy","title":"Epic: Self-Update Command with GitHub Releases Integration","description":"## Overview\n\nImplement a complete self-update pipeline (`rch update`) that downloads verified release artifacts, safely updates local binaries with daemon coordination, optionally updates all workers, and supports rollback. The update must be cryptographically verified, fully idempotent, and handle in-progress builds gracefully.\n\n## Goals\n\n1. `rch update` for local binaries (rch, rchd, rch-wkr)\n2. SHA256 checksum verification on every download\n3. Optional signature verification (minisign/Sigstore)\n4. Version pinning and release channels (stable/beta/nightly)\n5. Fleet update with parallel SSH distribution\n6. Rollback to previous version\n7. Graceful daemon restart with build drain\n8. Update locking to prevent concurrent updates\n9. Changelog/release notes display\n\n## Release Artifact Contract\n\nRelease assets MUST include:\n- Platform-specific tarballs: `rch-v{version}-{target}.tar.gz`\n- Per-asset checksums: `rch-v{version}-{target}.tar.gz.sha256`\n- Aggregated checksums: `checksums.txt`\n- Optional signatures: `checksums.txt.sig` (minisign) or `.sigstore` attestation\n- Release notes: `RELEASE_NOTES.md`\n\n## CLI Interface\n\n```\nrch update [OPTIONS]\n\nOPTIONS:\n  --check                Check for updates without installing\n  --version \u003cVER\u003e        Install specific version (e.g., v0.2.0)\n  --channel \u003cCHANNEL\u003e    Release channel: stable (default), beta, nightly\n  --fleet                Update all configured workers\n  --rollback             Restore previous version from backup\n  --verify               Verify current installation integrity\n  --yes                  Skip confirmation prompts\n  --dry-run              Show planned actions without executing\n  --no-restart           Update binaries but don't restart daemon\n  --drain-timeout \u003cSEC\u003e  Wait up to N seconds for builds to complete (default: 60)\n  --force                Skip version check, reinstall current version\n  --json                 Output results as JSON\n```\n\n## Update Flow\n\n### Phase 1: Discovery\n```rust\npub struct UpdateCheck {\n    pub current_version: Version,\n    pub latest_version: Version,\n    pub update_available: bool,\n    pub release_url: String,\n    pub release_notes: Option\u003cString\u003e,\n    pub assets: Vec\u003cReleaseAsset\u003e,\n}\n\nasync fn check_for_updates(channel: Channel) -\u003e Result\u003cUpdateCheck\u003e {\n    // 1. Fetch release list from GitHub API\n    // 2. Filter by channel (stable = no prerelease, beta = prerelease, nightly = latest)\n    // 3. Compare versions\n    // 4. Return update info\n}\n```\n\n### Phase 2: Download and Verify\n```rust\npub struct VerifiedDownload {\n    pub path: PathBuf,\n    pub checksum: String,\n    pub signature_status: SignatureStatus,\n}\n\nasync fn download_and_verify(asset: \u0026ReleaseAsset) -\u003e Result\u003cVerifiedDownload\u003e {\n    // 1. Download asset to temp file\n    // 2. Download checksum file\n    // 3. Verify SHA256\n    // 4. If signature available, verify with minisign/sigstore\n    // 5. Return verified download\n}\n```\n\n### Phase 3: Daemon Coordination\n```rust\npub enum DaemonState {\n    NotRunning,\n    Running { pid: u32, active_builds: u32 },\n    Draining { pid: u32, remaining: u32, deadline: Instant },\n}\n\nasync fn coordinate_daemon_update(drain_timeout: Duration) -\u003e Result\u003cDaemonState\u003e {\n    // 1. Check if daemon is running\n    // 2. If running, signal drain mode (stop accepting new builds)\n    // 3. Wait for active builds to complete (up to timeout)\n    // 4. If builds still running after timeout, warn user\n    // 5. Return state for update decision\n}\n```\n\n### Phase 4: Installation\n```rust\nasync fn install_update(download: \u0026VerifiedDownload, backup: bool) -\u003e Result\u003cInstallResult\u003e {\n    // 1. Acquire update lock\n    // 2. Stop daemon gracefully\n    // 3. Backup current binaries to ~/.rch/backups/v{version}/\n    // 4. Extract new binaries to temp location\n    // 5. Atomic replace: rename temp -\u003e target\n    // 6. Verify new binaries work (--version check)\n    // 7. Restart daemon\n    // 8. Release lock\n}\n```\n\n### Phase 5: Fleet Update\n```rust\npub struct FleetUpdateResult {\n    pub workers: Vec\u003cWorkerUpdateResult\u003e,\n    pub success_count: u32,\n    pub failure_count: u32,\n    pub skipped_count: u32,\n}\n\nasync fn update_fleet(workers: \u0026[WorkerConfig], parallel: usize) -\u003e Result\u003cFleetUpdateResult\u003e {\n    // 1. Check versions on all workers in parallel\n    // 2. Filter to workers needing update\n    // 3. Upload new binaries via rsync\n    // 4. Restart worker agents\n    // 5. Verify health\n    // 6. Collect results\n}\n```\n\n## Rollback Strategy\n\n```rust\npub struct Backup {\n    pub version: Version,\n    pub path: PathBuf,\n    pub created_at: DateTime\u003cUtc\u003e,\n    pub binaries: Vec\u003cString\u003e,\n}\n\nasync fn rollback() -\u003e Result\u003c()\u003e {\n    // 1. List available backups\n    // 2. Select most recent (or let user choose)\n    // 3. Stop daemon\n    // 4. Restore binaries from backup\n    // 5. Verify restored binaries\n    // 6. Restart daemon\n}\n```\n\n## Update Lock\n\n```rust\n// Prevent concurrent updates\npub struct UpdateLock {\n    file: File,\n    path: PathBuf,\n}\n\nimpl UpdateLock {\n    pub fn acquire() -\u003e Result\u003cSelf\u003e {\n        let path = dirs::data_dir()?.join(\"rch/update.lock\");\n        // Use flock for cross-process locking\n    }\n}\n```\n\n## Implementation Files\n\n```\nrch/src/\n├── update/\n│   ├── mod.rs           # Public API\n│   ├── check.rs         # Version checking\n│   ├── download.rs      # Download and verification\n│   ├── verify.rs        # Checksum and signature verification\n│   ├── install.rs       # Binary installation\n│   ├── daemon.rs        # Daemon coordination\n│   ├── fleet.rs         # Fleet update logic\n│   ├── rollback.rs      # Rollback functionality\n│   └── lock.rs          # Update locking\n├── commands/\n│   └── update.rs        # CLI command\n```\n\n## Testing Requirements\n\n### Unit Tests (rch/src/update/tests/)\n\n**check_test.rs**\n```rust\n#[test]\nfn test_version_comparison() {\n    assert!(Version::parse(\"0.2.0\") \u003e Version::parse(\"0.1.0\"));\n    assert!(Version::parse(\"0.2.0-beta.1\") \u003c Version::parse(\"0.2.0\"));\n}\n\n#[test]\nfn test_channel_filtering() {\n    let releases = vec![\n        Release { version: \"0.2.0\", prerelease: false },\n        Release { version: \"0.3.0-beta.1\", prerelease: true },\n    ];\n    assert_eq!(filter_by_channel(\u0026releases, Channel::Stable).version, \"0.2.0\");\n    assert_eq!(filter_by_channel(\u0026releases, Channel::Beta).version, \"0.3.0-beta.1\");\n}\n```\n\n**verify_test.rs**\n```rust\n#[test]\nfn test_checksum_verification_success() {\n    let content = b\"test content\";\n    let expected = \"6ae8a75555209fd6c44157c0aed8016e763ff435a19cf186f76863140143ff72\";\n    assert!(verify_sha256(content, expected).is_ok());\n}\n\n#[test]\nfn test_checksum_verification_failure() {\n    let content = b\"test content\";\n    let wrong = \"0000000000000000000000000000000000000000000000000000000000000000\";\n    assert!(verify_sha256(content, wrong).is_err());\n}\n\n#[test]\nfn test_checksum_file_parsing() {\n    let checksums = \"abc123  rch-v0.1.0-linux.tar.gz\\ndef456  rch-v0.1.0-darwin.tar.gz\";\n    let parsed = parse_checksums(checksums);\n    assert_eq!(parsed.get(\"rch-v0.1.0-linux.tar.gz\"), Some(\u0026\"abc123\"));\n}\n```\n\n**daemon_test.rs**\n```rust\n#[tokio::test]\nasync fn test_drain_waits_for_builds() {\n    let mock_daemon = MockDaemon::with_active_builds(2);\n    let result = coordinate_daemon_update(\u0026mock_daemon, Duration::from_secs(5)).await;\n    assert!(result.is_ok());\n    assert_eq!(mock_daemon.drain_called(), true);\n}\n```\n\n### Integration Tests (rch/tests/update_integration.rs)\n\n```rust\n#[tokio::test]\nasync fn test_update_check_with_mock_github() {\n    let server = MockGitHubServer::new();\n    server.add_release(\"v0.2.0\", false);\n\n    let result = check_for_updates_with_url(server.url(), Channel::Stable).await;\n    assert!(result.unwrap().update_available);\n}\n\n#[tokio::test]\nasync fn test_download_and_verify() {\n    let server = MockServer::new();\n    server.serve_file(\"rch.tar.gz\", include_bytes!(\"fixtures/rch.tar.gz\"));\n    server.serve_file(\"rch.tar.gz.sha256\", b\"\u003ccorrect checksum\u003e\");\n\n    let result = download_and_verify(\u0026server.url()).await;\n    assert!(result.is_ok());\n}\n\n#[tokio::test]\nasync fn test_rollback_restores_previous() {\n    let tmp = TempDir::new().unwrap();\n    setup_fake_installation(\u0026tmp, \"0.1.0\");\n    setup_backup(\u0026tmp, \"0.0.9\");\n\n    let result = rollback_with_base(\u0026tmp).await;\n    assert!(result.is_ok());\n    assert_eq!(get_installed_version(\u0026tmp), \"0.0.9\");\n}\n```\n\n### E2E Test Script (scripts/e2e_update_test.sh)\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# Test update functionality with mock releases\nlog() { echo \"[$(date -Iseconds)] $*\" \u003e\u00262; }\n\n# Setup mock release server\nstart_mock_server() {\n    python3 -c \"\nimport http.server\nimport os\nos.chdir('$MOCK_RELEASE_DIR')\nhttp.server.test(HandlerClass=http.server.SimpleHTTPRequestHandler, port=8765)\n\" \u0026\n    MOCK_PID=$!\n    sleep 1\n}\n\n# Test 1: Update check detects new version\ntest_update_check() {\n    log \"Test: update --check detects new version\"\n    OUTPUT=$(\"$RCH\" update --check 2\u003e\u00261)\n    echo \"$OUTPUT\" | grep -q \"available\" || fail \"Should detect update\"\n    pass \"Update check\"\n}\n\n# Test 2: Dry run shows planned actions\ntest_dry_run() {\n    log \"Test: update --dry-run shows plan\"\n    OUTPUT=$(\"$RCH\" update --dry-run 2\u003e\u00261)\n    echo \"$OUTPUT\" | grep -q \"Would download\" || fail \"Should show download plan\"\n    pass \"Dry run\"\n}\n\n# Test 3: Update with verification\ntest_update_with_verify() {\n    log \"Test: update downloads and verifies\"\n    \"$RCH\" update --yes 2\u003e\u00261\n    \"$RCH\" --version | grep -q \"0.2.0\" || fail \"Should be updated\"\n    pass \"Update with verification\"\n}\n\n# Test 4: Rollback restores previous\ntest_rollback() {\n    log \"Test: rollback restores previous version\"\n    \"$RCH\" update --rollback --yes 2\u003e\u00261\n    \"$RCH\" --version | grep -q \"0.1.0\" || fail \"Should be rolled back\"\n    pass \"Rollback\"\n}\n\n# Run tests\nstart_mock_server\ntrap \"kill $MOCK_PID 2\u003e/dev/null\" EXIT\n\ntest_update_check\ntest_dry_run\ntest_update_with_verify\ntest_rollback\n\nlog \"All update E2E tests passed!\"\n```\n\n## Logging Requirements\n\n- INFO: Update check result (current version, latest version)\n- INFO: Download progress (bytes/total, speed)\n- INFO: Verification status (checksum match, signature status)\n- INFO: Daemon coordination (drain started, builds remaining)\n- INFO: Installation steps (backup created, binaries replaced)\n- WARN: Signature not available (continue with checksum only)\n- WARN: Drain timeout reached (builds still in progress)\n- ERROR: Checksum mismatch (with expected vs actual)\n- ERROR: Installation failed (with rollback instructions)\n\n## Success Criteria\n\n- [ ] `rch update --check` reports update availability\n- [ ] `rch update` downloads and verifies checksum\n- [ ] `rch update` creates backup before installing\n- [ ] `rch update` coordinates with daemon (drain builds)\n- [ ] `rch update --fleet` updates workers in parallel\n- [ ] `rch update --rollback` restores previous version\n- [ ] Update lock prevents concurrent updates\n- [ ] JSON output for automation\n- [ ] Unit test coverage \u003e 80%\n- [ ] E2E tests pass with mock server\n\n## Dependencies\n\n- remote_compilation_helper-bcl: CI workflow for release artifacts\n- remote_compilation_helper-gao: cargo-dist for automated releases\n\n## Blocks\n\n- remote_compilation_helper-eke: install.sh uses update infrastructure\n- remote_compilation_helper-brr: Fleet deployment uses update distribution\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:50:59.495549941-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:26:26.373922193-05:00","dependencies":[{"issue_id":"remote_compilation_helper-9zy","depends_on_id":"remote_compilation_helper-bcl","type":"blocks","created_at":"2026-01-16T15:03:14.884903594-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-9zy","depends_on_id":"remote_compilation_helper-gao","type":"blocks","created_at":"2026-01-16T15:13:37.2367856-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ac7","title":"Implement worker configuration system (workers.toml)","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T08:46:12.570030987-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T08:48:27.672771503-05:00","closed_at":"2026-01-16T08:48:27.672771503-05:00","close_reason":"Implemented worker configuration system: rchd/src/config.rs with TOML-based workers.toml and daemon.toml support. Loads workers at daemon startup and populates WorkerPool. 4 new tests, all 43 tests pass."}
{"id":"remote_compilation_helper-alo","title":"Improve error messages with actionable suggestions and help links","description":"## Overview\n\nImprove error messages across CLI and hook paths with actionable, user-friendly guidance, structured error codes, and optional help links (OSC-8 when supported). Errors must be concise but informative.\n\nThis bead builds on the miette error diagnostics (remote_compilation_helper-gof) to provide rich, contextual error messages.\n\n## Goals\n\n1. Standardize error codes (rch::category::specific)\n2. Add remediation hints (commands to run)\n3. Include linkable docs where helpful (OSC-8 hyperlinks)\n4. Support JSON error details\n5. Show source context for config/code errors\n\n## Error Categories\n\n| Category | Code Prefix | Examples |\n|----------|-------------|----------|\n| Config | rch::config | invalid_toml, missing_field, permission |\n| Worker | rch::worker | connection_failed, unhealthy, timeout |\n| Daemon | rch::daemon | not_running, port_in_use, startup_failed |\n| Transfer | rch::transfer | rsync_failed, ssh_auth, permission |\n| Hook | rch::hook | classify_failed, parse_error |\n\n## Error Message Format\n\n### Human Output\n```\nError: rch::worker::connection_failed\n\n  × Connection to gpu-worker failed\n   ╭────\n   │ Could not establish SSH connection to build@192.168.1.100:22\n   │ Reason: Permission denied (publickey)\n   ╰────\n  help: Verify SSH access with:\n        ssh -i ~/.ssh/rch_key build@192.168.1.100\n\n  docs: https://rch.dev/docs/troubleshooting#ssh-connection\n```\n\n### JSON Output\n```json\n{\n  \"error\": {\n    \"code\": \"rch::worker::connection_failed\",\n    \"message\": \"Connection to gpu-worker failed\",\n    \"details\": {\n      \"worker_id\": \"gpu-worker\",\n      \"host\": \"192.168.1.100\",\n      \"user\": \"build\",\n      \"reason\": \"Permission denied (publickey)\"\n    },\n    \"suggestions\": [\n      \"ssh -i ~/.ssh/rch_key build@192.168.1.100\"\n    ],\n    \"docs_url\": \"https://rch.dev/docs/troubleshooting#ssh-connection\"\n  }\n}\n```\n\n## Implementation\n\n### Error Type Design\n\n```rust\nuse miette::{Diagnostic, SourceSpan};\nuse thiserror::Error;\n\n#[derive(Error, Diagnostic, Debug)]\n#[error(\"Connection to {worker_id} failed\")]\n#[diagnostic(\n    code(rch::worker::connection_failed),\n    help(\"Verify SSH access with: ssh -i {identity_file} {user}@{host}\"),\n    url(\"https://rch.dev/docs/troubleshooting#ssh-connection\")\n)]\npub struct ConnectionError {\n    pub worker_id: String,\n    pub host: String,\n    pub user: String,\n    pub identity_file: String,\n    #[source]\n    pub source: std::io::Error,\n}\n```\n\n### Error to JSON Conversion\n\n```rust\nimpl From\u003c\u0026dyn Diagnostic\u003e for JsonError {\n    fn from(diag: \u0026dyn Diagnostic) -\u003e Self {\n        JsonError {\n            code: diag.code().map(|c| c.to_string()),\n            message: diag.to_string(),\n            help: diag.help().map(|h| h.to_string()),\n            url: diag.url().map(|u| u.to_string()),\n        }\n    }\n}\n```\n\n### Common Error Patterns\n\n```rust\n// Daemon not running\n#[derive(Error, Diagnostic, Debug)]\n#[error(\"Daemon is not running\")]\n#[diagnostic(\n    code(rch::daemon::not_running),\n    help(\"Start the daemon with: rch daemon start\")\n)]\npub struct DaemonNotRunning;\n\n// Config parse error with source context\n#[derive(Error, Diagnostic, Debug)]\n#[error(\"Invalid configuration\")]\n#[diagnostic(code(rch::config::invalid))]\npub struct ConfigError {\n    #[source_code]\n    pub src: miette::NamedSource\u003cString\u003e,\n    #[label(\"error here\")]\n    pub span: SourceSpan,\n    #[help]\n    pub help: String,\n}\n\n// Worker timeout\n#[derive(Error, Diagnostic, Debug)]\n#[error(\"Worker {worker_id} timed out after {timeout_secs}s\")]\n#[diagnostic(\n    code(rch::worker::timeout),\n    help(\"Check worker connectivity: rch workers probe {worker_id}\")\n)]\npub struct WorkerTimeout {\n    pub worker_id: String,\n    pub timeout_secs: u64,\n}\n```\n\n## Terminal Hyperlinks (OSC-8)\n\nWhen terminal supports OSC-8 hyperlinks:\n\n```rust\nfn format_help_link(url: \u0026str, text: \u0026str) -\u003e String {\n    if supports_hyperlinks() {\n        format!(\"\\x1b]8;;{}\\x1b\\\\{}\\x1b]8;;\\x1b\\\\\", url, text)\n    } else {\n        format!(\"{} ({})\", text, url)\n    }\n}\n```\n\n## Tests\n\n- Unit: error to JSON mapping preserves all fields\n- Unit: miette formatting includes all diagnostics\n- Integration: sample failures produce expected hints\n- E2E: simulate daemon missing, worker unreachable, config errors\n\n## Acceptance Criteria\n\n- [ ] All public errors have error codes\n- [ ] Errors include actionable suggestions\n- [ ] Config errors show source context\n- [ ] JSON errors include code + message + suggestions\n- [ ] Help URLs use OSC-8 when supported\n- [ ] Non-TTY output omits ANSI codes\n\n## Dependencies\n\n- miette integration (remote_compilation_helper-gof)\n- JSON output (remote_compilation_helper-b9p)\n- Terminal hyperlinks (remote_compilation_helper-20k)\n\n## Logging\n\n- E2E logs should include the exact error message + suggestions emitted for each simulated failure.\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:36:33.103970136-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.373792167-05:00","dependencies":[{"issue_id":"remote_compilation_helper-alo","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T11:59:05.809708699-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-alo","depends_on_id":"remote_compilation_helper-gof","type":"blocks","created_at":"2026-01-16T15:14:44.080449159-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ayn","title":"Epic: Automatic Toolchain Version Synchronization","description":"## Overview\n\nImplement automatic Rust toolchain synchronization between local machine and remote workers to eliminate version mismatch failures. This epic covers detection, transport, worker verification, caching, and robust testing.\n\n## Goals\n\n1. Detect local toolchain (channel/date/version)\n2. Send toolchain info through daemon protocol\n3. Ensure worker has toolchain (install if missing)\n4. Execute remote commands with matching toolchain\n5. Cache toolchain availability to avoid repeated checks\n6. Fail‑open to local execution if sync fails\n\n## Sub‑Beads\n\n- Protocol + transfer support (remote_compilation_helper-o9s)\n- Worker toolchain verification + install (remote_compilation_helper-0lo)\n- Test coverage and E2E (remote_compilation_helper-mio)\n\n## Testing Requirements\n\n- Unit: toolchain detection + formatting\n- Integration: mock worker install flow\n- E2E: toolchain sync with mock SSH + failure injection\n\n## Acceptance Criteria\n\n- Worker uses exact toolchain as local\n- Mismatch errors eliminated or surfaced with clear message\n- Failures fall back to local\n- Tests cover success + failure paths\n\n## Dependencies\n\n- Local fallback epic (remote_compilation_helper-ne8)\n\n## Logging\n\n- E2E logs must include local toolchain detection, worker toolchain ensure/install path, and any fall‑open decisions.\n","status":"open","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:05:27.660369027-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.41639328-05:00","dependencies":[{"issue_id":"remote_compilation_helper-ayn","depends_on_id":"remote_compilation_helper-ne8","type":"blocks","created_at":"2026-01-16T12:14:51.379924298-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-b9p","title":"Add --json output flag for machine-readable output","description":"## Overview\n\nAdd a global `--json` output mode with a consistent envelope, explicit error codes, and optional progress events. This must cover all CLI commands and be stable for scripting.\n\n## Goals\n\n1. Global `--json` flag\n2. Envelope: version, command, success, data, error\n3. Structured error codes + suggestions\n4. Optional progress events for long operations\n5. Preserve exit code semantics\n\n## JSON Envelope\n\n```json\n{\n  \"version\": \"1\",\n  \"command\": \"status\",\n  \"success\": true,\n  \"data\": { ... },\n  \"error\": null\n}\n```\n\n## Error Object\n\n```json\n{\n  \"code\": \"WORKER_UNREACHABLE\",\n  \"message\": \"Could not connect to worker\",\n  \"details\": { \"worker_id\": \"gpu-1\" },\n  \"suggestions\": [\"Check SSH connectivity\", \"Run: rch doctor\"]\n}\n```\n\n## Progress Events (Optional)\n\nWhen `--json` and long operations occur (sync, install, probe):\n\n```json\n{\"event\":\"progress\",\"phase\":\"sync\",\"percent\":42}\n```\n\nThese should be line‑delimited JSON to remain stream‑friendly.\n\n## Tests\n\n- Unit: envelope serialization\n- Unit: error serialization\n- Integration: each command returns valid JSON\n- Integration: progress events are valid JSON lines\n- E2E: `jq` validates all outputs\n\n## Acceptance Criteria\n\n- All commands support `--json`\n- Errors have consistent codes\n- Progress events optional and well‑formed\n\n## Dependencies\n\n- Output abstraction layer (remote_compilation_helper-u0v)\n\n## Logging\n\n- E2E logs should print JSON validation results and any schema mismatches.\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:37:03.672228669-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.456684194-05:00","dependencies":[{"issue_id":"remote_compilation_helper-b9p","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T11:59:35.192422114-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-bcl","title":"Add GitHub Actions CI workflow for cross-platform testing","description":"## Overview\n\nAdd comprehensive GitHub Actions CI with quality gates, security scanning, cross-platform testing, and detailed logging. This is a prerequisite for automated releases.\n\n## Goals\n\n1. Linux + macOS + Windows test matrix\n2. Security scanning (cargo-audit, dependency review)\n3. Full quality gates: check, clippy, fmt, test\n4. E2E tests with RCH_MOCK_SSH=1\n5. Build release artifacts for all supported targets\n6. Coverage reporting with codecov\n7. MSRV (Minimum Supported Rust Version) verification\n8. Artifact upload on failure for debugging\n\n## Workflow Structure\n\n### Trigger Events\n```yaml\non:\n  push:\n    branches: [master, main]\n  pull_request:\n    branches: [master, main]\n  schedule:\n    - cron: '0 6 * * 1'  # Weekly security scan\n```\n\n### Jobs\n\n#### 1. check (fastest feedback)\n- cargo check --all-targets --all-features\n- Runs on: ubuntu-latest\n- Purpose: Fast syntax and type checking\n\n#### 2. fmt\n- cargo fmt --all -- --check\n- Runs on: ubuntu-latest\n- Purpose: Ensure consistent formatting\n\n#### 3. clippy\n- cargo clippy --all-targets --all-features -- -D warnings\n- Runs on: ubuntu-latest\n- Purpose: Lint checks with strict warnings\n\n#### 4. security\n- cargo audit\n- cargo deny check\n- Runs on: ubuntu-latest\n- Purpose: Dependency vulnerability scanning\n\n#### 5. test (matrix)\n- cargo test --all-features --workspace\n- Matrix: ubuntu-latest, macos-latest, windows-latest\n- Rust: stable, nightly, MSRV (1.75.0)\n- Purpose: Cross-platform correctness\n\n#### 6. e2e\n- RCH_MOCK_SSH=1 ./scripts/e2e_test.sh\n- Runs on: ubuntu-latest\n- Upload logs as artifacts on failure\n- Purpose: Integration testing\n\n#### 7. coverage\n- cargo llvm-cov --all-features --workspace --lcov --output-path lcov.info\n- Upload to codecov\n- Purpose: Track test coverage\n\n#### 8. build-release\n- Build release binaries for all targets\n- Upload as artifacts\n- Purpose: Verify release builds work\n\n## Target Matrix\n\n```yaml\ntargets:\n  - x86_64-unknown-linux-gnu\n  - x86_64-unknown-linux-musl\n  - aarch64-unknown-linux-gnu\n  - x86_64-apple-darwin\n  - aarch64-apple-darwin\n  - x86_64-pc-windows-msvc\n```\n\n## Caching Strategy\n\n```yaml\n- uses: Swatinem/rust-cache@v2\n  with:\n    cache-on-failure: true\n    shared-key: ${{ matrix.os }}-${{ matrix.rust }}\n```\n\n## Implementation Files\n\n```\n.github/\n├── workflows/\n│   ├── ci.yml              # Main CI workflow\n│   ├── release.yml         # Release workflow (cargo-dist)\n│   └── security.yml        # Weekly security scan\n├── dependabot.yml          # Automated dependency updates\n└── CODEOWNERS              # Review requirements\n```\n\n## Workflow YAML (ci.yml)\n\n```yaml\nname: CI\n\non:\n  push:\n    branches: [master, main]\n  pull_request:\n  schedule:\n    - cron: '0 6 * * 1'\n\nenv:\n  CARGO_TERM_COLOR: always\n  RUST_BACKTRACE: 1\n\njobs:\n  check:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@stable\n      - uses: Swatinem/rust-cache@v2\n      - run: cargo check --all-targets --all-features\n\n  fmt:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@nightly\n        with:\n          components: rustfmt\n      - run: cargo fmt --all -- --check\n\n  clippy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: clippy\n      - uses: Swatinem/rust-cache@v2\n      - run: cargo clippy --all-targets --all-features -- -D warnings\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: rustsec/audit-check@v2\n        with:\n          token: ${{ secrets.GITHUB_TOKEN }}\n\n  test:\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        rust: [stable, nightly]\n        include:\n          - os: ubuntu-latest\n            rust: '1.75.0'  # MSRV\n    runs-on: ${{ matrix.os }}\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@master\n        with:\n          toolchain: ${{ matrix.rust }}\n      - uses: Swatinem/rust-cache@v2\n      - run: cargo test --all-features --workspace\n      - name: Upload test logs on failure\n        if: failure()\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-logs-${{ matrix.os }}-${{ matrix.rust }}\n          path: |\n            target/debug/deps/*.log\n            **/test-output.log\n\n  e2e:\n    runs-on: ubuntu-latest\n    needs: [check, clippy]\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@stable\n      - uses: Swatinem/rust-cache@v2\n      - name: Build\n        run: cargo build --release\n      - name: Run E2E tests\n        env:\n          RCH_MOCK_SSH: '1'\n          RCH_LOG_LEVEL: debug\n        run: |\n          chmod +x scripts/e2e_test.sh\n          ./scripts/e2e_test.sh 2\u003e\u00261 | tee e2e-output.log\n      - name: Upload E2E logs\n        if: always()\n        uses: actions/upload-artifact@v4\n        with:\n          name: e2e-logs\n          path: e2e-output.log\n\n  coverage:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@stable\n        with:\n          components: llvm-tools-preview\n      - uses: taiki-e/install-action@cargo-llvm-cov\n      - uses: Swatinem/rust-cache@v2\n      - run: cargo llvm-cov --all-features --workspace --lcov --output-path lcov.info\n      - uses: codecov/codecov-action@v4\n        with:\n          files: lcov.info\n          fail_ci_if_error: false\n```\n\n## Testing Requirements\n\n### Unit Tests\n- Workflow syntax validation (actionlint)\n- Job dependency graph correctness\n\n### Integration Tests\n- Push to test branch triggers workflow\n- PR triggers subset of jobs\n- Matrix expands correctly\n\n### E2E Tests\n- Full workflow run completes\n- Artifacts uploaded correctly\n- Coverage reports generated\n\n## Logging Requirements\n\n- Each job logs start time and duration\n- Failure artifacts include full logs\n- E2E test output captured and uploaded\n\n## Success Criteria\n\n- [ ] All jobs pass on clean repo\n- [ ] Clippy/fmt fail PRs on violations\n- [ ] E2E tests run with mock SSH\n- [ ] Coverage reports uploaded to codecov\n- [ ] Security scan runs weekly\n- [ ] MSRV verified (1.75.0)\n- [ ] Windows builds pass\n- [ ] Artifacts uploaded on failure\n\n## Dependencies\n\nNone - this is infrastructure.\n\n## Blocks\n\n- remote_compilation_helper-9zy (Self-Update) - needs release artifacts\n- remote_compilation_helper-gao (cargo-dist) - generates release workflow\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:55:59.396566992-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:25:22.690464563-05:00"}
{"id":"remote_compilation_helper-bqd","title":"Add styled box rendering with borders, padding, and margins","description":"## Overview\nAdd Charm-style styled box rendering with borders, padding, margins, and alignment. Inspired by Lip Gloss (Go), this provides a consistent API for rendering styled content blocks - the foundation for premium CLI output like headers, status displays, and confirmation dialogs.\n\n## Dependencies\n- **BLOCKED BY**: remote_compilation_helper-u0v (UI output abstraction layer)\n- **BLOCKED BY**: remote_compilation_helper-nbo (colors)\n\n**Can be worked in PARALLEL with cmj (status indicators) and alo (errors) after nbo completes.**\n\n## Requirements\n\n### Core Style API (Lip Gloss-Inspired)\n```rust\n// rch/src/ui/style.rs\n\n#[derive(Debug, Clone, Default)]\npub struct Style {\n    // Foreground/Background\n    foreground: Option\u003cColor\u003e,\n    background: Option\u003cColor\u003e,\n\n    // Text modifiers\n    bold: bool,\n    italic: bool,\n    underline: bool,\n    strikethrough: bool,\n    dim: bool,\n\n    // Box model\n    padding: Padding,     // Inner spacing\n    margin: Margin,       // Outer spacing\n    border: Option\u003cBorderStyle\u003e,\n    border_foreground: Option\u003cColor\u003e,\n\n    // Dimensions\n    width: Option\u003cu16\u003e,\n    height: Option\u003cu16\u003e,\n    max_width: Option\u003cu16\u003e,\n    max_height: Option\u003cu16\u003e,\n\n    // Alignment\n    align_horizontal: Align,\n    align_vertical: Align,\n}\n\n#[derive(Debug, Clone, Copy, Default)]\npub enum Align {\n    #[default]\n    Left,\n    Center,\n    Right,\n}\n\n#[derive(Debug, Clone, Copy, Default)]\npub struct Padding {\n    top: u16,\n    right: u16,\n    bottom: u16,\n    left: u16,\n}\n\nimpl Padding {\n    pub fn all(v: u16) -\u003e Self { Self { top: v, right: v, bottom: v, left: v } }\n    pub fn horizontal(h: u16) -\u003e Self { Self { top: 0, right: h, bottom: 0, left: h } }\n    pub fn vertical(v: u16) -\u003e Self { Self { top: v, right: 0, bottom: v, left: 0 } }\n    pub fn new(top: u16, right: u16, bottom: u16, left: u16) -\u003e Self { ... }\n}\n```\n\n### Border Styles\n```rust\n#[derive(Debug, Clone, Copy)]\npub enum BorderStyle {\n    Normal,     // ┌─┐│└─┘\n    Rounded,    // ╭─╮│╰─╯\n    Double,     // ╔═╗║╚═╝\n    Thick,      // ┏━┓┃┗━┛\n    Hidden,     // Padding only, no visible border\n}\n\nimpl BorderStyle {\n    pub fn chars(\u0026self) -\u003e BorderChars {\n        match self {\n            Self::Normal =\u003e BorderChars {\n                top_left: '┌', top: '─', top_right: '┐',\n                left: '│', right: '│',\n                bottom_left: '└', bottom: '─', bottom_right: '┘',\n            },\n            Self::Rounded =\u003e BorderChars {\n                top_left: '╭', top: '─', top_right: '╮',\n                left: '│', right: '│',\n                bottom_left: '╰', bottom: '─', bottom_right: '╯',\n            },\n            Self::Double =\u003e BorderChars {\n                top_left: '╔', top: '═', top_right: '╗',\n                left: '║', right: '║',\n                bottom_left: '╚', bottom: '═', bottom_right: '╝',\n            },\n            Self::Thick =\u003e BorderChars {\n                top_left: '┏', top: '━', top_right: '┓',\n                left: '┃', right: '┃',\n                bottom_left: '┗', bottom: '━', bottom_right: '┛',\n            },\n            Self::Hidden =\u003e BorderChars::empty(),\n        }\n    }\n\n    /// ASCII fallback for non-Unicode terminals\n    pub fn ascii_chars(\u0026self) -\u003e BorderChars {\n        BorderChars {\n            top_left: '+', top: '-', top_right: '+',\n            left: '|', right: '|',\n            bottom_left: '+', bottom: '-', bottom_right: '+',\n        }\n    }\n}\n```\n\n### Builder Pattern API\n```rust\nimpl Style {\n    pub fn new() -\u003e Self { Self::default() }\n\n    // Chaining methods\n    pub fn foreground(mut self, color: impl Into\u003cColor\u003e) -\u003e Self {\n        self.foreground = Some(color.into());\n        self\n    }\n\n    pub fn background(mut self, color: impl Into\u003cColor\u003e) -\u003e Self {\n        self.background = Some(color.into());\n        self\n    }\n\n    pub fn bold(mut self) -\u003e Self {\n        self.bold = true;\n        self\n    }\n\n    pub fn padding(mut self, p: Padding) -\u003e Self {\n        self.padding = p;\n        self\n    }\n\n    pub fn border(mut self, style: BorderStyle) -\u003e Self {\n        self.border = Some(style);\n        self\n    }\n\n    pub fn border_foreground(mut self, color: impl Into\u003cColor\u003e) -\u003e Self {\n        self.border_foreground = Some(color.into());\n        self\n    }\n\n    pub fn width(mut self, w: u16) -\u003e Self {\n        self.width = Some(w);\n        self\n    }\n\n    pub fn align(mut self, h: Align) -\u003e Self {\n        self.align_horizontal = h;\n        self\n    }\n\n    /// Render content with this style applied\n    pub fn render(\u0026self, content: \u0026str, ctx: \u0026OutputContext) -\u003e String {\n        // 1. Apply text styles (bold, colors, etc.)\n        // 2. Apply padding\n        // 3. Apply width constraints (wrap/truncate)\n        // 4. Apply alignment\n        // 5. Apply border\n        // 6. Apply margin\n        render_styled(self, content, ctx)\n    }\n}\n```\n\n### Usage Examples\n\n#### Application Header\n```rust\nlet header_style = Style::new()\n    .border(BorderStyle::Rounded)\n    .border_foreground(Color::Cyan)\n    .padding(Padding::new(0, 2, 0, 2))\n    .foreground(Color::White)\n    .bold();\n\nlet header = header_style.render(\n    \"RCH Configuration Wizard\\nSet up your remote compilation workers.\",\n    ctx\n);\n// Output:\n// ╭─────────────────────────────────────────────╮\n// │  RCH Configuration Wizard                   │\n// │  Set up your remote compilation workers.    │\n// ╰─────────────────────────────────────────────╯\n```\n\n#### Status Box\n```rust\nlet status_style = Style::new()\n    .border(BorderStyle::Normal)\n    .padding(Padding::horizontal(1))\n    .width(50);\n\nlet status = format!(\n    \"Status:     {}\\nSocket:     {}\\nUptime:     {}\",\n    \"Running\".green(),\n    \"/tmp/rch.sock\",\n    \"2h 15m\"\n);\nprintln!(\"{}\", status_style.render(\u0026status, ctx));\n```\n\n#### Error Box\n```rust\nlet error_style = Style::new()\n    .border(BorderStyle::Rounded)\n    .border_foreground(Color::Red)\n    .foreground(Color::Red)\n    .padding(Padding::all(1));\n\nprintln!(\"{}\", error_style.render(\"Error: Connection refused\", ctx));\n// ╭────────────────────────────────╮\n// │                                │\n// │  Error: Connection refused     │\n// │                                │\n// ╰────────────────────────────────╯\n```\n\n#### Confirmation Dialog\n```rust\nlet dialog_style = Style::new()\n    .border(BorderStyle::Double)\n    .border_foreground(Color::Yellow)\n    .padding(Padding::new(1, 2, 1, 2))\n    .width(40)\n    .align(Align::Center);\n\nlet dialog = dialog_style.render(\n    \"Delete all files?\\n\\n[Y]es  [N]o\",\n    ctx\n);\n```\n\n### Layout Utilities\n```rust\n/// Join multiple styled blocks horizontally\npub fn join_horizontal(items: \u0026[\u0026str], align: Align) -\u003e String {\n    // Split each item into lines\n    // Pad to equal height\n    // Join line by line with spacing\n}\n\n/// Join multiple styled blocks vertically\npub fn join_vertical(items: \u0026[\u0026str]) -\u003e String {\n    items.join(\"\\n\")\n}\n\n/// Place content at specific position in a larger canvas\npub fn place(\n    width: u16,\n    height: u16,\n    h_align: Align,\n    v_align: Align,\n    content: \u0026str\n) -\u003e String {\n    // Create canvas of size\n    // Place content at aligned position\n}\n```\n\n### Predefined Styles (Theme)\n```rust\n// rch/src/ui/theme.rs\n\npub struct Theme {\n    pub title: Style,\n    pub subtitle: Style,\n    pub info_box: Style,\n    pub warning_box: Style,\n    pub error_box: Style,\n    pub success_box: Style,\n    pub dialog: Style,\n    pub key_value: Style,\n}\n\nimpl Theme {\n    pub fn default() -\u003e Self {\n        Self {\n            title: Style::new()\n                .foreground(Color::White)\n                .background(Color::Cyan)\n                .bold()\n                .padding(Padding::horizontal(1)),\n\n            info_box: Style::new()\n                .border(BorderStyle::Rounded)\n                .border_foreground(Color::Cyan)\n                .padding(Padding::horizontal(1)),\n\n            warning_box: Style::new()\n                .border(BorderStyle::Rounded)\n                .border_foreground(Color::Yellow)\n                .foreground(Color::Yellow)\n                .padding(Padding::horizontal(1)),\n\n            error_box: Style::new()\n                .border(BorderStyle::Rounded)\n                .border_foreground(Color::Red)\n                .foreground(Color::Red)\n                .padding(Padding::horizontal(1)),\n\n            // ... etc\n        }\n    }\n}\n```\n\n### Files to Modify\n- Create `rch/src/ui/style.rs` - Style struct and builder\n- Create `rch/src/ui/border.rs` - Border rendering\n- Create `rch/src/ui/layout.rs` - Layout utilities (join, place)\n- Create `rch/src/ui/theme.rs` - Predefined styles\n- `rch/src/ui/mod.rs` - Export new modules\n- `rch/src/commands.rs` - Use styled boxes for headers, status displays\n\n## Testing Requirements\n\n### Unit Tests (`rch/src/ui/style.rs`)\n```rust\n#[test]\nfn test_style_builder_chain() {\n    let style = Style::new()\n        .bold()\n        .foreground(Color::Red)\n        .padding(Padding::all(1));\n\n    assert!(style.bold);\n    assert_eq!(style.foreground, Some(Color::Red));\n    assert_eq!(style.padding.top, 1);\n}\n\n#[test]\nfn test_border_rendering() {\n    let style = Style::new()\n        .border(BorderStyle::Rounded)\n        .width(20);\n\n    let ctx = OutputContext::test_human();\n    let output = style.render(\"Hello\", \u0026ctx);\n\n    assert!(output.contains('╭'));\n    assert!(output.contains('╰'));\n}\n\n#[test]\nfn test_ascii_fallback() {\n    let style = Style::new()\n        .border(BorderStyle::Rounded)\n        .width(20);\n\n    let ctx = OutputContext::test_plain(); // No unicode\n    let output = style.render(\"Hello\", \u0026ctx);\n\n    assert!(output.contains('+'));\n    assert!(!output.contains('╭'));\n}\n\n#[test]\nfn test_padding_applied() {\n    let style = Style::new()\n        .padding(Padding::all(1))\n        .width(10);\n\n    let ctx = OutputContext::test_human();\n    let output = style.render(\"Hi\", \u0026ctx);\n    let lines: Vec\u003c_\u003e = output.lines().collect();\n\n    // Should have blank line before and after content\n    assert_eq!(lines.len(), 3);\n    assert!(lines[0].trim().is_empty());\n    assert!(lines[2].trim().is_empty());\n}\n\n#[test]\nfn test_text_alignment() {\n    let style = Style::new()\n        .width(20)\n        .align(Align::Center);\n\n    let ctx = OutputContext::test_human();\n    let output = style.render(\"Hi\", \u0026ctx);\n\n    // \"Hi\" should be centered in 20 chars\n    assert!(output.contains(\"         Hi         \") || output.contains(\"        Hi        \"));\n}\n```\n\n### Integration Tests (`rch/tests/style_integration.rs`)\n```rust\n#[test]\nfn test_themed_output() {\n    let ctx = OutputContext::test_human();\n    let theme = Theme::default();\n\n    let output = theme.error_box.render(\"Error occurred\", \u0026ctx);\n\n    // Should have red border\n    assert!(output.contains(\"\\x1b[31m\")); // Red ANSI\n    // Should have rounded corners\n    assert!(output.contains('╭') || output.contains('+'));\n}\n```\n\n### E2E Test Additions (`scripts/e2e_test.sh`)\n```bash\ntest_styled_boxes() {\n    log \"INFO\" \"STYLE\" \"Testing styled box rendering...\"\n\n    # Test that headers have borders\n    local output\n    output=$(\"$RCH\" status 2\u003e\u00261)\n\n    # Should contain box-drawing characters (or ASCII fallback)\n    if ! echo \"$output\" | grep -qE '[┌╭+]'; then\n        log \"WARN\" \"STYLE\" \"No border characters found (may be piped mode)\"\n    fi\n\n    log \"INFO\" \"STYLE\" \"Styled box test OK\"\n}\n```\n\n## Acceptance Criteria\n- [ ] Style struct with builder pattern implemented\n- [ ] All border styles render correctly (Normal, Rounded, Double, Thick)\n- [ ] ASCII fallback for non-Unicode terminals\n- [ ] Padding (all sides) works correctly\n- [ ] Width constraints with wrapping/truncation\n- [ ] Text alignment (left, center, right)\n- [ ] Layout utilities (join_horizontal, join_vertical, place)\n- [ ] Predefined theme with common styles\n- [ ] Unit tests for all style features\n- [ ] Integration tests verify visual output\n- [ ] Applied to at least: status command header, config wizard, error display\n\n## Logging\n\n- E2E logs should include rendered box outputs in both Unicode and ASCII modes for snapshot comparison.\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:24:51.226082167-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.496320965-05:00","labels":["ux"],"dependencies":[{"issue_id":"remote_compilation_helper-bqd","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T12:27:13.314945096-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-bqd","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T12:27:13.370418609-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-brr","title":"Fleet Worker Deployment Command","description":"## Overview\n\nAdd `rch install --fleet` to deploy or update the worker agent on all configured workers in parallel. This should be idempotent, resumable, and provide clear per‑worker status.\n\n## Goals\n\n1. Single command deploys to all workers\n2. Parallelism with configurable concurrency\n3. Verify prerequisites (rsync, zstd, rustup)\n4. Install or update rch‑wkr + dependencies\n5. Post‑install health verification\n6. Resume failed workers without redoing successful ones\n\n## CLI Interface\n\n```\nrch install --fleet [OPTIONS]\n\nOPTIONS:\n  --worker \u003cID\u003e      Target a single worker\n  --parallel \u003cN\u003e     Max parallel deployments (default: 4)\n  --no-toolchain     Skip rustup/toolchain checks\n  --force            Reinstall even if version matches\n  --verify           Run post‑install verification\n  --dry-run          Show actions without changes\n```\n\n## Deployment Steps (Per Worker)\n\n1. Preflight (SSH, disk, tools)\n2. Version check (skip if up‑to‑date)\n3. Transfer (rsync/scp)\n4. Install (permissions + path)\n5. Toolchain sync (optional)\n6. Verify (health + info)\n\n## Resumability\n\n- Local deployment report (JSON)\n- `--resume` retries only failed workers\n\n## Tests\n\n- Unit: deployment plan generation\n- Integration: mock SSH deployment with success/fail mix\n- E2E: `RCH_MOCK_SSH=1` fleet install logs per worker\n\n## Logging\n\n- Log per‑worker steps with timestamps\n- Summary report at end with success/fail/skip counts\n\n## Acceptance Criteria\n\n- `rch install --fleet` works with parallel workers\n- Skips already‑up‑to‑date workers unless `--force`\n- Reports per‑worker status (success/fail/skip)\n- JSON output for automation\n\n## Dependencies\n\n- Progress indicators (remote_compilation_helper-5te)\n- Toolchain sync epic (remote_compilation_helper-ayn)\n\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:55:28.882381156-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:10:08.843376963-05:00","dependencies":[{"issue_id":"remote_compilation_helper-brr","depends_on_id":"remote_compilation_helper-9zy","type":"blocks","created_at":"2026-01-16T15:22:41.304818337-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-btf","title":"Add interactive config initialization wizard","description":"## Overview\n\nAdd an interactive config initialization wizard focused on generating `~/.config/rch/config.toml` and `workers.toml`. This is a lighter‑weight companion to the full setup wizard and can be invoked standalone or as a step inside `rch setup`.\n\n## Goals\n\n1. Interactive prompts for common config settings\n2. Safe defaults + validation\n3. Idempotent file creation (no overwrite without confirmation)\n4. Can run in non‑interactive mode with flags\n\n## CLI Interface\n\n```\nrch config init --wizard\nrch config init --wizard --non-interactive\nrch config init --wizard --defaults\n```\n\n## Implementation\n\n- Use `dialoguer` or `inquire`\n- Validate input (paths, ints, bools)\n- Write TOML with comments\n- If files exist, prompt to merge or skip\n\n## Tests\n\n- Unit: config generation with defaults\n- Integration: wizard in mock mode (non‑interactive)\n- E2E: config init in scripts/e2e_test.sh\n\n## Acceptance Criteria\n\n- Wizard produces valid config files\n- Safe idempotent behavior\n- Works with `--non-interactive`\n\n## Dependencies\n\n- Idempotent setup (remote_compilation_helper-0dl)\n\n## Logging\n\n- E2E logs should include wizard step names, chosen defaults, and output file paths.\n","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:37:17.463952233-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.533285074-05:00","dependencies":[{"issue_id":"remote_compilation_helper-btf","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T12:02:43.264255984-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-btf","depends_on_id":"remote_compilation_helper-cmj","type":"blocks","created_at":"2026-01-16T12:02:43.359005211-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ceb","title":"Bug: Daemon health checks don't respect RCH_MOCK_SSH mode","description":"When RCH_MOCK_SSH=1 is set, the daemon's health check still tries to make real SSH connections, causing mock workers to be marked unhealthy. This breaks E2E tests in mock mode. Fix: Daemon should check RCH_MOCK_SSH and skip real health checks, marking workers as healthy in mock mode.","status":"closed","priority":1,"issue_type":"bug","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:21:31.483079134-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T11:27:52.958905075-05:00","closed_at":"2026-01-16T11:27:52.958905075-05:00","close_reason":"Added debug logging to health check. Issue was that the daemon binary hadn't been rebuilt after mock mode implementation changes. E2E tests now pass consistently."}
{"id":"remote_compilation_helper-cmj","title":"Standardize status indicators (✓/✗/⚠) across all commands","description":"## Overview\nStandardize status indicator symbols and their meanings across ALL commands. Ensure visual consistency and immediate recognizability.\n\n## Dependencies\n- **BLOCKED BY**: remote_compilation_helper-nbo (colors) - indicators need color support\n\n## Requirements\n\n### Standard Status Indicators\nDefine enum in ui.rs:\n```rust\npub enum StatusIndicator {\n    Success,    // ✓ (green) - operation succeeded, healthy state\n    Error,      // ✗ (red) - operation failed, error state\n    Warning,    // ⚠ (yellow) - degraded, needs attention\n    Info,       // ● (cyan) - neutral information\n    Pending,    // ○ (gray) - waiting, not started\n    InProgress, // ◐ (blue) - currently running\n    Disabled,   // ⊘ (gray) - intentionally disabled\n}\n```\n\n### Application Mapping\n\n| Context | Current | Should Be |\n|---------|---------|-----------|\n| Worker healthy | \"OK\" or \"✓\" | ✓ (green) |\n| Worker unreachable | \"✗\" | ✗ (red) |\n| Worker degraded | varies | ⚠ (yellow) |\n| Worker disabled | plain text | ⊘ (gray) |\n| Daemon running | \"Status: Running\" | ✓ Running (green) |\n| Daemon stopped | \"Status: Not running\" | ✗ Stopped (red) |\n| Config valid | \"✓\" | ✓ Valid (green) |\n| Config warning | \"⚠\" | ⚠ with explanation (yellow) |\n| Config error | \"✗\" | ✗ with explanation (red) |\n| Hook installed | plain text | ✓ Installed (green) |\n| Hook not installed | plain text | ○ Not installed (gray) |\n| Probe success | \"✓ OK (100ms)\" | ✓ 100ms (green) |\n| Probe failed | \"✗ Error: ...\" | ✗ Error message (red) |\n\n### Implementation\n1. Create `StatusIndicator::display(\u0026self, mode: OutputMode) -\u003e String` method\n2. Update ALL status displays in commands.rs to use StatusIndicator\n3. Ensure consistent spacing after indicators\n\n### Files to Modify\n- `rch/src/ui.rs` - add StatusIndicator enum and display logic\n- `rch/src/commands.rs` - update all status displays (lines 176, 179, 182, 188, 228, 231, 234, 240, 312-327, 629-687, 696-703, 873-908)\n\n## Testing Requirements\n\n### Unit Tests\n- Test each StatusIndicator produces correct symbol and color\n- Test Plain mode produces symbols without ANSI codes\n- Test JSON mode produces structured status\n\n### Integration Tests\n- Snapshot tests for status command output\n- Verify all status displays use the standard indicators\n\n### E2E Test Additions\n```bash\n# Scenario: status_indicators\n# Verify consistent indicators across commands\nrun_scenario \"status_consistency\" \"verify\" \"\"\n```\n\n## Acceptance Criteria\n- [ ] All commands use StatusIndicator enum\n- [ ] No hardcoded status symbols remain in commands.rs\n- [ ] Visual consistency verified across all commands\n- [ ] Unit tests cover all indicator types\n- [ ] Snapshot tests capture expected output format","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:36:34.370314322-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T13:35:06.364526809-05:00","closed_at":"2026-01-16T13:35:06.364526809-05:00","close_reason":"StatusIndicator enum implemented and all commands updated to use it consistently","dependencies":[{"issue_id":"remote_compilation_helper-cmj","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T11:58:14.488091447-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5","title":"RCH Core TODOs Master Plan (Hook + WorkerPool + CLI + Tests)","description":"Background\n- RCH is a transparent compilation offloading system; the hook must be fast, precise, and fail-open.\n- The current codebase has core scaffolding; this plan captures the remaining high-leverage TODOs in a self-contained way.\n\nScope\n- Hook integration (classification → daemon → transfer pipeline → artifacts)\n- WorkerPool correctness (counting, status, health recovery)\n- rch CLI commands (daemon/workers/status/config/hook) with clear UX\n- Comprehensive tests (unit/integration/e2e) + detailed logging\n\nNon-Goals\n- New features beyond the above TODOs (e.g., UI, metrics, autoscaling)\n\nPrinciples\n- Fail-open: errors in remote pipeline must allow local execution.\n- Precision over recall for classification; correctness over cleverness.\n- Observability: log enough to debug without overwhelming normal output.","design":"This master epic decomposes three top TODO areas into actionable, dependency-aware tasks, plus a testing epic. The structure allows parallel work while preserving ordering constraints (e.g., CLI tests depend on CLI implementations). Each task includes background, goal, and acceptance to minimize future ambiguity.","acceptance_criteria":"- All child epics are created, linked, and contain granular tasks with dependencies.\n- Each task contains enough context to implement without re-reading the long plan document.\n- Test tasks explicitly cover unit, integration, and e2e with logging expectations.","notes":"If any task is already implemented in HEAD, verify by code inspection + tests, then close with a note referencing evidence.","status":"closed","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.056378843-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T10:42:09.690778309-05:00","closed_at":"2026-01-16T10:42:09.690778309-05:00","close_reason":"All child epics completed: Hook pipeline, WorkerPool, CLI commands, and Testing/E2E coverage"}
{"id":"remote_compilation_helper-ei5.1","title":"Hook: Remote Execution Pipeline","description":"Purpose\n- Complete the hook execution flow end-to-end: classify → select worker → transfer → remote exec → artifact return.\n- Enforce fail-open semantics and avoid double-execution.\n\nKey Risks\n- Latency regressions in hook path.\n- Incorrect deny/allow decisions causing duplicate execution or blocked commands.\n- Artifact return correctness for Rust targets.","design":"Hook must remain a thin orchestrator; state lives in daemon or transfer pipeline. Prefer small helpers and explicit error handling. Keep stdout semantics aligned with Claude Code hook expectations (empty output = allow).","acceptance_criteria":"- Hook pipeline is fully functional with remote execution and artifact retrieval.\n- Fail-open behavior is preserved when any remote stage fails.\n- Unit + integration tests exist for the hook pipeline.","notes":"If remote pipeline already exists in HEAD, verify all stages (sync/exec/artifacts) and ensure tests cover failure modes.","status":"closed","priority":1,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.131789506-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:40:07.874951999-05:00","closed_at":"2026-01-16T09:40:07.874951999-05:00","close_reason":"All child tasks complete: TransferPipeline integration, config application, protocol-safe output, and tests","dependencies":[{"issue_id":"remote_compilation_helper-ei5.1","depends_on_id":"remote_compilation_helper-ei5","type":"parent-child","created_at":"2026-01-16T09:13:18.133611567-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.1.1","title":"Hook: integrate TransferPipeline for remote compilation","description":"Background\n- Hook currently classifies commands and selects a worker. It must then orchestrate transfer, remote exec, and artifact return.\n\nGoals\n- Wire TransferPipeline into hook flow (sync → exec → artifacts).\n- Preserve fail-open if any stage errors.\n- Stream remote stdout/stderr to the agent (stderr preferred).\n\nImplementation Notes\n- Use `TransferPipeline::new`, `sync_to_remote`, `execute_remote_streaming`, `retrieve_artifacts`.\n- Deny local execution after successful remote run to avoid double compile.\n- Ensure exit codes propagate meaningfully to hook output.","design":"Keep hook code minimal; pipeline complexity stays in transfer module. Ensure minimal allocations and avoid blocking operations in the hook.","acceptance_criteria":"- Remote compilation is executed for classified commands.\n- Artifacts returned into local target/.\n- Any pipeline failure results in allow/local execution.\n- Streaming output visible to agent during remote execution.","notes":"Verified in rch/src/hook.rs that TransferPipeline is integrated: execute_remote_compilation builds pipeline, runs sync_to_remote, execute_remote_streaming, and retrieve_artifacts with fail-open handling.","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.441152283-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:17:09.135510493-05:00","closed_at":"2026-01-16T09:17:09.135510493-05:00","close_reason":"Implemented in rch/src/hook.rs (TransferPipeline wired end-to-end)","dependencies":[{"issue_id":"remote_compilation_helper-ei5.1.1","depends_on_id":"remote_compilation_helper-ei5.1","type":"parent-child","created_at":"2026-01-16T09:13:18.442637219-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.1.2","title":"Hook: apply config (threshold, socket path, transfer settings)","description":"Background\n- Hook has hardcoded confidence threshold and socket path.\n\nGoals\n- Load RchConfig (user + project + env overrides).\n- Apply confidence threshold, socket path, and transfer settings.\n- Respect global enable/disable flags.\n\nConsiderations\n- Config loading must be fast; cache if necessary.\n- If config parsing fails, fail-open to local execution.","design":"Prefer a single `load_config()` call per hook invocation; avoid repeated filesystem reads where possible.","acceptance_criteria":"- Hook uses config values for threshold and socket path.\n- Config errors are non-fatal and lead to allow/local execution.\n- Unit tests cover env overrides and project config precedence.","notes":"Implemented config usage in rch/src/hook.rs: load_config with fail-open on error, check general.enabled, use compilation.confidence_threshold, use general.socket_path for daemon query, and pass transfer settings into TransferPipeline.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.523018409-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:21:39.388184953-05:00","closed_at":"2026-01-16T09:21:39.388184953-05:00","close_reason":"Hook now loads config for threshold/socket/transfer with fail-open","dependencies":[{"issue_id":"remote_compilation_helper-ei5.1.2","depends_on_id":"remote_compilation_helper-ei5.1","type":"parent-child","created_at":"2026-01-16T09:13:18.524698803-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.1.2","depends_on_id":"remote_compilation_helper-ei5.1.1","type":"blocks","created_at":"2026-01-16T09:13:19.277779164-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.1.3","title":"Hook: enforce protocol-safe output + streaming behavior","description":"Background\n- Claude Code hook protocol expects empty stdout to allow; JSON output to deny.\n\nGoals\n- Ensure hook outputs are correct and consistent for success/failure.\n- Include clear deny reasons when remote compilation is used.\n- Avoid noisy output to stdout in allow path.\n\nConsiderations\n- Streaming should go to stderr; stdout reserved for hook response.","design":"Treat stdout as control channel; stderr as data channel.","acceptance_criteria":"- Allow path produces empty stdout.\n- Deny path includes JSON with clear reason.\n- Streaming output uses stderr only.","notes":"Verified in rch/src/hook.rs: allow path emits no stdout; deny path emits JSON only. execute_remote_compilation streams both stdout/stderr via eprintln (stderr), keeping stdout reserved for hook protocol.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.608172004-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:17:50.036604733-05:00","closed_at":"2026-01-16T09:17:50.036604733-05:00","close_reason":"Hook output/streaming behavior already protocol-safe","dependencies":[{"issue_id":"remote_compilation_helper-ei5.1.3","depends_on_id":"remote_compilation_helper-ei5.1","type":"parent-child","created_at":"2026-01-16T09:13:18.609561079-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.1.3","depends_on_id":"remote_compilation_helper-ei5.1.1","type":"blocks","created_at":"2026-01-16T09:13:19.321808261-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.1.4","title":"Hook: unit + integration tests (mocked pipeline)","description":"Background\n- Hook logic should be testable without real SSH workers.\n\nGoals\n- Add unit tests for hook decision paths.\n- Add integration test for daemon socket request/response (mock server).\n- Add mock pipeline for transfer/ssh to validate sequencing.\n\nLogging\n- Tests should emit clear phase logs for debug (sync/exec/artifacts).","design":"Prefer deterministic mocks; avoid real network/rsync in unit tests.","acceptance_criteria":"- Unit tests cover classification allow/deny and config thresholds.\n- Integration tests validate daemon request parsing and response handling.\n- Mocked pipeline verifies proper sequencing and fail-open behavior.","notes":"Align test logs with e2e script logs to simplify troubleshooting.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.689802807-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:39:50.673405109-05:00","closed_at":"2026-01-16T09:39:50.673405109-05:00","close_reason":"Hook unit and integration tests added covering classification, daemon communication, and fail-open behavior","dependencies":[{"issue_id":"remote_compilation_helper-ei5.1.4","depends_on_id":"remote_compilation_helper-ei5.1","type":"parent-child","created_at":"2026-01-16T09:13:18.690998939-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.1.4","depends_on_id":"remote_compilation_helper-ei5.1.1","type":"blocks","created_at":"2026-01-16T09:13:19.363360404-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.1.4","depends_on_id":"remote_compilation_helper-ei5.1.2","type":"blocks","created_at":"2026-01-16T09:13:19.403126415-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.2","title":"WorkerPool: Correctness \u0026 Health","description":"Purpose\n- Ensure WorkerPool accounting and status mutation are correct and thread-safe.\n- Health monitor should allow unreachable workers to recover.\n\nKey Risks\n- Incorrect availability leading to overcommit or starvation.\n- Workers stuck in unreachable state forever.","design":"Use interior mutability (RwLock or atomics) for status; avoid blocking slow paths. Health should poll all workers to allow recovery.","acceptance_criteria":"- WorkerPool length reflects actual workers.\n- Worker status can be updated safely; health monitor checks all workers.\n- Tests validate status transitions and selection behavior.","notes":"If fixes are already merged, ensure tests capture the regressions that prompted the fixes.","status":"closed","priority":2,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.203900478-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:32:01.725935525-05:00","closed_at":"2026-01-16T09:32:01.725935525-05:00","close_reason":"All child tasks completed: WorkerPool length accounting (ei5.2.1), status mutation + health recovery (ei5.2.2), and selection tests (ei5.2.3). All 26 rchd tests pass.","dependencies":[{"issue_id":"remote_compilation_helper-ei5.2","depends_on_id":"remote_compilation_helper-ei5","type":"parent-child","created_at":"2026-01-16T09:13:18.205775207-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.2.1","title":"WorkerPool: accurate length accounting","description":"Background\n- WorkerPool must report actual worker count and be safe for concurrent access.\n\nGoals\n- Implement accurate len() using AtomicUsize or async lock-based length.\n- Ensure add/remove paths keep count correct.\n\nConsiderations\n- Keep read access fast (no full lock unless necessary).","design":"If using atomic counters, ensure increments happen only when inserting a new worker.","acceptance_criteria":"- len() reflects real worker count.\n- Tests demonstrate len() increments on add and remains stable.","notes":"Verified in rchd/src/workers.rs: WorkerPool tracks worker_count via AtomicUsize, incremented on insert; len() reads worker_count; all_workers() exists for health monitoring.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.757207118-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:17:16.658002273-05:00","closed_at":"2026-01-16T09:17:16.658002273-05:00","close_reason":"Worker count tracking implemented in rchd/src/workers.rs","dependencies":[{"issue_id":"remote_compilation_helper-ei5.2.1","depends_on_id":"remote_compilation_helper-ei5.2","type":"parent-child","created_at":"2026-01-16T09:13:18.758765271-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.2.2","title":"WorkerPool: status mutation + health recovery","description":"Background\n- Worker status must be mutable and visible to selection and health systems.\n\nGoals\n- Add interior mutability for status (RwLock or atomics).\n- Health monitor should check all workers (not just healthy) to allow recovery.\n- Ensure selection only uses healthy workers.","design":"Avoid holding locks during long operations; update status after health check completes.","acceptance_criteria":"- set_status updates state safely and is reflected in selection.\n- Health monitor evaluates all workers each interval.\n- Tests cover transition to degraded/unreachable and recovery.","notes":"Verified in rchd/src/workers.rs: WorkerState status uses RwLock with async getters/setters; WorkerPool set_status updates state. rchd/src/health.rs checks all_workers each interval, enabling recovery from unreachable.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.825333559-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:17:42.473822962-05:00","closed_at":"2026-01-16T09:17:42.473822962-05:00","close_reason":"Status mutability + health recovery implemented","dependencies":[{"issue_id":"remote_compilation_helper-ei5.2.2","depends_on_id":"remote_compilation_helper-ei5.2","type":"parent-child","created_at":"2026-01-16T09:13:18.827199061-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.2.2","depends_on_id":"remote_compilation_helper-ei5.2.1","type":"blocks","created_at":"2026-01-16T09:13:19.443859928-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.2.3","title":"Worker selection: healthy-only + slot-aware tests","description":"Background\n- Selection must respect worker health and slot availability.\n\nGoals\n- Ensure selection filters unhealthy workers.\n- Validate reservation and release paths via tests.","design":"Keep selection deterministic; prefer explicit weights and clear logs.","acceptance_criteria":"- Selection ignores degraded/unreachable workers.\n- Unit tests validate scoring and filtering behavior.","notes":"If selection already correct, add tests to lock it in.","status":"closed","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.892304494-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:31:41.871695987-05:00","closed_at":"2026-01-16T09:31:41.871695987-05:00","close_reason":"Selection tests exist and pass: test_select_worker_ignores_unhealthy verifies unhealthy workers are filtered, test_select_worker_respects_slot_availability verifies slot availability is respected. All 3 selection tests pass.","dependencies":[{"issue_id":"remote_compilation_helper-ei5.2.3","depends_on_id":"remote_compilation_helper-ei5.2","type":"parent-child","created_at":"2026-01-16T09:13:18.894054418-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.2.3","depends_on_id":"remote_compilation_helper-ei5.2.2","type":"blocks","created_at":"2026-01-16T09:13:19.483083537-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.3","title":"rch CLI: Full Command Implementations","description":"Purpose\n- Implement rch CLI subcommands so operators can manage daemon, workers, config, and hook.\n- Provide clear human-readable output with optional JSON support.\n\nKey Risks\n- Incomplete or misleading output makes debugging difficult.\n- Commands that mutate system state must be explicit and safe.","design":"Keep CLI thin: prefer calling daemon APIs or shared config helpers. Avoid long-running operations in the hook process. Ensure consistent output formatting across commands.","acceptance_criteria":"- All CLI subcommands in rch/main.rs are implemented (no TODO stubs remain).\n- Each command has clear output and error handling.\n- Tests exist for key command paths and input validation.","notes":"There is an in-progress issue for CLI handlers; reparent it under this epic and expand scope/acceptance to cover all subcommands.","status":"closed","priority":2,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.277356722-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:31:16.758359063-05:00","closed_at":"2026-01-16T09:31:16.758359063-05:00","close_reason":"All child tasks completed: CLI subcommand handlers implemented (ei5.3.1), unit+integration tests added (ei5.3.2). All rch CLI commands functional with tests.","dependencies":[{"issue_id":"remote_compilation_helper-ei5.3","depends_on_id":"remote_compilation_helper-ei5","type":"parent-child","created_at":"2026-01-16T09:13:18.278577901-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.3.1","title":"rch CLI: implement all subcommand handlers","description":"Background\n- rch CLI currently stubs most subcommands; operators need full workflow coverage.\n\nGoals\n- Implement daemon, workers, status, config, and hook commands.\n- Provide friendly text output and optional JSON for automation.\n\nConsiderations\n- Commands should surface clear errors (daemon down, config missing, etc.).\n- Use shared config loaders and daemon socket API instead of duplicating logic.","design":"Prefer small helper functions per subcommand; avoid long match arms.","acceptance_criteria":"- All subcommand handlers implemented with real functionality.\n- Commands produce consistent, human-readable output with optional JSON.\n- Validation ensures safe mutations (e.g., hook install/uninstall).","notes":"There is an existing in-progress issue for CLI handlers. Reparent it under this epic and expand its description to cover all subcommands.","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.958970175-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:27:07.244901109-05:00","closed_at":"2026-01-16T09:27:07.244901109-05:00","close_reason":"Implemented all CLI subcommand handlers in rch/src/commands.rs: workers (list/probe/benchmark/drain/enable), daemon (start/stop/restart/status/logs), config (show/init/validate/set), hook (install/uninstall/test), and status commands. All 63 tests pass.","dependencies":[{"issue_id":"remote_compilation_helper-ei5.3.1","depends_on_id":"remote_compilation_helper-ei5.3","type":"parent-child","created_at":"2026-01-16T09:13:18.960204679-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.3.2","title":"rch CLI: unit + integration tests","description":"Background\n- CLI behavior needs tests to avoid regressions.\n\nGoals\n- Unit tests for parsing and validation logic.\n- Integration tests for socket interactions using mock daemon.\n- Golden output tests for `status` and `workers list` output.\n\nLogging\n- Tests should log command args and outputs for debugging.","design":"Use temp dirs for config file tests; avoid touching real user configs.","acceptance_criteria":"- Tests cover at least one path per subcommand.\n- Mock daemon tests validate error handling and JSON parsing.\n- Golden outputs are stable and documented.","notes":"Coordinate with hook tests to reuse mock daemon components.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:19.030320134-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:32:09.72456541-05:00","closed_at":"2026-01-16T09:32:09.72456541-05:00","close_reason":"Added 11 CLI tests covering TOML parsing, config validation, worker config conversion, and command classification","dependencies":[{"issue_id":"remote_compilation_helper-ei5.3.2","depends_on_id":"remote_compilation_helper-ei5.3","type":"parent-child","created_at":"2026-01-16T09:13:19.031842099-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.3.2","depends_on_id":"remote_compilation_helper-ei5.3.1","type":"blocks","created_at":"2026-01-16T09:13:19.528382144-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.4","title":"Testing \u0026 E2E Coverage","description":"Purpose\n- Add comprehensive tests and e2e scripts with logging so pipeline correctness is verifiable.\n- Ensure tests cover failure modes and fail-open behavior.\n\nKey Risks\n- Flaky tests due to network/SSH variability.\n- Insufficient logging makes debugging failures slow.","design":"Prefer deterministic mocks for CI; keep real-worker tests opt-in. Log both structured and human-readable output with timestamps and phases.","acceptance_criteria":"- Unit tests cover classification, selection, transfer pipeline invariants.\n- Integration tests exercise hook ↔ daemon socket and remote pipeline via mocks.\n- E2E scripts provide deterministic, logged runs (real and mock SSH).","notes":"Test tasks depend on core implementation tasks to avoid chasing moving targets.","status":"closed","priority":2,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:18.360432736-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T10:41:59.626013603-05:00","closed_at":"2026-01-16T10:41:59.626013603-05:00","close_reason":"All child tasks completed: test infra, e2e script, integration tests","dependencies":[{"issue_id":"remote_compilation_helper-ei5.4","depends_on_id":"remote_compilation_helper-ei5","type":"parent-child","created_at":"2026-01-16T09:13:18.363214773-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.4.1","title":"Test infra: mock SSH/rsync transport","description":"Background\n- End-to-end tests need a deterministic environment; real SSH is flaky.\n\nGoals\n- Build a mock SSH/rsync layer (env var gated) for tests.\n- Provide detailed logs of each phase (sync, exec, artifacts).","design":"Use environment flags (e.g., RCH_MOCK_SSH=1) to swap transport implementation.","acceptance_criteria":"- Mock layer can simulate success/failure and captures command invocations.\n- Logs include timestamps and phase markers.","notes":"Keep mock behavior simple but explicit; avoid hidden side effects.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:19.097230314-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T10:15:05.617255074-05:00","closed_at":"2026-01-16T10:15:05.617255074-05:00","close_reason":"Closed","dependencies":[{"issue_id":"remote_compilation_helper-ei5.4.1","depends_on_id":"remote_compilation_helper-ei5.4","type":"parent-child","created_at":"2026-01-16T09:13:19.098448057-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.4.1","depends_on_id":"remote_compilation_helper-ei5.1.1","type":"blocks","created_at":"2026-01-16T09:13:19.57061581-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.4.2","title":"E2E: full pipeline script with detailed logging","description":"Background\n- Need reliable end-to-end validation for hook → daemon → worker flow.\n\nGoals\n- Provide scripts: real-worker and mock-SSH runs.\n- Capture logs, timings, and phase outcomes.\n- Validate artifacts exist locally after remote compile.","design":"Keep scripts idempotent and safe; avoid destructive actions.","acceptance_criteria":"- `scripts/e2e_test.sh` supports real and mock modes with clear output.\n- Failure modes (worker down, transfer fail) are exercised.","notes":"Integrate with `RCH_MOCK_SSH=1` to keep CI fast.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:19.16254388-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T11:16:53.752175219-05:00","closed_at":"2026-01-16T11:16:53.752175219-05:00","close_reason":"Closed","dependencies":[{"issue_id":"remote_compilation_helper-ei5.4.2","depends_on_id":"remote_compilation_helper-ei5.4","type":"parent-child","created_at":"2026-01-16T09:13:19.163650823-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.4.2","depends_on_id":"remote_compilation_helper-ei5.4.1","type":"blocks","created_at":"2026-01-16T09:13:19.6535995-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.4.2","depends_on_id":"remote_compilation_helper-ei5.1.1","type":"blocks","created_at":"2026-01-16T09:13:19.692475095-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.4.2","depends_on_id":"remote_compilation_helper-ei5.3.1","type":"blocks","created_at":"2026-01-16T09:13:19.731321424-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ei5.4.3","title":"Integration tests: hook/daemon/transfer sequencing","description":"Background\n- Integration tests ensure components interoperate across crate boundaries.\n\nGoals\n- Tests for daemon socket API parsing and responses.\n- Tests for selection + health interplay.\n- Tests for transfer pipeline sequencing (mocked).","design":"Reuse mock transport from test infra task; avoid duplication.","acceptance_criteria":"- Integration tests run via `cargo test` without needing real SSH.\n- Tests cover fail-open behavior and error propagation.","notes":"Ensure integration tests are deterministic and fast.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T09:13:19.238461577-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T10:15:08.669424347-05:00","closed_at":"2026-01-16T10:15:08.669424347-05:00","close_reason":"Closed","dependencies":[{"issue_id":"remote_compilation_helper-ei5.4.3","depends_on_id":"remote_compilation_helper-ei5.4","type":"parent-child","created_at":"2026-01-16T09:13:19.239940291-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-ei5.4.3","depends_on_id":"remote_compilation_helper-ei5.4.1","type":"blocks","created_at":"2026-01-16T09:13:19.614753431-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-eke","title":"Enhance install.sh with Gum UI, Checksums, and Easy Mode","description":"## Overview\n\nEnhance install.sh to be a modern, polished installer with Gum UI (with ANSI fallback), SHA256 checksum verification, optional signature verification, proxy support, offline mode, uninstall capability, and an \"easy mode\" that configures PATH and runs post-install verification.\n\n## Goals\n\n1. Gum spinners and styled output (with graceful ANSI fallback)\n2. SHA256 checksum verification for all downloads\n3. Optional minisign/Sigstore signature verification\n4. Proxy support (HTTP_PROXY, HTTPS_PROXY, NO_PROXY)\n5. Offline/airgap installation from local tarball\n6. Uninstall functionality\n7. Easy mode: configure PATH, detect agents, run verification\n8. Lock file to prevent concurrent installations\n9. WSL detection and guidance\n10. Comprehensive logging and error messages\n\n## CLI Interface\n\n```bash\n./install.sh [OPTIONS]\n\nOPTIONS:\n  --version \u003cVER\u003e       Install specific version (default: latest)\n  --channel \u003cCHANNEL\u003e   Release channel: stable, beta, nightly\n  --install-dir \u003cDIR\u003e   Installation directory (default: /usr/local/bin)\n  --easy-mode           Configure PATH + detect agents + verify\n  --offline \u003cTARBALL\u003e   Install from local tarball (airgap mode)\n  --verify-only         Verify existing installation\n  --uninstall           Remove RCH binaries and config\n  --no-gum              Disable Gum UI (use ANSI fallback)\n  --no-sig              Skip signature verification\n  --yes                 Skip confirmation prompts\n  --help                Show help message\n\nENVIRONMENT VARIABLES:\n  HTTP_PROXY            HTTP proxy URL\n  HTTPS_PROXY           HTTPS proxy URL\n  NO_PROXY              Comma-separated list of hosts to bypass proxy\n  RCH_INSTALL_DIR       Override default install directory\n  RCH_NO_COLOR          Disable colored output\n```\n\n## Implementation Structure\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\n# ============================================================================\n# Configuration\n# ============================================================================\n\nVERSION=\"${RCH_VERSION:-latest}\"\nCHANNEL=\"${RCH_CHANNEL:-stable}\"\nINSTALL_DIR=\"${RCH_INSTALL_DIR:-/usr/local/bin}\"\nGITHUB_REPO=\"Dicklesworthstone/remote_compilation_helper\"\nGITHUB_API=\"https://api.github.com/repos/${GITHUB_REPO}\"\n\n# ============================================================================\n# Terminal Detection and UI Setup\n# ============================================================================\n\nsetup_ui() {\n    # Detect terminal capabilities\n    if [[ -t 1 ]] \u0026\u0026 [[ -z \"${RCH_NO_COLOR:-}\" ]] \u0026\u0026 [[ \"${TERM:-dumb}\" != \"dumb\" ]]; then\n        USE_COLOR=true\n    else\n        USE_COLOR=false\n    fi\n\n    # Check for Gum\n    if command -v gum \u003e/dev/null 2\u003e\u00261 \u0026\u0026 [[ -z \"${NO_GUM:-}\" ]]; then\n        USE_GUM=true\n    else\n        USE_GUM=false\n    fi\n\n    # ANSI color codes (fallback)\n    if $USE_COLOR; then\n        RED='\\033[0;31m'\n        GREEN='\\033[0;32m'\n        YELLOW='\\033[0;33m'\n        BLUE='\\033[0;34m'\n        BOLD='\\033[1m'\n        RESET='\\033[0m'\n    else\n        RED='' GREEN='' YELLOW='' BLUE='' BOLD='' RESET=''\n    fi\n}\n\n# ============================================================================\n# Output Functions\n# ============================================================================\n\ninfo() {\n    if $USE_GUM; then\n        gum style --foreground 212 \"→ $*\"\n    else\n        echo -e \"${BLUE}→${RESET} $*\"\n    fi\n}\n\nsuccess() {\n    if $USE_GUM; then\n        gum style --foreground 82 \"✓ $*\"\n    else\n        echo -e \"${GREEN}✓${RESET} $*\"\n    fi\n}\n\nwarn() {\n    if $USE_GUM; then\n        gum style --foreground 208 \"⚠ $*\"\n    else\n        echo -e \"${YELLOW}⚠${RESET} $*\" \u003e\u00262\n    fi\n}\n\nerror() {\n    if $USE_GUM; then\n        gum style --foreground 196 \"✗ $*\"\n    else\n        echo -e \"${RED}✗${RESET} $*\" \u003e\u00262\n    fi\n}\n\nspin() {\n    local title=\"$1\"\n    shift\n    if $USE_GUM; then\n        gum spin --spinner dot --title \"$title\" -- \"$@\"\n    else\n        info \"$title\"\n        \"$@\"\n    fi\n}\n\nconfirm() {\n    local prompt=\"$1\"\n    if [[ \"${YES:-}\" == \"true\" ]]; then\n        return 0\n    fi\n    if $USE_GUM; then\n        gum confirm \"$prompt\"\n    else\n        read -rp \"$prompt [y/N] \" response\n        [[ \"$response\" =~ ^[Yy] ]]\n    fi\n}\n\n# ============================================================================\n# Platform Detection\n# ============================================================================\n\ndetect_platform() {\n    local os arch\n\n    case \"$(uname -s)\" in\n        Linux*)  os=\"linux\" ;;\n        Darwin*) os=\"darwin\" ;;\n        MINGW*|MSYS*|CYGWIN*) os=\"windows\" ;;\n        *)       error \"Unsupported OS: $(uname -s)\"; exit 1 ;;\n    esac\n\n    case \"$(uname -m)\" in\n        x86_64|amd64)  arch=\"x86_64\" ;;\n        aarch64|arm64) arch=\"aarch64\" ;;\n        *)             error \"Unsupported architecture: $(uname -m)\"; exit 1 ;;\n    esac\n\n    # WSL detection\n    if [[ \"$os\" == \"linux\" ]] \u0026\u0026 grep -qi microsoft /proc/version 2\u003e/dev/null; then\n        IS_WSL=true\n        warn \"WSL detected. Some features may require additional configuration.\"\n    else\n        IS_WSL=false\n    fi\n\n    TARGET=\"${os}-${arch}\"\n    info \"Detected platform: $TARGET\"\n}\n\n# ============================================================================\n# Version Resolution\n# ============================================================================\n\nresolve_version() {\n    if [[ \"$VERSION\" == \"latest\" ]]; then\n        info \"Fetching latest $CHANNEL release...\"\n        local api_url=\"${GITHUB_API}/releases\"\n\n        if [[ \"$CHANNEL\" == \"stable\" ]]; then\n            api_url=\"${GITHUB_API}/releases/latest\"\n        fi\n\n        VERSION=$(curl -fsSL ${PROXY_ARGS:-} \"$api_url\" | jq -r '\n            if type == \"array\" then\n                [.[] | select(.prerelease == ('$([[ \"$CHANNEL\" != \"stable\" ]] \u0026\u0026 echo \"true\" || echo \"false\")'))] | first | .tag_name\n            else\n                .tag_name\n            end\n        ')\n\n        if [[ -z \"$VERSION\" || \"$VERSION\" == \"null\" ]]; then\n            error \"Failed to determine latest version\"\n            exit 1\n        fi\n    fi\n\n    info \"Installing version: $VERSION\"\n}\n\n# ============================================================================\n# Download and Verification\n# ============================================================================\n\ndownload_release() {\n    local base_url=\"https://github.com/${GITHUB_REPO}/releases/download/${VERSION}\"\n    local tarball=\"rch-${VERSION}-${TARGET}.tar.gz\"\n    local checksum_file=\"checksums.txt\"\n\n    TEMP_DIR=$(mktemp -d)\n    trap 'rm -rf \"$TEMP_DIR\"' EXIT\n\n    # Download tarball\n    spin \"Downloading $tarball...\" \\\n        curl -fsSL ${PROXY_ARGS:-} -o \"$TEMP_DIR/$tarball\" \"$base_url/$tarball\"\n\n    # Download checksums\n    spin \"Downloading checksums...\" \\\n        curl -fsSL ${PROXY_ARGS:-} -o \"$TEMP_DIR/$checksum_file\" \"$base_url/$checksum_file\"\n\n    # Verify checksum\n    verify_checksum \"$TEMP_DIR/$tarball\" \"$TEMP_DIR/$checksum_file\" \"$tarball\"\n\n    # Optional signature verification\n    if [[ \"${NO_SIG:-}\" != \"true\" ]]; then\n        if curl -fsSL ${PROXY_ARGS:-} -o \"$TEMP_DIR/${checksum_file}.sig\" \"$base_url/${checksum_file}.sig\" 2\u003e/dev/null; then\n            verify_signature \"$TEMP_DIR/$checksum_file\" \"$TEMP_DIR/${checksum_file}.sig\"\n        else\n            warn \"Signature file not available, skipping signature verification\"\n        fi\n    fi\n\n    TARBALL_PATH=\"$TEMP_DIR/$tarball\"\n}\n\nverify_checksum() {\n    local file=\"$1\"\n    local checksum_file=\"$2\"\n    local filename=\"$3\"\n\n    info \"Verifying checksum...\"\n\n    local expected\n    expected=$(grep \"$filename\" \"$checksum_file\" | awk '{print $1}')\n\n    if [[ -z \"$expected\" ]]; then\n        error \"Checksum not found for $filename\"\n        exit 1\n    fi\n\n    local computed\n    if command -v sha256sum \u003e/dev/null 2\u003e\u00261; then\n        computed=$(sha256sum \"$file\" | awk '{print $1}')\n    elif command -v shasum \u003e/dev/null 2\u003e\u00261; then\n        computed=$(shasum -a 256 \"$file\" | awk '{print $1}')\n    else\n        error \"No SHA256 tool found (sha256sum or shasum required)\"\n        exit 1\n    fi\n\n    if [[ \"$expected\" != \"$computed\" ]]; then\n        error \"Checksum verification failed!\"\n        error \"  Expected: $expected\"\n        error \"  Got:      $computed\"\n        exit 1\n    fi\n\n    success \"Checksum verified\"\n}\n\nverify_signature() {\n    local file=\"$1\"\n    local sig_file=\"$2\"\n\n    if command -v minisign \u003e/dev/null 2\u003e\u00261; then\n        info \"Verifying signature with minisign...\"\n        # Public key would be embedded or fetched\n        # minisign -Vm \"$file\" -x \"$sig_file\" -P \"$PUBLIC_KEY\"\n        warn \"Signature verification not yet implemented\"\n    else\n        warn \"minisign not installed, skipping signature verification\"\n    fi\n}\n\n# ============================================================================\n# Installation\n# ============================================================================\n\ninstall_binaries() {\n    info \"Installing to $INSTALL_DIR...\"\n\n    # Check permissions\n    if [[ ! -w \"$INSTALL_DIR\" ]]; then\n        if confirm \"Need sudo to install to $INSTALL_DIR. Continue?\"; then\n            SUDO=\"sudo\"\n        else\n            error \"Cannot write to $INSTALL_DIR\"\n            exit 1\n        fi\n    else\n        SUDO=\"\"\n    fi\n\n    # Extract and install\n    spin \"Extracting binaries...\" \\\n        tar -xzf \"$TARBALL_PATH\" -C \"$TEMP_DIR\"\n\n    for binary in rch rchd rch-wkr; do\n        if [[ -f \"$TEMP_DIR/$binary\" ]]; then\n            $SUDO install -m 755 \"$TEMP_DIR/$binary\" \"$INSTALL_DIR/$binary\"\n            success \"Installed $binary\"\n        fi\n    done\n}\n\n# ============================================================================\n# Easy Mode: PATH Configuration\n# ============================================================================\n\nconfigure_path() {\n    if [[ \":$PATH:\" == *\":$INSTALL_DIR:\"* ]]; then\n        info \"$INSTALL_DIR already in PATH\"\n        return 0\n    fi\n\n    local shell_rc\n    case \"${SHELL:-/bin/bash}\" in\n        */bash) shell_rc=\"$HOME/.bashrc\" ;;\n        */zsh)  shell_rc=\"$HOME/.zshrc\" ;;\n        */fish) shell_rc=\"$HOME/.config/fish/config.fish\" ;;\n        *)      shell_rc=\"$HOME/.profile\" ;;\n    esac\n\n    local path_line=\"export PATH=\\\"$INSTALL_DIR:\\$PATH\\\"\"\n\n    # Check if already configured\n    if [[ -f \"$shell_rc\" ]] \u0026\u0026 grep -qF \"$INSTALL_DIR\" \"$shell_rc\"; then\n        info \"PATH already configured in $shell_rc\"\n        return 0\n    fi\n\n    if confirm \"Add $INSTALL_DIR to PATH in $shell_rc?\"; then\n        echo \"\" \u003e\u003e \"$shell_rc\"\n        echo \"# Added by RCH installer\" \u003e\u003e \"$shell_rc\"\n        echo \"$path_line\" \u003e\u003e \"$shell_rc\"\n        success \"PATH configured in $shell_rc\"\n        warn \"Run 'source $shell_rc' or restart your shell\"\n    fi\n}\n\n# ============================================================================\n# Uninstall\n# ============================================================================\n\nuninstall() {\n    info \"Uninstalling RCH...\"\n\n    local binaries=(rch rchd rch-wkr)\n    local removed=0\n\n    for binary in \"${binaries[@]}\"; do\n        local path=\"$INSTALL_DIR/$binary\"\n        if [[ -f \"$path\" ]]; then\n            if [[ -w \"$INSTALL_DIR\" ]]; then\n                rm -f \"$path\"\n            else\n                sudo rm -f \"$path\"\n            fi\n            success \"Removed $path\"\n            ((removed++))\n        fi\n    done\n\n    if [[ $removed -eq 0 ]]; then\n        warn \"No RCH binaries found in $INSTALL_DIR\"\n    fi\n\n    # Optionally remove config\n    if confirm \"Remove RCH configuration (~/.config/rch)?\"; then\n        rm -rf \"$HOME/.config/rch\"\n        success \"Removed configuration\"\n    fi\n\n    success \"Uninstall complete\"\n}\n\n# ============================================================================\n# Verification\n# ============================================================================\n\nverify_installation() {\n    info \"Verifying installation...\"\n\n    local errors=0\n\n    for binary in rch rchd rch-wkr; do\n        local path=\"$INSTALL_DIR/$binary\"\n        if [[ -x \"$path\" ]]; then\n            local version\n            version=$(\"$path\" --version 2\u003e/dev/null | head -1 || echo \"unknown\")\n            success \"$binary: $version\"\n        else\n            error \"$binary: not found or not executable\"\n            ((errors++))\n        fi\n    done\n\n    if [[ $errors -gt 0 ]]; then\n        error \"Verification failed with $errors errors\"\n        return 1\n    fi\n\n    success \"Installation verified\"\n}\n\n# ============================================================================\n# Main\n# ============================================================================\n\nmain() {\n    setup_ui\n\n    # Parse arguments\n    while [[ $# -gt 0 ]]; do\n        case \"$1\" in\n            --version)    VERSION=\"$2\"; shift 2 ;;\n            --channel)    CHANNEL=\"$2\"; shift 2 ;;\n            --install-dir) INSTALL_DIR=\"$2\"; shift 2 ;;\n            --easy-mode)  EASY_MODE=true; shift ;;\n            --offline)    OFFLINE_TARBALL=\"$2\"; shift 2 ;;\n            --verify-only) VERIFY_ONLY=true; shift ;;\n            --uninstall)  DO_UNINSTALL=true; shift ;;\n            --no-gum)     NO_GUM=true; shift ;;\n            --no-sig)     NO_SIG=true; shift ;;\n            --yes)        YES=true; shift ;;\n            --help)       show_help; exit 0 ;;\n            *)            error \"Unknown option: $1\"; exit 1 ;;\n        esac\n    done\n\n    # Setup proxy\n    setup_proxy\n\n    # Handle modes\n    if [[ \"${DO_UNINSTALL:-}\" == \"true\" ]]; then\n        uninstall\n        exit 0\n    fi\n\n    if [[ \"${VERIFY_ONLY:-}\" == \"true\" ]]; then\n        verify_installation\n        exit $?\n    fi\n\n    # Installation flow\n    detect_platform\n\n    if [[ -n \"${OFFLINE_TARBALL:-}\" ]]; then\n        TARBALL_PATH=\"$OFFLINE_TARBALL\"\n        info \"Using offline tarball: $TARBALL_PATH\"\n    else\n        resolve_version\n        download_release\n    fi\n\n    install_binaries\n    verify_installation\n\n    if [[ \"${EASY_MODE:-}\" == \"true\" ]]; then\n        configure_path\n        info \"Detecting AI coding agents...\"\n        \"$INSTALL_DIR/rch\" agents detect || true\n    fi\n\n    echo \"\"\n    success \"RCH installation complete!\"\n    info \"Run 'rch setup' to configure workers and hooks\"\n}\n\nsetup_proxy() {\n    PROXY_ARGS=\"\"\n    if [[ -n \"${HTTPS_PROXY:-}\" ]]; then\n        PROXY_ARGS=\"--proxy $HTTPS_PROXY\"\n        info \"Using proxy: $HTTPS_PROXY\"\n    elif [[ -n \"${HTTP_PROXY:-}\" ]]; then\n        PROXY_ARGS=\"--proxy $HTTP_PROXY\"\n        info \"Using proxy: $HTTP_PROXY\"\n    fi\n}\n\nshow_help() {\n    cat \u003c\u003c 'EOF'\nRCH Installer\n\nUsage: ./install.sh [OPTIONS]\n\nOptions:\n  --version \u003cVER\u003e       Install specific version (default: latest)\n  --channel \u003cCHANNEL\u003e   Release channel: stable, beta, nightly\n  --install-dir \u003cDIR\u003e   Installation directory (default: /usr/local/bin)\n  --easy-mode           Configure PATH + detect agents + verify\n  --offline \u003cTARBALL\u003e   Install from local tarball (airgap mode)\n  --verify-only         Verify existing installation\n  --uninstall           Remove RCH binaries and config\n  --no-gum              Disable Gum UI (use ANSI fallback)\n  --no-sig              Skip signature verification\n  --yes                 Skip confirmation prompts\n  --help                Show this help message\n\nEnvironment Variables:\n  HTTP_PROXY            HTTP proxy URL\n  HTTPS_PROXY           HTTPS proxy URL\n  NO_PROXY              Hosts to bypass proxy\n  RCH_INSTALL_DIR       Override default install directory\n  RCH_NO_COLOR          Disable colored output\nEOF\n}\n\nmain \"$@\"\n```\n\n## Testing Requirements\n\n### Unit Tests (test/install.bats)\n\n```bash\n#!/usr/bin/env bats\n\nload test_helper\n\n@test \"detect_platform returns valid target on Linux x86_64\" {\n    # Mock uname\n    function uname() { [[ \"$1\" == \"-s\" ]] \u0026\u0026 echo \"Linux\" || echo \"x86_64\"; }\n    export -f uname\n\n    source install.sh --help\n    detect_platform\n    [[ \"$TARGET\" == \"linux-x86_64\" ]]\n}\n\n@test \"detect_platform returns valid target on macOS arm64\" {\n    function uname() { [[ \"$1\" == \"-s\" ]] \u0026\u0026 echo \"Darwin\" || echo \"arm64\"; }\n    export -f uname\n\n    source install.sh --help\n    detect_platform\n    [[ \"$TARGET\" == \"darwin-aarch64\" ]]\n}\n\n@test \"verify_checksum succeeds with correct checksum\" {\n    local tmp=$(mktemp)\n    echo \"test content\" \u003e \"$tmp\"\n    local checksum=$(sha256sum \"$tmp\" | awk '{print $1}')\n    echo \"$checksum  $(basename $tmp)\" \u003e \"${tmp}.checksums\"\n\n    source install.sh --help\n    verify_checksum \"$tmp\" \"${tmp}.checksums\" \"$(basename $tmp)\"\n}\n\n@test \"verify_checksum fails with wrong checksum\" {\n    local tmp=$(mktemp)\n    echo \"test content\" \u003e \"$tmp\"\n    echo \"wrongchecksum  $(basename $tmp)\" \u003e \"${tmp}.checksums\"\n\n    source install.sh --help\n    run verify_checksum \"$tmp\" \"${tmp}.checksums\" \"$(basename $tmp)\"\n    [[ \"$status\" -ne 0 ]]\n}\n\n@test \"configure_path is idempotent\" {\n    local tmp=$(mktemp)\n    echo 'export PATH=\"/usr/local/bin:$PATH\"' \u003e \"$tmp\"\n\n    SHELL=\"/bin/bash\"\n    HOME=$(dirname \"$tmp\")\n    mv \"$tmp\" \"$HOME/.bashrc\"\n\n    source install.sh --help\n    configure_path\n\n    local count=$(grep -c \"/usr/local/bin\" \"$HOME/.bashrc\")\n    [[ \"$count\" -eq 1 ]]\n}\n\n@test \"proxy setup uses HTTPS_PROXY\" {\n    export HTTPS_PROXY=\"http://proxy:8080\"\n    source install.sh --help\n    setup_proxy\n    [[ \"$PROXY_ARGS\" == \"--proxy http://proxy:8080\" ]]\n}\n```\n\n### E2E Test Script (scripts/e2e_install_test.sh)\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nlog() { echo \"[$(date -Iseconds)] $*\" \u003e\u00262; }\npass() { log \"✓ PASS: $*\"; }\nfail() { log \"✗ FAIL: $*\"; exit 1; }\n\nTEST_DIR=$(mktemp -d)\ntrap 'rm -rf \"$TEST_DIR\"' EXIT\n\n# Test 1: Help output\nlog \"Test 1: Help output\"\n./install.sh --help | grep -q \"RCH Installer\" || fail \"Help should show installer name\"\npass \"Help output\"\n\n# Test 2: Verify-only on fresh system\nlog \"Test 2: Verify-only fails when not installed\"\nINSTALL_DIR=\"$TEST_DIR/bin\" ./install.sh --verify-only \u0026\u0026 fail \"Should fail\" || true\npass \"Verify-only fails correctly\"\n\n# Test 3: Offline install\nlog \"Test 3: Offline install from tarball\"\n# Create mock tarball\nmkdir -p \"$TEST_DIR/pkg\"\necho '#!/bin/bash' \u003e \"$TEST_DIR/pkg/rch\"\necho 'echo \"rch 0.1.0\"' \u003e\u003e \"$TEST_DIR/pkg/rch\"\nchmod +x \"$TEST_DIR/pkg/rch\"\ntar -czf \"$TEST_DIR/rch.tar.gz\" -C \"$TEST_DIR/pkg\" rch\n\nINSTALL_DIR=\"$TEST_DIR/bin\" ./install.sh --offline \"$TEST_DIR/rch.tar.gz\" --yes\n[[ -x \"$TEST_DIR/bin/rch\" ]] || fail \"Binary not installed\"\npass \"Offline install\"\n\n# Test 4: Uninstall\nlog \"Test 4: Uninstall\"\nINSTALL_DIR=\"$TEST_DIR/bin\" ./install.sh --uninstall --yes\n[[ ! -f \"$TEST_DIR/bin/rch\" ]] || fail \"Binary not removed\"\npass \"Uninstall\"\n\nlog \"All install.sh E2E tests passed!\"\n```\n\n## Success Criteria\n\n- [ ] Gum UI works when available\n- [ ] ANSI fallback works without Gum\n- [ ] SHA256 checksum verification passes\n- [ ] Proxy support works (HTTP_PROXY, HTTPS_PROXY)\n- [ ] Offline install from local tarball works\n- [ ] Uninstall removes binaries cleanly\n- [ ] Easy mode configures PATH idempotently\n- [ ] WSL detection shows appropriate warnings\n- [ ] All bats tests pass\n- [ ] E2E tests pass\n\n## Dependencies\n\n- remote_compilation_helper-9zy: Uses release artifacts\n- remote_compilation_helper-gao: Release build configuration\n\n## Blocks\n\nNone - this is a user-facing installer.\n\n## Integration Tests\n\n- Run install script in a temp dir with mock tarball and verify PATH idempotency across shells.\n\n## Logging\n\n- E2E logs should include chosen install mode, resolved version/channel, and checksum source.\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:53:22.027466013-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.574476182-05:00","dependencies":[{"issue_id":"remote_compilation_helper-eke","depends_on_id":"remote_compilation_helper-9zy","type":"blocks","created_at":"2026-01-16T15:03:16.433038141-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-eke","depends_on_id":"remote_compilation_helper-gao","type":"blocks","created_at":"2026-01-16T15:13:38.489847179-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-eyd","title":"Implement worker health monitoring with heartbeats","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T08:46:13.579124926-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T08:52:05.008292273-05:00","closed_at":"2026-01-16T08:52:05.008292273-05:00","close_reason":"Implemented health.rs with HealthConfig, HealthCheckResult, WorkerHealth state tracking, and HealthMonitor background task. Monitors workers via SSH echo command, tracks consecutive failures, updates status to Healthy/Degraded/Unreachable. All 19 rchd tests pass."}
{"id":"remote_compilation_helper-gao","title":"Set up cargo-dist for automated cross-platform releases","description":"## Overview\n\nConfigure cargo-dist for automated multi-platform release builds with checksums, installers, and SBOM generation. This provides a complete release automation pipeline that generates verified artifacts for all supported platforms.\n\n## Research Findings (2025-2026)\n\n### cargo-dist v0.26.0 Features\n\n- Cross-compilation for all major targets\n- Automatic SHA256 checksum generation\n- Shell and PowerShell installers\n- SBOM (Software Bill of Materials) via cargo-auditable\n- GitHub Actions CI integration\n- Homebrew formula generation\n\n### Setup\n\n```bash\ncargo install cargo-dist\ncargo dist init\n```\n\n### Workspace Cargo.toml Changes\n\n```toml\n[workspace.metadata.dist]\ncargo-dist-version = \"0.26.0\"\nci = \"github\"\ntargets = [\n    \"x86_64-unknown-linux-gnu\",\n    \"aarch64-unknown-linux-gnu\",\n    \"x86_64-apple-darwin\",\n    \"aarch64-apple-darwin\"\n]\ninstallers = [\"shell\"]\nchecksum = \"sha256\"\ncargo-auditable = true\n```\n\n### Generated Release Assets\n\nFor each release:\n```\nrch-v1.0.0-x86_64-unknown-linux-gnu.tar.gz\nrch-v1.0.0-x86_64-unknown-linux-gnu.tar.gz.sha256\nchecksums.txt\ninstall.sh\n```\n\n## Implementation Steps\n\n1. **Install cargo-dist**: `cargo install cargo-dist`\n2. **Initialize in workspace**: `cargo dist init`\n3. **Configure targets** - Edit Cargo.toml with targets\n4. **Generate CI workflow**: `cargo dist generate-ci github`\n5. **Test locally**: `cargo dist build`\n6. **Create release**: `git tag v0.1.0 \u0026\u0026 git push --tags`\n\n## Comprehensive Testing Requirements\n\n### Unit Tests (Rust)\n\n```rust\n#[cfg(test)]\nmod tests {\n    use std::path::Path;\n\n    #[test]\n    fn test_dist_config_exists() {\n        let cargo_toml = include_str!(\"../../Cargo.toml\");\n        assert!(cargo_toml.contains(\"[workspace.metadata.dist]\"),\n                \"Cargo.toml should have dist metadata\");\n    }\n\n    #[test]\n    fn test_dist_targets_configured() {\n        let cargo_toml = include_str!(\"../../Cargo.toml\");\n        assert!(cargo_toml.contains(\"x86_64-unknown-linux-gnu\"),\n                \"Should target Linux x86_64\");\n        assert!(cargo_toml.contains(\"aarch64-unknown-linux-gnu\"),\n                \"Should target Linux ARM64\");\n    }\n\n    #[test]\n    fn test_checksum_algorithm_sha256() {\n        let cargo_toml = include_str!(\"../../Cargo.toml\");\n        assert!(cargo_toml.contains(\"checksum = \\\"sha256\\\"\"),\n                \"Should use SHA256 checksums\");\n    }\n}\n```\n\n### Integration Tests (`tests/cargo_dist_integration.rs`)\n\n```rust\nuse std::process::Command;\n\n#[test]\n#[ignore] // Run with --ignored for CI tests\nfn test_cargo_dist_plan_succeeds() {\n    let output = Command::new(\"cargo\")\n        .args([\"dist\", \"plan\", \"--output-format=json\"])\n        .output()\n        .expect(\"Failed to run cargo dist plan\");\n\n    assert!(output.status.success(),\n            \"cargo dist plan should succeed: {}\",\n            String::from_utf8_lossy(\u0026output.stderr));\n\n    let stdout = String::from_utf8_lossy(\u0026output.stdout);\n    assert!(stdout.contains(\"\\\"targets\\\"\"), \"Plan should include targets\");\n}\n\n#[test]\n#[ignore]\nfn test_cargo_dist_build_produces_artifacts() {\n    // Clean dist directory first\n    let _ = std::fs::remove_dir_all(\"target/dist\");\n\n    let output = Command::new(\"cargo\")\n        .args([\"dist\", \"build\"])\n        .output()\n        .expect(\"Failed to run cargo dist build\");\n\n    assert!(output.status.success(),\n            \"cargo dist build should succeed: {}\",\n            String::from_utf8_lossy(\u0026output.stderr));\n\n    // Check artifacts exist\n    assert!(std::path::Path::new(\"target/dist\").exists(),\n            \"target/dist directory should be created\");\n}\n\n#[test]\n#[ignore]\nfn test_checksums_are_valid() {\n    use std::io::Read;\n    use sha2::{Sha256, Digest};\n\n    let dist_path = std::path::Path::new(\"target/dist\");\n    if !dist_path.exists() {\n        eprintln!(\"Skipping: no dist artifacts\");\n        return;\n    }\n\n    for entry in std::fs::read_dir(dist_path).unwrap() {\n        let entry = entry.unwrap();\n        let path = entry.path();\n\n        if path.extension().map(|e| e == \"sha256\").unwrap_or(false) {\n            // Read expected checksum\n            let expected = std::fs::read_to_string(\u0026path)\n                .unwrap()\n                .split_whitespace()\n                .next()\n                .unwrap()\n                .to_string();\n\n            // Calculate actual checksum of corresponding file\n            let archive_path = path.with_extension(\"\");\n            if archive_path.exists() {\n                let mut file = std::fs::File::open(\u0026archive_path).unwrap();\n                let mut hasher = Sha256::new();\n                let mut buffer = [0u8; 8192];\n                loop {\n                    let n = file.read(\u0026mut buffer).unwrap();\n                    if n == 0 { break; }\n                    hasher.update(\u0026buffer[..n]);\n                }\n                let actual = format!(\"{:x}\", hasher.finalize());\n\n                assert_eq!(expected, actual,\n                    \"Checksum mismatch for {:?}\", archive_path);\n            }\n        }\n    }\n}\n```\n\n### CI Tests (`.github/workflows/test-release.yml`)\n\n```yaml\nname: Test Release Build\n\non:\n  pull_request:\n    paths:\n      - 'Cargo.toml'\n      - '**/Cargo.toml'\n      - '.github/workflows/release.yml'\n  workflow_dispatch:\n\njobs:\n  plan-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@stable\n\n      - name: Install cargo-dist\n        run: |\n          curl -fsSL https://github.com/axodotdev/cargo-dist/releases/latest/download/cargo-dist-installer.sh | sh\n\n      - name: Run cargo dist plan\n        run: cargo dist plan --output-format=json \u003e plan.json\n\n      - name: Validate plan\n        run: |\n          jq -e '.targets | length \u003e 0' plan.json\n          echo \"Plan validated successfully\"\n\n  build-test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: dtolnay/rust-toolchain@stable\n\n      - name: Install cargo-dist\n        run: curl -fsSL https://github.com/axodotdev/cargo-dist/releases/latest/download/cargo-dist-installer.sh | sh\n\n      - name: Build artifacts\n        run: cargo dist build\n\n      - name: Verify checksums\n        run: |\n          cd target/dist\n          for sha_file in *.sha256; do\n            if [ -f \"$sha_file\" ]; then\n              archive=\"${sha_file%.sha256}\"\n              if [ -f \"$archive\" ]; then\n                echo \"Verifying $archive...\"\n                sha256sum -c \"$sha_file\"\n              fi\n            fi\n          done\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: test-artifacts\n          path: target/dist/*\n```\n\n### E2E Test Script (`scripts/test_cargo_dist.sh`)\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" \u0026\u0026 pwd)\"\nPROJECT_ROOT=\"$(cd \"$SCRIPT_DIR/..\" \u0026\u0026 pwd)\"\nLOG_DIR=\"${PROJECT_ROOT}/test_logs/cargo_dist\"\n\nlog() {\n    local level=\"$1\" component=\"$2\" message=\"$3\"\n    echo \"[$level] [$component] $message\"\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] [$level] [$component] $message\" \u003e\u003e \"$LOG_DIR/test.log\"\n}\n\nmkdir -p \"$LOG_DIR\"\ncd \"$PROJECT_ROOT\"\n\n# Test 1: Check cargo-dist is available\nlog \"INFO\" \"SETUP\" \"Checking cargo-dist...\"\nif cargo dist --version \u003e /dev/null 2\u003e\u00261; then\n    log \"PASS\" \"SETUP\" \"cargo-dist available\"\nelse\n    log \"FAIL\" \"SETUP\" \"cargo-dist not installed\"\n    exit 1\nfi\n\n# Test 2: Validate config\nlog \"INFO\" \"CONFIG\" \"Validating configuration...\"\nif grep -q '\\[workspace.metadata.dist\\]' Cargo.toml; then\n    log \"PASS\" \"CONFIG\" \"dist metadata found\"\nelse\n    log \"FAIL\" \"CONFIG\" \"Missing dist metadata\"\n    exit 1\nfi\n\n# Test 3: Run plan\nlog \"INFO\" \"PLAN\" \"Running cargo dist plan...\"\nif cargo dist plan --output-format=json \u003e \"$LOG_DIR/plan.json\" 2\u003e\u00261; then\n    log \"PASS\" \"PLAN\" \"Plan succeeded\"\nelse\n    log \"FAIL\" \"PLAN\" \"Plan failed\"\n    exit 1\nfi\n\n# Test 4: Build (optional, slow)\nif [ \"${RUN_BUILD:-}\" = \"1\" ]; then\n    log \"INFO\" \"BUILD\" \"Running cargo dist build...\"\n    if cargo dist build 2\u003e\u00261 | tee \"$LOG_DIR/build.log\"; then\n        log \"PASS\" \"BUILD\" \"Build succeeded\"\n\n        # Verify checksums\n        log \"INFO\" \"CHECKSUM\" \"Verifying checksums...\"\n        cd target/dist\n        for sha_file in *.sha256; do\n            if [ -f \"$sha_file\" ]; then\n                if sha256sum -c \"$sha_file\" \u003e /dev/null 2\u003e\u00261; then\n                    log \"PASS\" \"CHECKSUM\" \"$sha_file verified\"\n                else\n                    log \"FAIL\" \"CHECKSUM\" \"$sha_file failed\"\n                fi\n            fi\n        done\n    else\n        log \"FAIL\" \"BUILD\" \"Build failed\"\n    fi\nfi\n\nlog \"INFO\" \"MAIN\" \"All tests completed. Logs at: $LOG_DIR\"\n```\n\n### E2E Test Additions (`scripts/e2e_test.sh`)\n\n```bash\ntest_cargo_dist_config() {\n    log \"INFO\" \"CARGO_DIST\" \"Testing cargo-dist configuration...\"\n\n    # Test 1: Check dist metadata exists\n    if grep -q '\\[workspace.metadata.dist\\]' \"$PROJECT_ROOT/Cargo.toml\"; then\n        log \"INFO\" \"CARGO_DIST\" \"dist metadata found\"\n    else\n        log \"WARN\" \"CARGO_DIST\" \"dist metadata not configured\"\n        return 0\n    fi\n\n    # Test 2: Verify cargo-dist available\n    if cargo dist --version \u003e /dev/null 2\u003e\u00261; then\n        log \"INFO\" \"CARGO_DIST\" \"cargo-dist available\"\n    else\n        log \"INFO\" \"CARGO_DIST\" \"cargo-dist not installed, skipping\"\n        return 0\n    fi\n\n    # Test 3: Run plan\n    if cargo dist plan \u003e /dev/null 2\u003e\u00261; then\n        log \"INFO\" \"CARGO_DIST\" \"cargo dist plan succeeded\"\n    else\n        log \"WARN\" \"CARGO_DIST\" \"cargo dist plan failed\"\n    fi\n\n    # Test 4: Check workflow exists\n    if [ -f \"$PROJECT_ROOT/.github/workflows/release.yml\" ]; then\n        log \"INFO\" \"CARGO_DIST\" \"release.yml exists\"\n    fi\n\n    log \"INFO\" \"CARGO_DIST\" \"Tests completed\"\n}\n```\n\n## Success Criteria\n\n- [ ] cargo-dist initialized in workspace\n- [ ] Targets: Linux + macOS (x86_64, aarch64)\n- [ ] GitHub Actions workflow generated\n- [ ] SHA256 checksums for all artifacts\n- [ ] Shell installer generated\n- [ ] SBOM via cargo-auditable\n- [ ] Release workflow on tags (v*)\n- [ ] All binaries included (rch, rchd, rch-wkr)\n- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] CI workflow tests pass\n- [ ] E2E tests verify checksums\n\n## Files to Create/Modify\n\n- `Cargo.toml` - Add workspace.metadata.dist\n- `.github/workflows/release.yml` - Generated by cargo-dist\n- `.github/workflows/test-release.yml` - CI tests\n- `scripts/test_cargo_dist.sh` - Local test script\n- `scripts/e2e_test.sh` - E2E additions\n\n## Dependencies\n\n- GitHub Actions CI (remote_compilation_helper-bcl)\n- Self-update command (remote_compilation_helper-9zy)\n- Install script (remote_compilation_helper-eke)\n\n## Logging\n\n- E2E logs must include cargo-dist plan/build output path, checksum verification results, and artifact list with sizes.\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T15:13:27.440636775-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.6135695-05:00"}
{"id":"remote_compilation_helper-gga","title":"Create installation script for local setup","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T08:46:14.901535898-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T08:57:20.522726579-05:00","closed_at":"2026-01-16T08:57:20.522726579-05:00","close_reason":"Installation script is complete and fully functional"}
{"id":"remote_compilation_helper-gof","title":"Integrate miette for beautiful error diagnostics","description":"## Overview\n\nIntegrate the miette crate for beautiful, context-rich error diagnostics that help users understand and fix problems quickly.\n\n## Research Findings (2025-2026)\n\n### miette Crate\n\nmiette (31.3M+ downloads) provides:\n- Beautiful error formatting with source context\n- Syntax highlighting for code snippets\n- Multiple related errors in one report\n- Structured error data with labels and help text\n- Automatic ANSI color handling\n\n**Cargo.toml:**\n```toml\n[dependencies]\nmiette = { version = \"7\", features = [\"fancy\"] }\nthiserror = \"2\"\n```\n\n### Error Design Pattern\n\n```rust\nuse miette::{Diagnostic, SourceSpan, NamedSource};\nuse thiserror::Error;\n\n#[derive(Error, Diagnostic, Debug)]\npub enum RchError {\n    #[error(\"Worker connection failed\")]\n    #[diagnostic(\n        code(rch::worker::connection_failed),\n        help(\"Check that the worker is running and SSH keys are configured\"),\n        url(\"https://rch.dev/docs/troubleshooting#connection-failed\")\n    )]\n    WorkerConnectionFailed {\n        worker_id: String,\n        #[source]\n        source: std::io::Error,\n    },\n\n    #[error(\"Invalid configuration\")]\n    #[diagnostic(code(rch::config::invalid))]\n    ConfigError {\n        #[source_code]\n        src: NamedSource\u003cString\u003e,\n        #[label(\"this field is invalid\")]\n        span: SourceSpan,\n        #[help]\n        help: String,\n    },\n\n    #[error(\"Daemon not running\")]\n    #[diagnostic(\n        code(rch::daemon::not_running),\n        help(\"Start the daemon with: rch daemon start\")\n    )]\n    DaemonNotRunning,\n}\n```\n\n### Integration Points\n\n1. **Config parsing errors**: Show TOML location with context\n2. **SSH connection failures**: Include host, port, suggested fixes\n3. **Compilation errors**: Forward rustc diagnostics\n4. **API errors**: Include request/response context\n5. **Validation errors**: Highlight invalid fields\n\n### Output Examples\n\n```\nError: rch::config::invalid\n\n  × Invalid configuration\n   ╭─[~/.config/rch/config.toml:5:1]\n 4 │ [workers.gpu-box]\n 5 │ host = 192.168.1.100\n   ·        ─────────────── this field is invalid\n 6 │ user = \"build\"\n   ╰────\n  help: IP addresses must be quoted: host = \"192.168.1.100\"\n```\n\n## Implementation\n\n### Error Module\n\n```rust\n// rch/src/error.rs\nuse miette::{Diagnostic, Report, SourceSpan, NamedSource};\nuse thiserror::Error;\n\npub type Result\u003cT\u003e = std::result::Result\u003cT, Report\u003e;\n\n#[derive(Error, Diagnostic, Debug)]\npub enum ConfigError {\n    #[error(\"Failed to read config file\")]\n    #[diagnostic(code(rch::config::read_failed))]\n    ReadFailed {\n        path: std::path::PathBuf,\n        #[source]\n        source: std::io::Error,\n    },\n\n    #[error(\"Invalid TOML syntax\")]\n    #[diagnostic(code(rch::config::parse_error))]\n    ParseError {\n        #[source_code]\n        src: NamedSource\u003cString\u003e,\n        #[label(\"{message}\")]\n        span: SourceSpan,\n        message: String,\n    },\n\n    #[error(\"Missing required field: {field}\")]\n    #[diagnostic(\n        code(rch::config::missing_field),\n        help(\"Add the '{field}' field to your config\")\n    )]\n    MissingField { field: String },\n}\n\n#[derive(Error, Diagnostic, Debug)]\npub enum WorkerError {\n    #[error(\"Connection to {worker_id} failed\")]\n    #[diagnostic(\n        code(rch::worker::connection_failed),\n        help(\"Verify SSH access with: ssh -i {identity_file} {user}@{host}\")\n    )]\n    ConnectionFailed {\n        worker_id: String,\n        host: String,\n        user: String,\n        identity_file: String,\n        #[source]\n        source: std::io::Error,\n    },\n\n    #[error(\"Worker {worker_id} is unhealthy\")]\n    #[diagnostic(\n        code(rch::worker::unhealthy),\n        help(\"Check worker status: rch workers probe {worker_id}\")\n    )]\n    Unhealthy { worker_id: String, reason: String },\n}\n\n#[derive(Error, Diagnostic, Debug)]\npub enum DaemonError {\n    #[error(\"Daemon is not running\")]\n    #[diagnostic(\n        code(rch::daemon::not_running),\n        help(\"Start the daemon with: rch daemon start\")\n    )]\n    NotRunning,\n\n    #[error(\"Port {port} is already in use\")]\n    #[diagnostic(\n        code(rch::daemon::port_in_use),\n        help(\"Stop the existing process or use --port to specify a different port\")\n    )]\n    PortInUse { port: u16 },\n\n    #[error(\"Daemon startup failed\")]\n    #[diagnostic(code(rch::daemon::startup_failed))]\n    StartupFailed {\n        #[source]\n        source: std::io::Error,\n    },\n}\n\n#[derive(Error, Diagnostic, Debug)]\npub enum TransferError {\n    #[error(\"rsync failed\")]\n    #[diagnostic(\n        code(rch::transfer::rsync_failed),\n        help(\"Ensure rsync is installed on both local and remote machines\")\n    )]\n    RsyncFailed {\n        exit_code: Option\u003ci32\u003e,\n        stderr: String,\n    },\n\n    #[error(\"SSH authentication failed\")]\n    #[diagnostic(\n        code(rch::transfer::ssh_auth),\n        help(\"Verify SSH key permissions (chmod 600) and that the key is added to the remote authorized_keys\")\n    )]\n    SshAuthFailed {\n        host: String,\n        user: String,\n        identity_file: String,\n    },\n}\n```\n\n### Main Integration\n\n```rust\n// rch/src/main.rs\nfn main() {\n    if let Err(report) = run() {\n        eprintln!(\"{:?}\", report);\n        std::process::exit(1);\n    }\n}\n```\n\n### Config Parser with Source Context\n\n```rust\npub fn parse_config(path: \u0026Path) -\u003e Result\u003cConfig\u003e {\n    let content = std::fs::read_to_string(path)\n        .map_err(|e| ConfigError::ReadFailed {\n            path: path.to_path_buf(),\n            source: e,\n        })?;\n\n    toml::from_str(\u0026content).map_err(|e| {\n        let span = e.span().map(|s| (s.start, s.end - s.start).into());\n        ConfigError::ParseError {\n            src: NamedSource::new(path.display().to_string(), content),\n            span: span.unwrap_or((0, 0).into()),\n            message: e.message().to_string(),\n        }\n    })\n}\n```\n\n## Comprehensive Testing Requirements\n\n### Unit Tests (`rch/src/error.rs` tests module)\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use miette::Report;\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // ConfigError Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_config_parse_error_formatting() {\n        let err = ConfigError::ParseError {\n            src: NamedSource::new(\"test.toml\", \"[invalid\".to_string()),\n            span: (0, 8).into(),\n            message: \"expected ']'\".to_string(),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"test.toml\"), \"Should include filename\");\n        assert!(formatted.contains(\"expected ']'\"), \"Should include error message\");\n        assert!(formatted.contains(\"rch::config::parse_error\"), \"Should include error code\");\n    }\n\n    #[test]\n    fn test_config_read_failed_includes_path() {\n        let err = ConfigError::ReadFailed {\n            path: std::path::PathBuf::from(\"/nonexistent/config.toml\"),\n            source: std::io::Error::new(std::io::ErrorKind::NotFound, \"file not found\"),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"Failed to read config file\"));\n        assert!(formatted.contains(\"rch::config::read_failed\"));\n    }\n\n    #[test]\n    fn test_config_missing_field_has_help() {\n        let err = ConfigError::MissingField {\n            field: \"workers\".to_string(),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"workers\"));\n        assert!(formatted.contains(\"help\"), \"Should include help text\");\n    }\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // WorkerError Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_worker_connection_failed_includes_remediation() {\n        let err = WorkerError::ConnectionFailed {\n            worker_id: \"gpu-worker\".to_string(),\n            host: \"192.168.1.100\".to_string(),\n            user: \"build\".to_string(),\n            identity_file: \"~/.ssh/id_rsa\".to_string(),\n            source: std::io::Error::new(std::io::ErrorKind::ConnectionRefused, \"refused\"),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"gpu-worker\"));\n        assert!(formatted.contains(\"ssh -i\"), \"Should include SSH verification command\");\n        assert!(formatted.contains(\"rch::worker::connection_failed\"));\n    }\n\n    #[test]\n    fn test_worker_unhealthy_includes_worker_id() {\n        let err = WorkerError::Unhealthy {\n            worker_id: \"slow-worker\".to_string(),\n            reason: \"high load\".to_string(),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"slow-worker\"));\n        assert!(formatted.contains(\"rch workers probe\"));\n    }\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // DaemonError Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_daemon_not_running_has_start_command() {\n        let err = DaemonError::NotRunning;\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"rch daemon start\"));\n        assert!(formatted.contains(\"rch::daemon::not_running\"));\n    }\n\n    #[test]\n    fn test_daemon_port_in_use_suggests_alternative() {\n        let err = DaemonError::PortInUse { port: 7800 };\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"7800\"));\n        assert!(formatted.contains(\"--port\"));\n    }\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // TransferError Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_rsync_failed_includes_exit_code() {\n        let err = TransferError::RsyncFailed {\n            exit_code: Some(12),\n            stderr: \"connection unexpectedly closed\".to_string(),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"rsync\"));\n        assert!(formatted.contains(\"rch::transfer::rsync_failed\"));\n    }\n\n    #[test]\n    fn test_ssh_auth_failed_includes_key_hint() {\n        let err = TransferError::SshAuthFailed {\n            host: \"example.com\".to_string(),\n            user: \"deploy\".to_string(),\n            identity_file: \"~/.ssh/deploy_key\".to_string(),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        assert!(formatted.contains(\"chmod 600\"));\n        assert!(formatted.contains(\"authorized_keys\"));\n    }\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Error Chain Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_error_source_chain_preserved() {\n        let inner = std::io::Error::new(std::io::ErrorKind::PermissionDenied, \"access denied\");\n        let err = ConfigError::ReadFailed {\n            path: std::path::PathBuf::from(\"/etc/rch/config.toml\"),\n            source: inner,\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        // miette should show the error chain\n        assert!(formatted.contains(\"access denied\") || formatted.contains(\"PermissionDenied\"));\n    }\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Source Context Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_source_context_shows_line_numbers() {\n        let content = r#\"[daemon]\nport = 7800\n\n[workers.test]\nhost = unquoted_value\nuser = \"test\"\n\"#;\n        \n        let err = ConfigError::ParseError {\n            src: NamedSource::new(\"config.toml\", content.to_string()),\n            span: (42, 14).into(), // Points to unquoted_value\n            message: \"expected string\".to_string(),\n        };\n\n        let report = Report::new(err);\n        let formatted = format!(\"{:?}\", report);\n        \n        // Should show surrounding context with line numbers\n        assert!(formatted.contains(\"host\"));\n    }\n\n    // ═══════════════════════════════════════════════════════════════════════════════\n    // Non-TTY Output Tests\n    // ═══════════════════════════════════════════════════════════════════════════════\n\n    #[test]\n    fn test_error_readable_without_colors() {\n        // Force non-graphical output for testing\n        let err = DaemonError::NotRunning;\n        let report = Report::new(err);\n        \n        // Basic formatting should work without panicking\n        let debug_fmt = format!(\"{:?}\", report);\n        let display_fmt = format!(\"{}\", report);\n        \n        assert!(!debug_fmt.is_empty());\n        assert!(!display_fmt.is_empty());\n    }\n}\n```\n\n### Integration Tests (`rch/tests/error_integration.rs`)\n\n```rust\n//! Integration tests for error handling and diagnostics\n\nuse std::process::Command;\nuse std::io::Write;\nuse tempfile::TempDir;\n\n/// Test that config parse errors show source context\n#[test]\nfn test_config_error_shows_source_context() {\n    let temp_dir = TempDir::new().unwrap();\n    let config_path = temp_dir.path().join(\"config.toml\");\n    \n    // Write invalid config\n    let mut file = std::fs::File::create(\u0026config_path).unwrap();\n    writeln!(file, \"[daemon]\").unwrap();\n    writeln!(file, \"port = not_a_number\").unwrap();\n    \n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"--config\", config_path.to_str().unwrap(), \"status\"])\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    \n    // Should show the file path\n    assert!(stderr.contains(\"config.toml\"), \"Should show config file path\");\n    // Should show error code\n    assert!(stderr.contains(\"rch::config\"), \"Should show error code\");\n}\n\n/// Test that daemon not running error shows helpful message\n#[test]\nfn test_daemon_not_running_error() {\n    // Ensure no daemon is running\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"status\"])\n        .env(\"RCH_DAEMON_PORT\", \"59999\") // Use unlikely port\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    \n    assert!(stderr.contains(\"rch daemon start\") || stderr.contains(\"not running\"),\n            \"Should suggest starting daemon\");\n}\n\n/// Test that worker connection errors include remediation\n#[test]\nfn test_worker_connection_error_remediation() {\n    let temp_dir = TempDir::new().unwrap();\n    let config_path = temp_dir.path().join(\"config.toml\");\n    \n    // Write config with unreachable worker\n    let mut file = std::fs::File::create(\u0026config_path).unwrap();\n    writeln!(file, r#\"\n[daemon]\nport = 59998\n\n[workers.unreachable]\nhost = \"192.0.2.1\"\nuser = \"test\"\nidentity_file = \"/nonexistent/key\"\ntotal_slots = 4\n\"#).unwrap();\n    \n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"--config\", config_path.to_str().unwrap(), \"workers\", \"probe\", \"unreachable\"])\n        .env(\"RCH_MOCK_SSH\", \"0\") // Disable mock to get real error\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    \n    // Should include SSH verification hint or connection error\n    assert!(stderr.contains(\"ssh\") || stderr.contains(\"connection\") || stderr.contains(\"failed\"),\n            \"Should show connection error with guidance\");\n}\n\n/// Test error output in JSON mode\n#[test]\nfn test_json_error_output() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"--json\", \"status\"])\n        .env(\"RCH_DAEMON_PORT\", \"59997\")\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    \n    // JSON output should be parseable or have structured error\n    // (Note: actual JSON error format depends on implementation)\n    assert!(!output.status.success(), \"Should fail when daemon not running\");\n}\n\n/// Test that errors don't contain ANSI codes when piped\n#[test]\nfn test_no_ansi_when_piped() {\n    let output = Command::new(env!(\"CARGO_BIN_EXE_rch\"))\n        .args([\"status\"])\n        .env(\"RCH_DAEMON_PORT\", \"59996\")\n        .env(\"NO_COLOR\", \"1\")\n        .output()\n        .expect(\"Failed to execute rch\");\n    \n    let stderr = String::from_utf8_lossy(\u0026output.stderr);\n    \n    // ANSI escape sequences start with \\x1b[\n    let has_ansi = stderr.contains(\"\\x1b[\");\n    assert!(!has_ansi, \"Should not contain ANSI codes when NO_COLOR is set\");\n}\n```\n\n### E2E Test Additions (`scripts/e2e_test.sh`)\n\n```bash\n# ═══════════════════════════════════════════════════════════════════════════════════\n# Error Diagnostics Tests\n# ═══════════════════════════════════════════════════════════════════════════════════\n\ntest_error_diagnostics() {\n    log \"INFO\" \"ERROR_DIAG\" \"Testing miette error diagnostics...\"\n\n    # Test 1: Invalid config shows source context\n    log \"INFO\" \"ERROR_DIAG\" \"Test 1: Config parse error with source context\"\n    local bad_config=\"$LOG_DIR/bad_config.toml\"\n    cat \u003e \"$bad_config\" \u003c\u003c 'EOF'\n[daemon]\nport = 7800\n\n[workers.test]\nhost = unquoted_value\nuser = \"test\"\nEOF\n    \n    local output\n    if output=$(\"$RCH\" --config \"$bad_config\" status 2\u003e\u00261); then\n        log \"WARN\" \"ERROR_DIAG\" \"Command succeeded unexpectedly\"\n    else\n        # Check for source context indicators\n        if echo \"$output\" | grep -q \"config.toml\\|host\\|unquoted\"; then\n            log \"INFO\" \"ERROR_DIAG\" \"✓ Config error shows source context\"\n        else\n            log \"FAIL\" \"ERROR_DIAG\" \"Config error missing source context\"\n            log \"DEBUG\" \"ERROR_DIAG\" \"Output: $output\"\n            return 1\n        fi\n        \n        # Check for error code\n        if echo \"$output\" | grep -q \"rch::config\"; then\n            log \"INFO\" \"ERROR_DIAG\" \"✓ Config error includes error code\"\n        else\n            log \"WARN\" \"ERROR_DIAG\" \"Config error missing error code (non-critical)\"\n        fi\n    fi\n\n    # Test 2: Daemon not running shows help\n    log \"INFO\" \"ERROR_DIAG\" \"Test 2: Daemon not running error\"\n    local saved_port=\"${RCH_DAEMON_PORT:-}\"\n    export RCH_DAEMON_PORT=59995\n    \n    if output=$(\"$RCH\" status 2\u003e\u00261); then\n        log \"WARN\" \"ERROR_DIAG\" \"Status succeeded (daemon may be running)\"\n    else\n        if echo \"$output\" | grep -qi \"daemon\\|start\\|not running\"; then\n            log \"INFO\" \"ERROR_DIAG\" \"✓ Daemon error shows helpful message\"\n        else\n            log \"FAIL\" \"ERROR_DIAG\" \"Daemon error missing helpful guidance\"\n            log \"DEBUG\" \"ERROR_DIAG\" \"Output: $output\"\n        fi\n    fi\n    \n    # Restore port\n    if [ -n \"$saved_port\" ]; then\n        export RCH_DAEMON_PORT=\"$saved_port\"\n    else\n        unset RCH_DAEMON_PORT\n    fi\n\n    # Test 3: No ANSI codes with NO_COLOR\n    log \"INFO\" \"ERROR_DIAG\" \"Test 3: No ANSI codes with NO_COLOR=1\"\n    export RCH_DAEMON_PORT=59994\n    export NO_COLOR=1\n    \n    output=$(\"$RCH\" status 2\u003e\u00261 || true)\n    \n    if echo \"$output\" | grep -q $'\\x1b\\['; then\n        log \"FAIL\" \"ERROR_DIAG\" \"ANSI codes present despite NO_COLOR=1\"\n        return 1\n    else\n        log \"INFO\" \"ERROR_DIAG\" \"✓ No ANSI codes when NO_COLOR is set\"\n    fi\n    \n    unset NO_COLOR\n    unset RCH_DAEMON_PORT\n\n    # Test 4: Error codes are consistent format\n    log \"INFO\" \"ERROR_DIAG\" \"Test 4: Error code format consistency\"\n    # Create various error conditions and check code format\n    local error_codes=()\n    \n    # Missing config\n    output=$(\"$RCH\" --config /nonexistent/path.toml status 2\u003e\u00261 || true)\n    if echo \"$output\" | grep -oE 'rch::[a-z_]+::[a-z_]+' \u003e\u003e /dev/null; then\n        log \"INFO\" \"ERROR_DIAG\" \"✓ Error code format correct\"\n    fi\n\n    log \"INFO\" \"ERROR_DIAG\" \"Error diagnostics tests completed\"\n}\n\n# Add to main test suite\nrun_all_tests() {\n    # ... existing tests ...\n    test_error_diagnostics\n}\n```\n\n### Logging Requirements\n\nAll error paths should include structured logging for debugging:\n\n```rust\nuse tracing::{error, warn, debug, info, instrument};\n\n#[instrument(skip(config_content), fields(path = %path.display()))]\npub fn parse_config(path: \u0026Path) -\u003e Result\u003cConfig\u003e {\n    debug!(\"Reading config file\");\n    \n    let content = std::fs::read_to_string(path)\n        .map_err(|e| {\n            error!(error = %e, \"Failed to read config file\");\n            ConfigError::ReadFailed {\n                path: path.to_path_buf(),\n                source: e,\n            }\n        })?;\n\n    debug!(content_length = content.len(), \"Config file read successfully\");\n\n    toml::from_str(\u0026content).map_err(|e| {\n        let span_info = e.span().map(|s| format!(\"{}:{}\", s.start, s.end));\n        error!(\n            message = %e.message(),\n            span = ?span_info,\n            \"Config parse error\"\n        );\n        ConfigError::ParseError {\n            src: NamedSource::new(path.display().to_string(), content),\n            span: e.span().map(|s| (s.start, s.end - s.start).into()).unwrap_or((0, 0).into()),\n            message: e.message().to_string(),\n        }\n    })\n}\n```\n\n## Files to Modify\n\n- `rch/Cargo.toml` - Add miette dependency\n- `rch/src/error.rs` - New error module with all error types\n- `rch/src/config.rs` - Integrate miette errors in config parsing\n- `rch/src/commands.rs` - Use new error types in command handlers\n- `rch/src/main.rs` - Setup miette handler\n- `rch/tests/error_integration.rs` - Integration tests\n- `scripts/e2e_test.sh` - E2E test additions\n\n## Success Criteria\n\n- [ ] All public errors implement Diagnostic\n- [ ] Config errors show source location with line numbers\n- [ ] Connection errors include remediation steps (SSH command to test)\n- [ ] Help text provides actionable guidance\n- [ ] URL links to documentation where applicable\n- [ ] Colors adapt to terminal capabilities (respects NO_COLOR)\n- [ ] Non-TTY output is still readable\n- [ ] Error codes follow `rch::category::specific` format\n- [ ] Unit test coverage \u003e90% for error module\n- [ ] Integration tests pass for all error scenarios\n- [ ] E2E tests verify user-facing error messages\n- [ ] Structured logging on all error paths\n\n## Dependencies\n\n- UI output layer (remote_compilation_helper-u0v) for color/mode detection","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T15:13:26.720608518-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:25:07.778303597-05:00","dependencies":[{"issue_id":"remote_compilation_helper-gof","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T15:13:36.242191663-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-gr7","title":"Epic: Observability with Prometheus Metrics Export","description":"## Overview\n\nAdd Prometheus metrics export for the daemon, covering worker health, circuit state, build history, and transfer timings.\n\n## Goals\n\n1. Expose `/metrics` endpoint on daemon\n2. Export counters + gauges:\n   - worker_status{worker,status}\n   - worker_slots{worker}\n   - circuit_state{worker}\n   - builds_total{result}\n   - build_duration_ms (histogram)\n   - transfer_bytes_total (counter)\n3. Low overhead\n\n## Implementation\n\n- Use `prometheus` crate\n- Add metrics registry + endpoint\n- Update on selection/health/build events\n\n## Tests\n\n- Unit: metric increment functions\n- Integration: `/metrics` output contains expected series\n- E2E: scrape via curl in mock mode\n\n## Acceptance Criteria\n\n- `/metrics` endpoint exports required metrics\n- Metrics are updated on events\n\n## Dependencies\n\n- Build history tracking (remote_compilation_helper-qgs)\n\n## Logging\n\n- E2E logs should include a snapshot of `/metrics` output with a count of key series.\n","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:54:53.528865955-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.653412831-05:00","dependencies":[{"issue_id":"remote_compilation_helper-gr7","depends_on_id":"remote_compilation_helper-7ds","type":"blocks","created_at":"2026-01-16T15:03:22.222529775-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-lgy","title":"Add interactive TUI dashboard with ratatui (future)","description":"## Overview\n\nCreate an optional interactive TUI dashboard using ratatui for real‑time monitoring and operator actions. Use ratatui's layout + widgets system for a polished, modern terminal UI.\n\n## Goals\n\n1. Real‑time worker status + slot gauges\n2. Active build list with progress\n3. Recent build history\n4. Keyboard shortcuts for common actions\n5. Graceful resize handling\n\n## Data Sources\n\n- Daemon status endpoint (`/status`)\n- Build history ring buffer\n- Worker health + circuit state\n\n## UI Design\n\n- Header: daemon state + uptime\n- Workers panel: list + gauges\n- Active builds panel: list + progress\n- Recent builds panel: table\n- Footer: keybinds\n\n## Implementation\n\n- ratatui widgets: `Block`, `Gauge`, `Table`, `List`\n- crossterm backend for input + resize\n- Async refresh loop (1s)\n\n## Tests\n\n- Unit: state reducer + key bindings\n- Integration: mock data feeds\n- E2E: run `rch tui` in test mode (no curses) and log render cycles to ensure no panic under resize and data changes\n\n## Logging\n\n- E2E logs should record refresh count, render latency, and last error (if any)\n\n## Acceptance Criteria\n\n- Dashboard renders with no panics\n- Updates every 1s with fresh data\n- Key actions (drain/enable) work\n- Resize‑safe\n\n## Dependencies\n\n- Status API + build history (remote_compilation_helper-3sy, remote_compilation_helper-qgs)\n\n","status":"open","priority":4,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:55:29.970277679-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:23:12.995093392-05:00","dependencies":[{"issue_id":"remote_compilation_helper-lgy","depends_on_id":"remote_compilation_helper-7ds","type":"blocks","created_at":"2026-01-16T15:03:20.431131018-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-mio","title":"Add toolchain synchronization tests and E2E scenarios","description":"## Overview\n\nAdd comprehensive unit, integration, and E2E tests for toolchain synchronization. The tests must validate correctness across normal, failure, and edge cases with clear logs.\n\n## Test Coverage\n\n### Unit\n- Toolchain parsing (channel/date/full version)\n- Cache behavior (hits/misses, invalidation)\n- Command wrapping (`rustup run`)\n\n### Integration (mocked worker)\n- Worker with missing toolchain triggers install\n- Worker without rustup logs warning and falls back\n- Failed install triggers local fallback\n\n### E2E (scripts/e2e_test.sh)\n- Mock SSH with toolchain install flow\n- Failure injection for rustup install\n- Verify compilation still proceeds locally on failure\n\n## Logging\n\n- E2E logs must show toolchain decision path\n- Include worker id and toolchain string in logs\n\n## Acceptance Criteria\n\n- All tests are deterministic and pass with mock transport\n- Failure paths explicitly validated\n- E2E logs are human-readable and include step‑by‑step reasoning\n\n## Dependencies\n\n- Toolchain sync implementation (remote_compilation_helper-0lo)\n\n","status":"open","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:14:14.088593123-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:05:29.33479923-05:00","dependencies":[{"issue_id":"remote_compilation_helper-mio","depends_on_id":"remote_compilation_helper-0lo","type":"blocks","created_at":"2026-01-16T12:14:50.472621322-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-mrg","title":"Handle no-worker response in hook with graceful local fallback","description":"## Parent Epic: Graceful Local Fallback (remote_compilation_helper-ne8)\n\n## Task Description\n\nModify the hook logic to gracefully handle the case when the daemon returns no available worker. Instead of failing or blocking, the hook should allow local execution and log an informative message.\n\n## Current State\n\nLooking at rch/src/hook.rs, when the daemon returns a response, the hook processes it. Need to verify the current behavior when `worker` is `None` and ensure it falls back gracefully.\n\n## Changes Required\n\n### 1. Update Hook Response Handling\n```rust\n// In rch/src/hook.rs or similar\n\nasync fn handle_compilation_command(...) -\u003e HookDecision {\n    // Query daemon for worker\n    let response = query_daemon(\u0026socket, \u0026request).await?;\n    \n    // NEW: Handle no-worker case gracefully\n    match response.worker {\n        Some(worker) =\u003e {\n            // Proceed with remote compilation\n            execute_remotely(worker, command).await\n        }\n        None =\u003e {\n            // Log informative message based on reason\n            let reason_msg = match response.reason {\n                Some(SelectionReason::NoWorkersConfigured) =\u003e \n                    \"no workers configured\",\n                Some(SelectionReason::AllWorkersUnreachable) =\u003e \n                    \"all workers unreachable\",\n                Some(SelectionReason::AllWorkersBusy) =\u003e \n                    \"all workers at capacity\",\n                Some(SelectionReason::AllCircuitsOpen) =\u003e \n                    \"all worker circuits open (recovering)\",\n                _ =\u003e \"unknown reason\",\n            };\n            \n            // Log warning to stderr (visible to user)\n            eprintln!(\n                \"⚠️  RCH: No remote workers available ({}), executing locally\",\n                reason_msg\n            );\n            \n            // Return allow decision - local execution proceeds\n            HookDecision::Allow\n        }\n    }\n}\n```\n\n### 2. Ensure Consistent Fail-Open\n\nReview ALL error paths in hook.rs to ensure they return `Allow`:\n- Config load failure → Allow\n- Socket connection failure → Allow  \n- Daemon timeout → Allow\n- Invalid response → Allow\n- No worker available → Allow (this task)\n\n### 3. Add Telemetry/Logging\n\nTrack fallback events for operational visibility:\n```rust\n// Log at INFO level so it appears in logs\ntracing::info!(\n    reason = %reason_msg,\n    project = %project_id,\n    \"Local fallback triggered\"\n);\n```\n\n## Files to Modify\n- `rch/src/hook.rs`\n- Possibly `rch/src/main.rs` if decision handling is there\n\n## Testing\n\n```rust\n#[tokio::test]\nasync fn test_hook_no_worker_fallback() {\n    // Setup mock daemon that returns no worker\n    let mock_response = SelectionResponse {\n        worker: None,\n        slots_reserved: 0,\n        reason: Some(SelectionReason::AllWorkersUnreachable),\n    };\n    \n    // Verify hook returns Allow\n    let decision = handle_compilation_with_mock(mock_response).await;\n    assert_eq!(decision, HookDecision::Allow);\n}\n\n#[tokio::test]\nasync fn test_hook_all_busy_fallback() {\n    // All workers busy\n    let mock_response = SelectionResponse {\n        worker: None,\n        slots_reserved: 0,\n        reason: Some(SelectionReason::AllWorkersBusy),\n    };\n    \n    let decision = handle_compilation_with_mock(mock_response).await;\n    assert_eq!(decision, HookDecision::Allow);\n}\n```\n\n## Acceptance Criteria\n- [ ] Hook returns Allow when no worker available\n- [ ] Informative message printed to stderr\n- [ ] Different messages for different reasons\n- [ ] INFO-level log entry for tracking\n- [ ] All error paths in hook return Allow (fail-open audit)\n- [ ] Tests cover all no-worker scenarios\n\n## Dependencies\n- Requires: \"Add reason field to SelectionResponse\" task\n\n## Estimated Effort: 2-3 hours","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:08:17.52218289-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T12:51:17.303126706-05:00","closed_at":"2026-01-16T12:51:17.303126706-05:00","close_reason":"Already implemented as part of remote_compilation_helper-4ur. The hook at rch/src/hook.rs:116-125 gracefully handles no-worker responses, logs an informative warning with the reason, and returns Allow for local fallback.","dependencies":[{"issue_id":"remote_compilation_helper-mrg","depends_on_id":"remote_compilation_helper-4ur","type":"blocks","created_at":"2026-01-16T12:08:42.770174732-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-nbo","title":"Add terminal colors and visual polish to CLI output","description":"## Overview\nTransform plain monochrome CLI output into polished, colored terminal output. Builds on the UI output abstraction layer.\n\n## Dependencies\n- **BLOCKED BY**: remote_compilation_helper-u0v (UI output abstraction layer)\n\n## Requirements\n\n### Color Scheme\nUsing `colored` crate with consistent palette:\n- **Success**: Green (bright) - for ✓, \"OK\", successful operations\n- **Error**: Red (bright) - for ✗, errors, failures\n- **Warning**: Yellow - for ⚠, degraded states, non-critical issues\n- **Info**: Cyan - for informational messages, hints\n- **Header**: White/Bold - for section titles\n- **Muted**: Gray/Dim - for secondary information, timestamps\n- **Emphasis**: Bold - for important values, worker names\n\n### Visual Elements\n1. **Section Headers**: \n   ```\n   ═══ Worker Status ═══\n   ```\n   Using box-drawing characters for premium feel\n\n2. **Key-Value Alignment**:\n   ```\n   Status:     Running\n   Socket:     /tmp/rch.sock\n   Uptime:     2h 15m\n   ```\n   Right-align labels, consistent spacing\n\n3. **Tables** (for workers list, status):\n   ```\n   ┌────────────┬─────────────────┬────────┬──────────┐\n   │ Worker     │ Host            │ Status │ Slots    │\n   ├────────────┼─────────────────┼────────┼──────────┤\n   │ gpu-1      │ gpu1.internal   │ ✓      │ 32/64    │\n   │ cpu-fleet  │ cpu.internal    │ ⚠      │ 8/16     │\n   └────────────┴─────────────────┴────────┴──────────┘\n   ```\n   Consider `comfy-table` or `tabled` crate\n\n### Commands to Update\n- `rch status` - colorize all status indicators\n- `rch workers list` - table format with colors\n- `rch workers probe` - colored success/failure per worker\n- `rch workers benchmark` - colored results\n- `rch config show` - syntax-highlighted TOML-like output\n- `rch config validate` - colored checkmarks/warnings\n- `rch daemon status` - colored running/stopped indicator\n- `rch hook test` - colored test results\n\n## Testing Requirements\n\n### Unit Tests\n- Verify color codes are present in Human mode output\n- Verify NO color codes in Plain mode output\n- Verify table formatting is correct\n- Test each color function produces expected ANSI codes\n\n### Integration Tests\n- Snapshot tests comparing output format\n- Test color output disabled when piped\n\n### E2E Test Additions (scripts/e2e_test.sh)\n```bash\n# Scenario: colored output\nrun_scenario \"colored_output\" \"verify\" \"\"\n# Check that Human mode output contains ANSI codes\n# Check that piped output contains no ANSI codes\n```\n\n## Acceptance Criteria\n- [ ] All commands produce colored output in Human mode\n- [ ] Consistent color scheme across all commands\n- [ ] Tables render correctly with box-drawing characters\n- [ ] Key-value pairs are properly aligned\n- [ ] All unit tests pass\n- [ ] Visual inspection confirms premium appearance","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:36:30.753664152-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T13:29:52.43097929-05:00","closed_at":"2026-01-16T13:29:52.43097929-05:00","close_reason":"Toolchain detection fully implemented in toolchain.rs with tests. CLI colored output implemented across all commands using Style system.","dependencies":[{"issue_id":"remote_compilation_helper-nbo","depends_on_id":"remote_compilation_helper-u0v","type":"blocks","created_at":"2026-01-16T11:57:31.272148274-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ne8","title":"Epic: Graceful Local Fallback When No Workers Available","description":"## Overview\n\nImplement automatic local fallback when no healthy workers are available, completing RCH's fail-open philosophy. This is the second-highest impact improvement identified and addresses a critical gap in reliability.\n\n## Problem Statement\n\nCurrently, when the daemon has no healthy workers to assign (all unreachable, overloaded, or draining), the behavior may not gracefully degrade. The hook should NEVER prevent a build from happening - if remote compilation isn't possible, local compilation must proceed.\n\n## Goals\n\n1. When daemon returns no available worker, hook allows local execution\n2. User sees informative message explaining the fallback\n3. Telemetry tracks fallback events for monitoring\n4. System maintains fail-open semantics in ALL failure scenarios\n\n## Design\n\n### Protocol Changes\n- Add `reason: Option\u003cString\u003e` to SelectionResponse for no-worker cases\n- Possible reasons: \"all_workers_unreachable\", \"all_workers_busy\", \"no_workers_configured\"\n\n### Hook Behavior\n```\n1. Hook queries daemon for worker\n2. If daemon returns worker=null:\n   - Log warning: \"⚠️ RCH: No remote workers available ({reason}), executing locally\"\n   - Return \"allow\" decision to Claude Code\n3. Compilation proceeds locally\n```\n\n### Rationale\n\nThis is ranked #2 of 5 improvements because:\n- Completes the fail-open philosophy that is core to RCH\n- Ensures AI agents can ALWAYS compile (the entire point of RCH)\n- Builds user trust - system is transparent about degraded state\n- Minimal implementation effort with maximum reliability impact\n- Essential for production use - any worker outage would otherwise break workflows\n\n## Success Criteria\n\n- [ ] No scenario exists where RCH prevents a build from happening\n- [ ] User always sees clear messaging when fallback occurs\n- [ ] Fallback events are logged for operational visibility\n- [ ] All existing tests pass\n- [ ] New tests cover all fallback scenarios\n\n## Estimated Effort: 1-2 days\n\n## Dependencies: None (this is foundational)\n\n## Blocked By: Nothing - this should be implemented first","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:04:44.686384473-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T13:00:15.802139654-05:00","closed_at":"2026-01-16T13:00:15.802139654-05:00","close_reason":"Epic complete. All success criteria met: (1) SelectionReason enum added to protocol, (2) Hook gracefully falls back with informative messages, (3) All error paths return Allow (fail-open), (4) 8 comprehensive fallback tests added, (5) All 100+ tests pass."}
{"id":"remote_compilation_helper-o9s","title":"Add toolchain field to protocol and transfer pipeline","description":"## Parent Epic: Automatic Toolchain Synchronization (remote_compilation_helper-ayn)\n\n## Task Description\n\nExtend the RCH protocol to include toolchain information in selection requests and execution requests. The worker needs to know which toolchain to use for compilation.\n\n## Changes Required\n\n### 1. Update SelectionRequest\n```rust\n// In rch-common/src/protocol.rs\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SelectionRequest {\n    pub project_id: String,\n    pub required_cores: u32,\n    pub preferred_workers: Vec\u003cString\u003e,\n    pub toolchain: Option\u003cToolchainInfo\u003e,  // NEW\n}\n```\n\n### 2. Update Daemon API Parsing\n```rust\n// In rchd/src/api.rs\n\n// Parse toolchain from query params or body\nfn parse_selection_request(request: \u0026Request) -\u003e Result\u003cSelectionRequest\u003e {\n    // ... existing parsing ...\n    \n    // Parse toolchain if provided\n    let toolchain = query.get(\"toolchain\")\n        .map(|s| serde_json::from_str(s))\n        .transpose()?;\n    \n    Ok(SelectionRequest {\n        // ... existing fields ...\n        toolchain,\n    })\n}\n```\n\n### 3. Update ExecutionRequest (Worker Protocol)\n```rust\n// In rch-common/src/protocol.rs or worker protocol\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExecutionRequest {\n    pub command: String,\n    pub working_dir: PathBuf,\n    pub env: HashMap\u003cString, String\u003e,\n    pub toolchain: Option\u003cToolchainInfo\u003e,  // NEW\n}\n```\n\n### 4. Update Transfer Pipeline\n```rust\n// In rch/src/transfer.rs\n\nimpl TransferPipeline {\n    /// Execute command on remote worker with toolchain\n    pub async fn execute_remote(\n        \u0026self,\n        worker: \u0026WorkerConfig,\n        command: \u0026str,\n        toolchain: Option\u003c\u0026ToolchainInfo\u003e,\n    ) -\u003e Result\u003cExecutionResult\u003e {\n        let wrapped_command = match toolchain {\n            Some(tc) =\u003e format!(\n                \"rustup run {} {}\",\n                tc.rustup_toolchain(),\n                command\n            ),\n            None =\u003e command.to_string(),\n        };\n        \n        self.ssh_client.execute(\u0026wrapped_command).await\n    }\n}\n```\n\n### 5. Update Hook to Pass Toolchain\n```rust\n// In rch/src/hook.rs\n\nasync fn handle_compilation(command: \u0026str, project_root: \u0026Path) -\u003e HookDecision {\n    // Detect toolchain\n    let toolchain = detect_toolchain(project_root).ok();\n    \n    // Include in selection request\n    let request = SelectionRequest {\n        project_id: project_id.clone(),\n        required_cores: estimate_cores(command),\n        preferred_workers: vec![],\n        toolchain: toolchain.clone(),\n    };\n    \n    // ... query daemon ...\n    \n    // Include in execution\n    let result = pipeline.execute_remote(\n        \u0026worker,\n        command,\n        toolchain.as_ref(),\n    ).await;\n}\n```\n\n## Protocol Wire Format\n\nThe toolchain can be sent as:\n1. Query parameter (URL-encoded JSON)\n2. Request body (for POST requests)\n3. Custom header\n\nRecommended: URL-encoded JSON in query param for GET, body for POST.\n\n```\nGET /select-worker?project=foo\u0026cores=4\u0026toolchain=%7B%22channel%22%3A%22nightly%22%2C%22date%22%3A%222024-01-15%22%7D\n```\n\nOr cleaner with POST body:\n```json\n{\n  \"project_id\": \"foo\",\n  \"required_cores\": 4,\n  \"toolchain\": {\n    \"channel\": \"nightly\",\n    \"date\": \"2024-01-15\"\n  }\n}\n```\n\n## Files to Modify\n- `rch-common/src/protocol.rs` or `rch-common/src/types.rs`\n- `rchd/src/api.rs`\n- `rch/src/hook.rs`\n- `rch/src/transfer.rs`\n\n## Testing\n```rust\n#[test]\nfn test_selection_request_with_toolchain() {\n    let request = SelectionRequest {\n        project_id: \"test\".to_string(),\n        required_cores: 4,\n        preferred_workers: vec![],\n        toolchain: Some(ToolchainInfo {\n            channel: \"nightly\".to_string(),\n            date: Some(\"2024-01-15\".to_string()),\n            full_version: \"nightly-2024-01-15\".to_string(),\n        }),\n    };\n    \n    let json = serde_json::to_string(\u0026request).unwrap();\n    let parsed: SelectionRequest = serde_json::from_str(\u0026json).unwrap();\n    \n    assert_eq!(parsed.toolchain.unwrap().channel, \"nightly\");\n}\n\n#[test]\nfn test_command_wrapping_with_toolchain() {\n    let tc = ToolchainInfo {\n        channel: \"nightly\".to_string(),\n        date: Some(\"2024-01-15\".to_string()),\n        full_version: \"\".to_string(),\n    };\n    \n    let wrapped = wrap_command(\"cargo build\", Some(\u0026tc));\n    assert_eq!(wrapped, \"rustup run nightly-2024-01-15 cargo build\");\n}\n\n#[test]\nfn test_command_no_wrapping_without_toolchain() {\n    let wrapped = wrap_command(\"cargo build\", None);\n    assert_eq!(wrapped, \"cargo build\");\n}\n```\n\n## Acceptance Criteria\n- [ ] SelectionRequest includes toolchain field\n- [ ] ExecutionRequest includes toolchain field\n- [ ] Daemon API parses toolchain from requests\n- [ ] Transfer pipeline wraps commands with rustup run\n- [ ] Hook detects and passes toolchain through pipeline\n- [ ] Serialization/deserialization works correctly\n- [ ] Tests cover protocol changes\n\n## Dependencies\n- Requires: \"Implement local toolchain version detection\" task\n\n## Estimated Effort: 2-3 hours","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:12:59.322422438-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T13:28:30.91001043-05:00","closed_at":"2026-01-16T13:28:30.91001043-05:00","close_reason":"Protocol updated: toolchain field added to SelectionRequest, transfer pipeline supports toolchain wrapping via wrap_command_with_toolchain, hook interface updated. Full integration with detect_toolchain pending.","dependencies":[{"issue_id":"remote_compilation_helper-o9s","depends_on_id":"remote_compilation_helper-6qs","type":"blocks","created_at":"2026-01-16T12:14:48.463999007-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-od4","title":"Add comprehensive tests for local fallback scenarios","description":"## Parent Epic: Graceful Local Fallback (remote_compilation_helper-ne8)\n\n## Task Description\n\nCreate comprehensive test coverage for all local fallback scenarios. These tests ensure the fail-open philosophy is maintained across all edge cases.\n\n## Test Scenarios\n\n### 1. No Workers Configured\n```rust\n#[tokio::test]\nasync fn test_fallback_no_workers_configured() {\n    // Empty workers.toml\n    // Hook should: allow local, log \"no workers configured\"\n}\n```\n\n### 2. All Workers Unreachable\n```rust\n#[tokio::test]\nasync fn test_fallback_all_workers_unreachable() {\n    // All workers have status: Unreachable\n    // Hook should: allow local, log \"all workers unreachable\"\n}\n```\n\n### 3. All Workers Busy\n```rust\n#[tokio::test]\nasync fn test_fallback_all_workers_busy() {\n    // All workers at max slot capacity\n    // Hook should: allow local, log \"all workers at capacity\"\n}\n```\n\n### 4. Daemon Socket Missing\n```rust\n#[tokio::test]\nasync fn test_fallback_daemon_not_running() {\n    // Socket file doesn't exist\n    // Hook should: allow local, log \"daemon not running\"\n}\n```\n\n### 5. Daemon Timeout\n```rust\n#[tokio::test]\nasync fn test_fallback_daemon_timeout() {\n    // Daemon takes too long to respond\n    // Hook should: allow local after timeout, log \"daemon timeout\"\n}\n```\n\n### 6. Daemon Returns Error\n```rust\n#[tokio::test]\nasync fn test_fallback_daemon_error() {\n    // Daemon returns HTTP 500 or malformed response\n    // Hook should: allow local, log \"daemon error\"\n}\n```\n\n### 7. Mixed Worker States\n```rust\n#[tokio::test]\nasync fn test_fallback_mixed_states() {\n    // Some unreachable, some draining, some disabled\n    // None actually available\n    // Hook should: allow local with appropriate reason\n}\n```\n\n### 8. Network Partition During Selection\n```rust\n#[tokio::test]\nasync fn test_fallback_network_error() {\n    // Connection reset during daemon query\n    // Hook should: allow local, log \"connection error\"\n}\n```\n\n### 9. Repeated Fallbacks (Rate Limiting Check)\n```rust\n#[tokio::test]\nasync fn test_repeated_fallbacks_logged_appropriately() {\n    // Multiple fallbacks in short succession\n    // Verify logging doesn't spam excessively\n}\n```\n\n## Integration Tests\n\nAdd to e2e_test.sh:\n```bash\nrun_scenario \"no_workers\" \"allow\" \"no-workers\"\nrun_scenario \"all_unreachable\" \"allow\" \"all-unreachable\"\nrun_scenario \"daemon_down\" \"allow\" \"daemon-down\"\n```\n\n## Mock Infrastructure\n\nExtend MockConfig to support these scenarios:\n```rust\nimpl MockConfig {\n    pub fn no_workers() -\u003e Self { /* ... */ }\n    pub fn all_unreachable() -\u003e Self { /* ... */ }\n    pub fn all_busy() -\u003e Self { /* ... */ }\n    pub fn daemon_error() -\u003e Self { /* ... */ }\n}\n```\n\n## Files to Modify\n- `rch/src/hook.rs` (add test module)\n- `rch-common/src/mock.rs` (extend mock configs)\n- `scripts/e2e_test.sh` (add scenarios)\n\n## Acceptance Criteria\n- [ ] All 9 unit test scenarios implemented and passing\n- [ ] E2E test scenarios added and passing\n- [ ] Mock infrastructure extended for fallback testing\n- [ ] No scenario results in blocking/denial when it should fallback\n- [ ] Test names clearly describe the scenario\n\n## Dependencies\n- Requires: Both previous tasks in this epic\n\n## Estimated Effort: 2-3 hours","status":"closed","priority":1,"issue_type":"task","assignee":"BlueSnow","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:08:35.609332325-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T13:00:46.844977856-05:00","closed_at":"2026-01-16T13:00:46.844977856-05:00","close_reason":"Implemented comprehensive tests for all local fallback scenarios: no workers, all unreachable, all busy, circuits open, selection error, daemon error, malformed JSON, connection reset. All 8 tests pass.","dependencies":[{"issue_id":"remote_compilation_helper-od4","depends_on_id":"remote_compilation_helper-mrg","type":"blocks","created_at":"2026-01-16T12:08:42.834306854-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-ova","title":"Integrate circuit breaker with worker selection","description":"## Overview\n\nIntegrate circuit breaker state into worker selection logic so that workers with open circuits are not selected and half‑open workers are probed conservatively.\n\n## Goals\n\n1. Exclude `Open` circuits from selection\n2. Allow `HalfOpen` only if probe budget allows\n3. Prefer `Closed` workers over `HalfOpen`\n4. Return explicit `SelectionReason::AllCircuitsOpen` when applicable\n\n## Implementation Steps\n\n1. Extend `WorkerState` to expose circuit state (from health layer)\n2. Update selection filter:\n   - Filter out `Open` circuits\n   - Allow `HalfOpen` only if `can_probe`\n3. Adjust scoring:\n   - Apply penalty to half‑open workers\n4. Update selection response to return `AllCircuitsOpen` if no candidates\n\n## Tests\n\n- Unit: selection ignores open circuits\n- Unit: selection allows half‑open only within probe budget\n- Unit: selection returns `AllCircuitsOpen` when all are open\n- Integration: simulate mixed circuit states\n- E2E: add `scripts/e2e_test.sh` case that forces all circuits open (mock failures) and logs that selection reason is `AllCircuitsOpen`\n\n## Logging\n\n- E2E logs must capture selection decisions and circuit states\n\n## Acceptance Criteria\n\n- Open circuits never receive new jobs\n- Half‑open workers get limited probes\n- Selection reason is accurate for user‑facing messaging\n\n## Dependencies\n\n- Circuit state core types (remote_compilation_helper-62v)\n- Circuit state integrated in health (remote_compilation_helper-52l)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:11:22.978619487-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:22:36.165646494-05:00","dependencies":[{"issue_id":"remote_compilation_helper-ova","depends_on_id":"remote_compilation_helper-52l","type":"blocks","created_at":"2026-01-16T12:12:01.93377572-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-piz","title":"Epic: Web Dashboard (Next.js 16 + React 19 + Tailwind 4)","description":"## Overview\n\nBuild an optional web dashboard for RCH with Next.js 16, React 19, Tailwind CSS v4, lucide-react icons, and Motion (formerly Framer Motion) for animations. The dashboard should surface the same operational visibility as \\`rch status\\`, plus historical charts and worker management.\n\n## Goals\n\n1. Polished, modern web UI with dark theme by default\n2. Real-time worker status + build history\n3. Simple install/start flow (\\`rch ui\\` or \\`rch web\\`)\n4. Responsive layout for desktop + mobile\n5. Minimal backend footprint (reuse rchd status API)\n\n## Tech Stack (2026 Best Practices)\n\n### Next.js 16 (App Router)\n- **Turbopack stable**: 5-10x faster builds vs Webpack\n- **React 19.2 support**: Full Server Components\n- **Cache Components**: Fine-grained caching with \\`\u003cCache\u003e\\` wrapper\n- **DevTools MCP integration**: AI-assisted debugging\n- **proxy.ts**: New middleware replacement for better type safety\n\n\\`\\`\\`typescript\n// next.config.ts\nimport type { NextConfig } from 'next';\n\nconst config: NextConfig = {\n  experimental: {\n    turbo: true, // Turbopack enabled by default in Next.js 16\n  },\n};\n\nexport default config;\n\\`\\`\\`\n\n### React 19 Features\n- **View Transitions**: Native page transition animations\n- **useEffectEvent()**: Stable event handlers in effects\n- **Activity component**: Coordinated loading/suspense\n- **React Compiler 1.0**: Automatic memoization (no manual useMemo/useCallback)\n\n\\`\\`\\`typescript\n// Using View Transitions\n'use client';\nimport { useViewTransition } from 'react';\n\nexport function WorkerCard({ worker, onSelect }) {\n  const { startTransition } = useViewTransition();\n  \n  return (\n    \u003cbutton onClick={() =\u003e startTransition(() =\u003e onSelect(worker))}\u003e\n      {worker.name}\n    \u003c/button\u003e\n  );\n}\n\\`\\`\\`\n\n### Tailwind CSS v4\n- **Rust-based engine**: 10x faster than v3\n- **Auto content detection**: No \\`content\\` array needed\n- **Zero PostCSS dependency**: Direct integration\n- **CSS-first config**: Use CSS custom properties\n\n\\`\\`\\`css\n/* app/globals.css */\n@import \"tailwindcss\";\n\n@theme {\n  --color-primary: oklch(70% 0.15 240);\n  --color-success: oklch(75% 0.18 145);\n  --color-warning: oklch(80% 0.15 85);\n  --color-error: oklch(65% 0.2 25);\n  --color-surface: oklch(15% 0.01 240);\n  --color-surface-elevated: oklch(20% 0.01 240);\n  \n  --font-mono: \"JetBrains Mono\", ui-monospace, monospace;\n}\n\\`\\`\\`\n\n### Motion (formerly Framer Motion)\nRebranded in Feb 2025, import from \"motion/react\":\n\n\\`\\`\\`typescript\nimport { motion, AnimatePresence } from \"motion/react\";\n\n// Smooth worker card animations\nexport function WorkerList({ workers }) {\n  return (\n    \u003cAnimatePresence mode=\"popLayout\"\u003e\n      {workers.map(worker =\u003e (\n        \u003cmotion.div\n          key={worker.id}\n          initial={{ opacity: 0, y: 20 }}\n          animate={{ opacity: 1, y: 0 }}\n          exit={{ opacity: 0, scale: 0.95 }}\n          layout\n        \u003e\n          \u003cWorkerCard worker={worker} /\u003e\n        \u003c/motion.div\u003e\n      ))}\n    \u003c/AnimatePresence\u003e\n  );\n}\n\\`\\`\\`\n\n### Lucide React Icons\nTree-shakable, 1500+ icons. Use direct imports:\n\n\\`\\`\\`typescript\n// DO: Direct imports (tree-shaking optimized)\nimport { Server, Activity, AlertCircle } from 'lucide-react';\n\n// DON'T: Dynamic imports (bloats bundle)\n// import * as icons from 'lucide-react';\n\\`\\`\\`\n\n### shadcn/ui Components\nCopy-paste components with React 19 + Tailwind v4 support:\n\n\\`\\`\\`bash\nnpx shadcn@latest init\nnpx shadcn@latest add button card badge progress\n\\`\\`\\`\n\nComponents are server-component friendly and use CSS variables for theming.\n\n## Project Structure\n\n\\`\\`\\`\nweb/\n├── app/\n│   ├── layout.tsx          # Root layout with theme provider\n│   ├── page.tsx            # Overview dashboard\n│   ├── workers/\n│   │   ├── page.tsx        # Worker list\n│   │   └── [id]/page.tsx   # Worker detail\n│   ├── builds/\n│   │   └── page.tsx        # Build history\n│   └── settings/\n│       └── page.tsx        # Config view\n├── components/\n│   ├── ui/                 # shadcn components\n│   ├── workers/\n│   │   ├── worker-card.tsx\n│   │   ├── worker-list.tsx\n│   │   └── slot-gauge.tsx\n│   ├── builds/\n│   │   └── build-table.tsx\n│   └── layout/\n│       ├── header.tsx\n│       ├── sidebar.tsx\n│       └── status-bar.tsx\n├── lib/\n│   ├── api.ts              # rchd API client\n│   ├── hooks/\n│   │   ├── use-workers.ts\n│   │   └── use-builds.ts\n│   └── utils.ts\n├── styles/\n│   └── globals.css         # Tailwind v4 config\n├── next.config.ts\n├── package.json\n└── tsconfig.json\n\\`\\`\\`\n\n## Pages / Views\n\n### 1. Overview Dashboard\n\n\\`\\`\\`typescript\n// app/page.tsx\nimport { Suspense } from 'react';\nimport { DaemonStatus } from '@/components/daemon-status';\nimport { WorkerSummary } from '@/components/worker-summary';\nimport { RecentBuilds } from '@/components/recent-builds';\n\nexport default function Overview() {\n  return (\n    \u003cdiv className=\"grid gap-6 md:grid-cols-2 lg:grid-cols-3\"\u003e\n      \u003cSuspense fallback={\u003cStatusSkeleton /\u003e}\u003e\n        \u003cDaemonStatus /\u003e\n      \u003c/Suspense\u003e\n      \n      \u003cSuspense fallback={\u003cWorkersSkeleton /\u003e}\u003e\n        \u003cWorkerSummary /\u003e\n      \u003c/Suspense\u003e\n      \n      \u003cSuspense fallback={\u003cBuildsSkeleton /\u003e}\u003e\n        \u003cRecentBuilds limit={10} /\u003e\n      \u003c/Suspense\u003e\n    \u003c/div\u003e\n  );\n}\n\\`\\`\\`\n\nFeatures:\n- Daemon status + uptime\n- Total workers + health summary (healthy/degraded/offline)\n- Recent builds (last 10)\n\n### 2. Workers View\n\n\\`\\`\\`typescript\n// components/workers/worker-card.tsx\n'use client';\nimport { motion } from 'motion/react';\nimport { Server, Activity, AlertCircle } from 'lucide-react';\nimport { Badge } from '@/components/ui/badge';\nimport { Progress } from '@/components/ui/progress';\n\ninterface WorkerCardProps {\n  worker: Worker;\n  onDrain?: () =\u003e void;\n}\n\nexport function WorkerCard({ worker, onDrain }: WorkerCardProps) {\n  const statusIcon = {\n    healthy: \u003cActivity className=\"text-success\" /\u003e,\n    degraded: \u003cAlertCircle className=\"text-warning\" /\u003e,\n    offline: \u003cServer className=\"text-error\" /\u003e,\n  }[worker.status];\n  \n  const slotUsage = (worker.usedSlots / worker.totalSlots) * 100;\n  \n  return (\n    \u003cmotion.div\n      className=\"rounded-lg bg-surface-elevated p-4 border border-white/5\"\n      whileHover={{ scale: 1.02 }}\n      transition={{ type: \"spring\", stiffness: 400 }}\n    \u003e\n      \u003cdiv className=\"flex items-center justify-between mb-3\"\u003e\n        \u003cdiv className=\"flex items-center gap-2\"\u003e\n          {statusIcon}\n          \u003cspan className=\"font-mono font-medium\"\u003e{worker.id}\u003c/span\u003e\n        \u003c/div\u003e\n        \u003cBadge variant={worker.status}\u003e{worker.status}\u003c/Badge\u003e\n      \u003c/div\u003e\n      \n      \u003cdiv className=\"space-y-2\"\u003e\n        \u003cdiv className=\"flex justify-between text-sm text-muted-foreground\"\u003e\n          \u003cspan\u003eSlots\u003c/span\u003e\n          \u003cspan\u003e{worker.usedSlots}/{worker.totalSlots}\u003c/span\u003e\n        \u003c/div\u003e\n        \u003cProgress value={slotUsage} className=\"h-2\" /\u003e\n      \u003c/div\u003e\n      \n      \u003cdiv className=\"mt-3 flex gap-2\"\u003e\n        \u003cbutton\n          onClick={onDrain}\n          className=\"text-xs text-muted-foreground hover:text-foreground\"\n        \u003e\n          Drain\n        \u003c/button\u003e\n      \u003c/div\u003e\n    \u003c/motion.div\u003e\n  );\n}\n\\`\\`\\`\n\nFeatures:\n- Worker cards with slot gauges\n- Filter by status/tag\n- Actions: drain/enable\n\n### 3. Builds View\n\n\\`\\`\\`typescript\n// components/builds/build-table.tsx\n'use client';\nimport { formatDistanceToNow } from 'date-fns';\nimport { CheckCircle, XCircle, Clock } from 'lucide-react';\nimport {\n  Table, TableBody, TableCell, TableHead, TableHeader, TableRow\n} from '@/components/ui/table';\n\nexport function BuildTable({ builds }: { builds: Build[] }) {\n  return (\n    \u003cTable\u003e\n      \u003cTableHeader\u003e\n        \u003cTableRow\u003e\n          \u003cTableHead\u003eProject\u003c/TableHead\u003e\n          \u003cTableHead\u003eWorker\u003c/TableHead\u003e\n          \u003cTableHead\u003eDuration\u003c/TableHead\u003e\n          \u003cTableHead\u003eStatus\u003c/TableHead\u003e\n          \u003cTableHead\u003eTime\u003c/TableHead\u003e\n        \u003c/TableRow\u003e\n      \u003c/TableHeader\u003e\n      \u003cTableBody\u003e\n        {builds.map(build =\u003e (\n          \u003cTableRow key={build.id}\u003e\n            \u003cTableCell className=\"font-mono\"\u003e{build.project}\u003c/TableCell\u003e\n            \u003cTableCell\u003e{build.worker}\u003c/TableCell\u003e\n            \u003cTableCell\u003e{formatDuration(build.durationMs)}\u003c/TableCell\u003e\n            \u003cTableCell\u003e\n              {build.exitCode === 0 ? (\n                \u003cCheckCircle className=\"h-4 w-4 text-success\" /\u003e\n              ) : (\n                \u003cXCircle className=\"h-4 w-4 text-error\" /\u003e\n              )}\n            \u003c/TableCell\u003e\n            \u003cTableCell className=\"text-muted-foreground\"\u003e\n              {formatDistanceToNow(build.timestamp, { addSuffix: true })}\n            \u003c/TableCell\u003e\n          \u003c/TableRow\u003e\n        ))}\n      \u003c/TableBody\u003e\n    \u003c/Table\u003e\n  );\n}\n\\`\\`\\`\n\nFeatures:\n- Build history table\n- Duration + exit code filters\n- Pagination\n\n### 4. Settings View\n\nRead-only config summary with links to config files.\n\n## Data Layer\n\n### API Client\n\n\\`\\`\\`typescript\n// lib/api.ts\nconst API_BASE = process.env.NEXT_PUBLIC_RCH_API || 'http://localhost:7800';\n\nexport async function fetchStatus(): Promise\u003cDaemonStatus\u003e {\n  const res = await fetch(\\`\\${API_BASE}/status\\`, {\n    next: { revalidate: 2 }, // ISR every 2 seconds\n  });\n  if (!res.ok) throw new Error('Daemon unreachable');\n  return res.json();\n}\n\nexport async function fetchWorkers(): Promise\u003cWorker[]\u003e {\n  const res = await fetch(\\`\\${API_BASE}/workers\\`);\n  return res.json();\n}\n\nexport async function fetchBuilds(params?: { limit?: number }): Promise\u003cBuild[]\u003e {\n  const url = new URL(\\`\\${API_BASE}/history\\`);\n  if (params?.limit) url.searchParams.set('limit', String(params.limit));\n  const res = await fetch(url);\n  return res.json();\n}\n\nexport async function drainWorker(id: string): Promise\u003cvoid\u003e {\n  await fetch(\\`\\${API_BASE}/workers/\\${id}/drain\\`, { method: 'POST' });\n}\n\\`\\`\\`\n\n### React Query Hooks\n\n\\`\\`\\`typescript\n// lib/hooks/use-workers.ts\n'use client';\nimport { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';\nimport { fetchWorkers, drainWorker } from '@/lib/api';\n\nexport function useWorkers() {\n  return useQuery({\n    queryKey: ['workers'],\n    queryFn: fetchWorkers,\n    refetchInterval: 2000, // Poll every 2s\n  });\n}\n\nexport function useDrainWorker() {\n  const queryClient = useQueryClient();\n  \n  return useMutation({\n    mutationFn: drainWorker,\n    onSuccess: () =\u003e {\n      queryClient.invalidateQueries({ queryKey: ['workers'] });\n    },\n  });\n}\n\\`\\`\\`\n\n## Styling \u0026 Theming\n\n### Dark Theme by Default\n\n\\`\\`\\`css\n/* styles/globals.css */\n@import \"tailwindcss\";\n\n@theme {\n  /* Dark theme colors using OKLCH for perceptual uniformity */\n  --color-background: oklch(10% 0.01 240);\n  --color-foreground: oklch(95% 0.01 240);\n  --color-muted: oklch(60% 0.01 240);\n  --color-muted-foreground: oklch(70% 0.01 240);\n  \n  --color-surface: oklch(15% 0.01 240);\n  --color-surface-elevated: oklch(20% 0.015 240);\n  --color-border: oklch(25% 0.01 240);\n  \n  --color-primary: oklch(70% 0.15 240);\n  --color-success: oklch(75% 0.18 145);\n  --color-warning: oklch(80% 0.15 85);\n  --color-error: oklch(65% 0.2 25);\n  \n  --radius-sm: 0.25rem;\n  --radius-md: 0.5rem;\n  --radius-lg: 0.75rem;\n}\n\nbody {\n  @apply bg-background text-foreground antialiased;\n}\n\\`\\`\\`\n\n### Responsive Breakpoints\n\n\\`\\`\\`typescript\n// Responsive layout for dashboard\n\u003cdiv className=\"grid gap-4 \n  grid-cols-1 \n  md:grid-cols-2 \n  lg:grid-cols-3 \n  xl:grid-cols-4\"\u003e\n  {/* Content */}\n\u003c/div\u003e\n\\`\\`\\`\n\n## Implementation Steps\n\n1. **Scaffold** \\`web/\\` app with Next.js 16\n   \\`\\`\\`bash\n   npx create-next-app@latest web --typescript --tailwind --app --turbopack\n   \\`\\`\\`\n\n2. **Tailwind v4 setup** + theme tokens\n   \\`\\`\\`bash\n   npm install tailwindcss@latest\n   \\`\\`\\`\n\n3. **Install dependencies**\n   \\`\\`\\`bash\n   npm install motion lucide-react @tanstack/react-query date-fns\n   npx shadcn@latest init\n   npx shadcn@latest add button card badge progress table\n   \\`\\`\\`\n\n4. **Layout + navigation**\n   - Sidebar with nav links\n   - Header with daemon status indicator\n   - Status bar footer\n\n5. **API client** for rchd endpoints\n\n6. **Worker cards** + build table\n\n7. **Motion polish** + empty/error states\n\n8. **CLI integration** (\\`rch web\\` command)\n   \\`\\`\\`rust\n   // Opens browser to dashboard\n   pub async fn cmd_web(args: \u0026WebArgs) -\u003e Result\u003c()\u003e {\n       let port = args.port.unwrap_or(3000);\n       // Start web server if not running\n       // Open browser\n       webbrowser::open(\u0026format!(\"http://localhost:{}\", port))?;\n       Ok(())\n   }\n   \\`\\`\\`\n\n## Error States\n\n### Daemon Offline\n\n\\`\\`\\`typescript\nexport function DaemonOffline() {\n  return (\n    \u003cdiv className=\"flex flex-col items-center justify-center h-64 text-center\"\u003e\n      \u003cAlertCircle className=\"h-12 w-12 text-error mb-4\" /\u003e\n      \u003ch2 className=\"text-lg font-medium mb-2\"\u003eDaemon Unreachable\u003c/h2\u003e\n      \u003cp className=\"text-muted-foreground mb-4\"\u003e\n        Unable to connect to rchd. Is the daemon running?\n      \u003c/p\u003e\n      \u003ccode className=\"bg-surface px-3 py-1 rounded text-sm\"\u003e\n        rch daemon start\n      \u003c/code\u003e\n    \u003c/div\u003e\n  );\n}\n\\`\\`\\`\n\n### Empty States\n\n\\`\\`\\`typescript\nexport function NoWorkers() {\n  return (\n    \u003cdiv className=\"text-center py-12\"\u003e\n      \u003cServer className=\"h-12 w-12 text-muted mx-auto mb-4\" /\u003e\n      \u003ch3 className=\"font-medium mb-2\"\u003eNo workers configured\u003c/h3\u003e\n      \u003cp className=\"text-muted-foreground text-sm\"\u003e\n        Add workers to your config to get started.\n      \u003c/p\u003e\n    \u003c/div\u003e\n  );\n}\n\\`\\`\\`\n\n## Performance Targets\n\n- Dashboard loads in \u003c2s locally\n- First Contentful Paint \u003c1s\n- Time to Interactive \u003c2s\n- Lighthouse score \u003e90\n\n## Acceptance Criteria\n\n- [ ] Dashboard loads in \u003c2s locally\n- [ ] Responsive layout works at 360px width\n- [ ] Clear error state when daemon is down\n- [ ] Worker actions (drain/enable) wired to API\n- [ ] Real-time updates via polling (2s interval)\n- [ ] Dark theme by default, consistent with CLI\n- [ ] Motion animations smooth (60fps)\n- [ ] All icons from lucide-react (tree-shaken)\n- [ ] Server components used where possible\n- [ ] \\`rch web\\` command opens browser\n\n## Dependencies\n\n- Status API + build history (remote_compilation_helper-3sy, remote_compilation_helper-qgs)\n- Rich status data model (remote_compilation_helper-7ds)\n\n## Tests\n\n- Unit: API client parsing\n- E2E: Playwright smoke tests (dashboard loads, worker list renders)\n- E2E logs: capture console + network errors\n\n## Logging\n\n- E2E logs must include console errors, failed network requests, and render timing metrics.\n","status":"open","priority":3,"issue_type":"epic","owner":"jeff141421@gmail.com","created_at":"2026-01-16T14:12:55.134604621-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.694862716-05:00"}
{"id":"remote_compilation_helper-qgs","title":"Add build history tracking to daemon","description":"## Overview\n\nAdd build history tracking in the daemon. This should record the most recent builds (success/failure, durations, worker, project), enabling `rch status`, TUI, and the web dashboard.\n\n## Goals\n\n1. In‑memory ring buffer of recent builds (default 100)\n2. Record start + end timestamps\n3. Store exit code, worker, project, command\n4. Optionally persist to disk for daemon restart survival\n\n## Implementation\n\n### Data Model\n\n```rust\nstruct BuildRecord {\n  id: u64,\n  timestamp: DateTime\u003cUtc\u003e,\n  project_id: String,\n  worker_id: String,\n  command: String,\n  exit_code: i32,\n  duration_ms: u64,\n}\n```\n\n### Storage\n- `VecDeque\u003cBuildRecord\u003e` with fixed capacity\n- Optional JSONL persistence to `~/.config/rch/build_history.jsonl`\n- On startup, load most recent N records\n\n### Recording Hooks\n- Add hooks in daemon execution pipeline (or selection + execution callbacks)\n- Ensure record is added on both success and failure\n\n## Tests\n\n- Unit: ring buffer capacity behavior\n- Unit: persistence load/save\n- Integration: record insertion on mock build execution\n- E2E: `/status` includes build history\n\n## Logging\n\n- DEBUG log on record insert\n- WARN on persistence failures\n\n## Acceptance Criteria\n\n- Recent build history available via `/status`\n- Buffer does not grow unbounded\n- Persistence optional but safe\n\n## Dependencies\n\n- `/status` API (remote_compilation_helper-3sy)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:15:56.044171161-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:04:50.793991022-05:00"}
{"id":"remote_compilation_helper-qq0","title":"Fix WorkerPool len() and set_status() methods","status":"closed","priority":2,"issue_type":"bug","owner":"jeff141421@gmail.com","created_at":"2026-01-16T08:58:32.833184859-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T09:07:01.026383152-05:00","closed_at":"2026-01-16T09:07:01.026383152-05:00","close_reason":"Fixed in commit 4321639 - added RwLock for status, AtomicUsize for len(), all_workers() method"}
{"id":"remote_compilation_helper-rwu","title":"Implement rsync transfer pipeline","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:20:07.608638498-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:30:30.514732797-05:00","closed_at":"2026-01-16T03:30:30.514732797-05:00","close_reason":"rsync transfer pipeline already implemented by PearlDune: sync_to_remote, execute_remote, retrieve_artifacts, cleanup_remote - all with zstd compression support. 4 tests pass."}
{"id":"remote_compilation_helper-srd","title":"Add comprehensive environment variable overrides to config","description":"## Overview\n\nAdd comprehensive environment variable overrides for all config settings, with explicit precedence, type coercion, and a `--env-dump`/`--sources` view showing where each value came from.\n\n## Goals\n\n1. Full env var coverage for config values\n2. Consistent naming: `RCH_\u003cSECTION\u003e_\u003cOPTION\u003e`\n3. Strong type parsing with validation and defaults\n4. Source tracking (default/user/project/env)\n\n## Env Var Matrix\n\n### General\n- `RCH_ENABLED` (bool)\n- `RCH_LOG_LEVEL` (string)\n- `RCH_SOCKET_PATH` (path)\n- `RCH_CONFIG_DIR` (path, overrides config directory)\n\n### Compilation\n- `RCH_CONFIDENCE_THRESHOLD` (float)\n- `RCH_MIN_LOCAL_TIME_MS` (u64)\n- `RCH_REMOTE_SPEEDUP_THRESHOLD` (float)\n\n### Transfer\n- `RCH_COMPRESSION` (u32)\n- `RCH_EXCLUDE_PATTERNS` (comma‑separated list)\n\n### Worker Selection\n- `RCH_WORKERS` (comma‑separated allowlist)\n- `RCH_PREFERRED_WORKER` (string)\n\n### Debug/Behavior\n- `RCH_DRY_RUN` (bool)\n- `RCH_BYPASS` (bool)\n- `RCH_LOCAL_ONLY` (bool)\n- `RCH_VERBOSE` (bool)\n\n## Implementation\n\n- Add type‑safe env parsing helpers\n- Track per‑field source in a `ConfigSources` struct\n- Add `rch config show --sources` or `--env-dump`\n\n## Tests\n\n- Unit: parsing helpers for bool/int/float/list\n- Unit: precedence order (env \u003e project \u003e user \u003e defaults)\n- Integration: `rch config show --sources` output contains expected sources\n- E2E: `scripts/e2e_test.sh` sets env overrides, runs `rch config show --sources`, logs source table and verifies each override is respected\n\n## Logging\n\n- E2E logs must print the effective config + source line for each overridden field\n\n## Acceptance Criteria\n\n- All env vars documented and supported\n- Invalid env values are reported with clear errors\n- Source reporting works for all fields\n\n## Dependencies\n\n- Help text updates (remote_compilation_helper-3nq)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:53:35.314349656-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:21:57.584359193-05:00"}
{"id":"remote_compilation_helper-sv9","title":"Implement rch-common shared library","description":"Create shared library with types.rs, protocol.rs, patterns.rs. Include compilation keywords and command classification types.","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:09:01.59083799-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:19:15.955070768-05:00","closed_at":"2026-01-16T03:19:15.955070768-05:00","close_reason":"Implemented types.rs, protocol.rs, patterns.rs with 5-tier classification system. All tests pass."}
{"id":"remote_compilation_helper-t4e","title":"Implement rchd local daemon","description":"Create rchd binary with main.rs, workers.rs, selection.rs. Manage worker pool state and selection algorithm.","status":"closed","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:09:03.785104124-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:19:12.913921133-05:00","closed_at":"2026-01-16T03:19:12.913921133-05:00","close_reason":"Closed"}
{"id":"remote_compilation_helper-u0o","title":"Implement SSH execution for remote commands","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:20:05.887941709-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:30:46.750830312-05:00","closed_at":"2026-01-16T03:30:46.750830312-05:00","close_reason":"SSH execution implemented by PearlDune in rch-common/src/ssh.rs: SshClient, SshPool, CommandResult with connection pooling, health checks, and streaming support. 3 tests pass."}
{"id":"remote_compilation_helper-u0v","title":"Create UI output abstraction layer (foundation for all CLI improvements)","description":"\n\n### Charm-Inspired Enhancements\n\n#### Adaptive Colors (Light/Dark Detection)\nInspired by Lip Gloss `AdaptiveColor`, detect terminal background and provide appropriate colors:\n\n```rust\n// rch/src/ui/adaptive.rs\n\n/// Colors that adapt to light/dark terminal background\n#[derive(Debug, Clone, Copy)]\npub struct AdaptiveColor {\n    pub light: Color,  // For light backgrounds\n    pub dark: Color,   // For dark backgrounds\n}\n\nimpl AdaptiveColor {\n    pub fn resolve(\u0026self, ctx: \u0026OutputContext) -\u003e Color {\n        if ctx.is_light_background() {\n            self.light\n        } else {\n            self.dark\n        }\n    }\n}\n\n/// Standard adaptive palette\npub mod palette {\n    use super::*;\n\n    pub const SUBTLE: AdaptiveColor = AdaptiveColor {\n        light: Color::Ansi256(236),  // Dark gray on light\n        dark: Color::Ansi256(248),   // Light gray on dark\n    };\n\n    pub const HIGHLIGHT: AdaptiveColor = AdaptiveColor {\n        light: Color::Ansi256(205),  // Magenta on light\n        dark: Color::Ansi256(212),   // Pink on dark\n    };\n\n    pub const SUCCESS: AdaptiveColor = AdaptiveColor {\n        light: Color::Ansi256(28),   // Dark green on light\n        dark: Color::Ansi256(82),    // Bright green on dark\n    };\n\n    pub const ERROR: AdaptiveColor = AdaptiveColor {\n        light: Color::Ansi256(124),  // Dark red on light\n        dark: Color::Ansi256(196),   // Bright red on dark\n    };\n\n    pub const WARNING: AdaptiveColor = AdaptiveColor {\n        light: Color::Ansi256(130),  // Dark yellow on light\n        dark: Color::Ansi256(214),   // Bright yellow on dark\n    };\n}\n```\n\n#### Background Detection\n```rust\n/// Detect if terminal has light or dark background\npub fn detect_background() -\u003e Background {\n    // Check COLORFGBG env var (format: \"fg;bg\" e.g., \"15;0\" = white on black)\n    if let Ok(colorfgbg) = std::env::var(\"COLORFGBG\") {\n        if let Some(bg) = colorfgbg.split(';').nth(1) {\n            if let Ok(bg_num) = bg.parse::\u003cu8\u003e() {\n                // Standard terminal colors: 0-7 are dark, 8-15 are light\n                return if bg_num \u003c 8 || bg_num == 8 {\n                    Background::Dark\n                } else {\n                    Background::Light\n                };\n            }\n        }\n    }\n\n    // Check terminal-specific env vars\n    if let Ok(theme) = std::env::var(\"TERMINAL_THEME\") {\n        if theme.to_lowercase().contains(\"light\") {\n            return Background::Light;\n        }\n    }\n\n    // macOS Terminal.app\n    if let Ok(bg) = std::env::var(\"TERM_BACKGROUND\") {\n        if bg == \"light\" {\n            return Background::Light;\n        }\n    }\n\n    // Default to dark (most common for developers)\n    Background::Dark\n}\n\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum Background {\n    Light,\n    Dark,\n}\n```\n\n#### Color Level Detection\n```rust\n/// Detect color support level\npub fn detect_color_level() -\u003e ColorLevel {\n    // Check COLORTERM for true color\n    if let Ok(colorterm) = std::env::var(\"COLORTERM\") {\n        if colorterm == \"truecolor\" || colorterm == \"24bit\" {\n            return ColorLevel::TrueColor;\n        }\n    }\n\n    // Check TERM for 256 color\n    if let Ok(term) = std::env::var(\"TERM\") {\n        if term.contains(\"256color\") {\n            return ColorLevel::Ansi256;\n        }\n        if term == \"dumb\" {\n            return ColorLevel::None;\n        }\n    }\n\n    // Check Windows Terminal (supports true color)\n    if std::env::var(\"WT_SESSION\").is_ok() {\n        return ColorLevel::TrueColor;\n    }\n\n    // Default to 16 colors for safety\n    ColorLevel::Ansi16\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\npub enum ColorLevel {\n    None,       // No color support\n    Ansi16,     // 16 colors (basic ANSI)\n    Ansi256,    // 256 colors\n    TrueColor,  // 24-bit RGB\n}\n\nimpl ColorLevel {\n    pub fn supports_256(\u0026self) -\u003e bool {\n        *self \u003e= ColorLevel::Ansi256\n    }\n\n    pub fn supports_true_color(\u0026self) -\u003e bool {\n        *self == ColorLevel::TrueColor\n    }\n}\n```\n\n#### Extended Terminal Capabilities\n```rust\npub struct TerminalCaps {\n    pub width: u16,\n    pub height: u16,\n    pub color_level: ColorLevel,\n    pub supports_unicode: bool,\n    pub supports_hyperlinks: bool,\n    pub background: Background,\n}\n\nimpl TerminalCaps {\n    pub fn detect() -\u003e Self {\n        Self {\n            width: terminal_size::terminal_size()\n                .map(|(w, _)| w.0)\n                .unwrap_or(80),\n            height: terminal_size::terminal_size()\n                .map(|(_, h)| h.0)\n                .unwrap_or(24),\n            color_level: detect_color_level(),\n            supports_unicode: detect_unicode_support(),\n            supports_hyperlinks: detect_hyperlink_support(),\n            background: detect_background(),\n        }\n    }\n}\n```\n\n#### Updated OutputContext\n```rust\npub struct OutputContext {\n    mode: OutputMode,\n    verbosity: Verbosity,\n    caps: TerminalCaps,      // Consolidated capabilities\n    stdout: OutputWriter,\n    stderr: OutputWriter,\n}\n\nimpl OutputContext {\n    // Existing methods...\n\n    // New capability queries\n    pub fn is_light_background(\u0026self) -\u003e bool {\n        self.caps.background == Background::Light\n    }\n\n    pub fn color_level(\u0026self) -\u003e ColorLevel {\n        if self.mode == OutputMode::Plain {\n            ColorLevel::None\n        } else {\n            self.caps.color_level\n        }\n    }\n\n    pub fn supports_hyperlinks(\u0026self) -\u003e bool {\n        self.mode == OutputMode::Human \u0026\u0026 self.caps.supports_hyperlinks\n    }\n\n    pub fn supports_unicode(\u0026self) -\u003e bool {\n        self.mode == OutputMode::Human \u0026\u0026 self.caps.supports_unicode\n    }\n\n    /// Get adaptive color resolved for current terminal\n    pub fn resolve_color(\u0026self, adaptive: AdaptiveColor) -\u003e Color {\n        adaptive.resolve(self)\n    }\n}\n```\n\n### Additional Testing for New Capabilities\n\n```rust\n// Unit tests for adaptive colors\n#[test]\nfn test_adaptive_color_resolves_for_dark() {\n    let ctx = OutputContext::test_dark_background();\n    let color = palette::SUCCESS.resolve(\u0026ctx);\n    assert_eq!(color, Color::Ansi256(82)); // Bright green\n}\n\n#[test]\nfn test_adaptive_color_resolves_for_light() {\n    let ctx = OutputContext::test_light_background();\n    let color = palette::SUCCESS.resolve(\u0026ctx);\n    assert_eq!(color, Color::Ansi256(28)); // Dark green\n}\n\n#[test]\nfn test_color_level_detection() {\n    std::env::set_var(\"COLORTERM\", \"truecolor\");\n    assert_eq!(detect_color_level(), ColorLevel::TrueColor);\n\n    std::env::remove_var(\"COLORTERM\");\n    std::env::set_var(\"TERM\", \"xterm-256color\");\n    assert_eq!(detect_color_level(), ColorLevel::Ansi256);\n}\n```\n\n### E2E Test Additions\n```bash\n# Test adaptive colors work in different environments\ntest_adaptive_colors() {\n    log \"INFO\" \"ADAPTIVE\" \"Testing adaptive color detection...\"\n\n    # Test dark background (default)\n    local output\n    output=$(\"$RCH\" status 2\u003e\u00261)\n    log \"INFO\" \"ADAPTIVE\" \"Dark background output OK\"\n\n    # Test with COLORFGBG for light background\n    COLORFGBG=\"0;15\" output=$(\"$RCH\" status 2\u003e\u00261)\n    log \"INFO\" \"ADAPTIVE\" \"Light background output OK\"\n}\n```","status":"closed","priority":1,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:55:58.445816787-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T12:52:37.38543276-05:00","closed_at":"2026-01-16T12:52:37.38543276-05:00","close_reason":"Implemented adaptive color system with Background enum, ColorLevel enum, AdaptiveColor struct, detection functions (detect_background, detect_color_level, detect_hyperlink_support), palette constants, and integrated into OutputContext. All 92 tests pass."}
{"id":"remote_compilation_helper-upg","title":"Add architecture documentation for 5-tier classifier","description":"## Overview\n\nAdd architecture documentation for the 5‑tier classifier, including design rationale, performance considerations, and examples of false positive/negative handling.\n\n## Contents\n\n- Tier 0‑4 descriptions\n- SIMD keyword filter rationale\n- Negative pattern list and why\n- Examples + edge cases (pipes, redirects, subshells)\n- Performance budget + benchmarks\n\n## Deliverables\n\n- `docs/classifier_architecture.md` with diagrams + examples\n\n## Tests\n\n- Doc check: ensure examples match unit tests\n- E2E: `scripts/e2e_test.sh` logs classifier decisions for a sample matrix of commands and asserts expected outcomes\n\n## Logging\n\n- E2E should log each command + expected classification result\n\n## Acceptance Criteria\n\n- Document fully describes classifier design\n- Examples align with current code\n\n## Integration Tests\n\n- Validate that the documented command matrix matches the classifier’s runtime output (via a small test harness).\n","status":"open","priority":3,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:54:56.604106736-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.736273558-05:00"}
{"id":"remote_compilation_helper-v7u","title":"Implement Unix socket API for hook-daemon communication","status":"closed","priority":1,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T03:20:10.927804477-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T03:27:18.781854725-05:00","closed_at":"2026-01-16T03:27:18.781854725-05:00","close_reason":"Implemented Unix socket API: created api.rs for daemon socket server, updated main.rs, added daemon client to hook.rs. All 35 tests pass, clippy clean."}
{"id":"remote_compilation_helper-wea","title":"Implement rch status CLI command with formatted output","description":"## Overview\n\nImplement the `rch status` CLI command with rich, human‑friendly output that consumes the daemon `/status` API. Provide a JSON output mode and degrade gracefully when daemon is down.\n\n## Goals\n\n1. `rch status` shows daemon summary + worker summary\n2. `rch status --workers` shows full worker table\n3. `rch status --jobs` shows recent build history\n4. `rch status --json` passes through the JSON envelope\n5. Clear guidance when daemon is unavailable\n\n## Output Requirements\n\n- Table layout with columns: worker, status, slots, speed, last check, circuit\n- Recent builds list with durations and exit codes\n- Issue list derived from status API `issues`\n\n## Implementation\n\n1. Add CLI command handler in `rch/src/commands.rs`\n2. Call `/status` endpoint on daemon socket\n3. Parse response into typed struct\n4. Render output with style helpers (status indicators, optional boxes)\n\n## Tests\n\n- Unit: rendering of worker table (plain + unicode)\n- Unit: JSON envelope generation\n- Integration: fake `/status` response parsing\n- E2E: `rch status` prints expected sections\n\n## Logging\n\n- On error, show actionable steps (start daemon, check socket path)\n\n## Acceptance Criteria\n\n- Clean, readable output in TTY and non‑TTY\n- JSON output valid and complete\n- Works when daemon is down (explicit error + remediation)\n\n## Dependencies\n\n- `/status` API (remote_compilation_helper-3sy)\n- Build history (remote_compilation_helper-qgs)\n- UI output abstraction + status indicators (remote_compilation_helper-u0v, remote_compilation_helper-cmj)\n\n","status":"open","priority":2,"issue_type":"task","owner":"jeff141421@gmail.com","created_at":"2026-01-16T12:17:18.57850862-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:05:04.578847245-05:00"}
{"id":"remote_compilation_helper-x8d","title":"Add 'rch doctor' diagnostic command","description":"## Overview\n\nAdd `rch doctor` to run comprehensive diagnostics and optionally auto-fix common issues. Extend the command to optionally install missing prerequisites (rsync, zstd, rustup) with explicit consent, aligning with the \"ultra automated\" goal.\n\n## Command Signature\n\n```\nrch doctor [OPTIONS]\n\nOPTIONS:\n  --fix            Attempt to fix safe issues\n  --install-deps   Allow installing missing local deps (requires confirmation)\n  --json           JSON output\n  -v, --verbose    Detailed output\n```\n\n## Diagnostic Checks\n\n1. Prerequisites\n   - rsync, zstd, ssh, rustup\n2. Configuration\n   - config.toml, workers.toml validity\n3. SSH Keys\n   - identity files exist + permissions\n4. Daemon\n   - socket exists + responds\n5. Workers\n   - connectivity, latency, required tools present\n6. Hooks\n   - Claude Code + Gemini CLI hook presence\n\n## Auto-Fix Rules\n\n- Safe fixes without prompting:\n  - create config dir\n  - fix key permissions (chmod 600)\n  - restart daemon (if already configured)\n\n- With `--install-deps` and confirmation:\n  - Install rsync/zstd via OS package manager\n  - Install rustup if missing\n\n## Output\n\n- Human summary with pass/warn/fail counts\n- JSON summary with per-check details and remediation hints\n\n## Tests\n\n- Unit: each check and fix path\n- Integration: mock SSH + missing dependency scenarios\n- E2E: doctor command with mock mode\n\n## Acceptance Criteria\n\n- Clear output for every failure mode\n- `--fix` only performs safe, idempotent fixes\n- `--install-deps` installs missing prerequisites with confirmation\n- JSON output includes error codes + suggestions\n\n## Dependencies\n\n- Colors + status indicators (remote_compilation_helper-nbo, remote_compilation_helper-cmj)\n- Agent detection (remote_compilation_helper-xi5)\n\n## Logging\n\n- E2E logs should include per‑check results and summary counts (pass/warn/fail).\n","status":"open","priority":3,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T11:37:16.226548289-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:35:12.77456712-05:00","dependencies":[{"issue_id":"remote_compilation_helper-x8d","depends_on_id":"remote_compilation_helper-nbo","type":"blocks","created_at":"2026-01-16T12:02:12.06551255-05:00","created_by":"Dicklesworthstone"},{"issue_id":"remote_compilation_helper-x8d","depends_on_id":"remote_compilation_helper-cmj","type":"blocks","created_at":"2026-01-16T12:02:12.178771436-05:00","created_by":"Dicklesworthstone"}]}
{"id":"remote_compilation_helper-xi5","title":"Epic: Agent Detection and Auto-Configuration","description":"## Overview\n\nImplement automatic detection of installed AI coding agents and idempotent hook configuration for each supported agent. This should be safe to run repeatedly, never clobber user settings, create backups before modifications, and produce a clear status report.\n\nThis bead uses documented config locations and hook formats for each agent. Where hook APIs are not documented, the system provides detection-only with manual guidance.\n\n## Supported Agents\n\n| Agent | Config Location | Hook Support | Detection | Version Command |\n|-------|----------------|--------------|-----------|-----------------|\n| Claude Code | ~/.config/claude-code | PreToolUse (JSON) | ✓ Full | `claude --version` |\n| Gemini CLI | ~/.gemini | pre_tool_use (JSON) | ✓ Full | `gemini --version` |\n| Codex CLI | ~/.codex | Hooks (TOML) | ✓ Full | `codex --version` |\n| Cursor | ~/.cursor | Unknown | Detection only | Settings UI |\n| Continue.dev | ~/.continue | config.json | ✓ Partial | N/A |\n| Windsurf | ~/.codeium/windsurf | Unknown | Detection only | N/A |\n| Aider | ~/.aider | None | Detection only | `aider --version` |\n| Cline | ~/.cline | Unknown | Detection only | N/A |\n\n## Goals\n\n1. Detect installed agents and their versions\n2. Report current hook status for each agent\n3. Install hooks safely (idempotent, backup, atomic)\n4. Uninstall hooks cleanly (remove only RCH entries)\n5. Support JSON output for scripting\n6. Provide manual guidance for unsupported agents\n7. Environment variable overrides for config paths\n\n## CLI Interface\n\n```\n# Status and detection\nrch agents                     # Show all detected agents with status\nrch agents detect              # Explicit detection scan\nrch agents --json              # JSON output for scripting\n\n# Hook management\nrch agents install             # Install hooks for all supported agents\nrch agents install --agent claude    # Install for specific agent\nrch agents install --all       # Install for all detected agents\nrch agents uninstall           # Remove RCH hooks from all agents\nrch agents uninstall --agent claude  # Remove from specific agent\n\n# Verification\nrch agents verify              # Verify hooks are working\nrch agents verify --agent claude\n```\n\n## Data Model\n\n```rust\n// rch/src/agents/mod.rs\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentRegistry {\n    pub agents: Vec\u003cAgentConfig\u003e,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AgentConfig {\n    /// Internal identifier\n    pub id: \u0026'static str,\n    /// Display name\n    pub display_name: \u0026'static str,\n    /// Environment variable to override config dir\n    pub config_dir_env: Option\u003c\u0026'static str\u003e,\n    /// Default config directory (with ~ expansion)\n    pub default_config_dir: \u0026'static str,\n    /// Config file name\n    pub config_file: \u0026'static str,\n    /// Command to get version (None if no CLI)\n    pub version_command: Option\u003c\u0026'static str\u003e,\n    /// Hook support level\n    pub hook_support: HookSupport,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum HookSupport {\n    /// Full hook support with known format\n    Full { format: HookFormat },\n    /// Partial support (may need manual steps)\n    Partial { format: HookFormat, notes: \u0026'static str },\n    /// Detection only, no hook installation\n    DetectionOnly { reason: \u0026'static str },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum HookFormat {\n    /// Claude Code PreToolUse hooks\n    ClaudeCode,\n    /// Gemini CLI pre_tool_use hooks\n    GeminiCli,\n    /// Codex CLI hooks in TOML\n    CodexCli,\n    /// Continue.dev config.json\n    ContinueDev,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DetectedAgent {\n    pub config: AgentConfig,\n    pub detected: bool,\n    pub version: Option\u003cString\u003e,\n    pub config_path: Option\u003cPathBuf\u003e,\n    pub hook_status: HookStatus,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum HookStatus {\n    /// Hook is installed and active\n    Active,\n    /// Agent detected, hook can be installed\n    Ready,\n    /// Hook installation not supported\n    NotSupported,\n    /// Hook exists but may be outdated\n    NeedsUpdate,\n    /// Agent not detected\n    NotDetected,\n}\n```\n\n## Agent Registry\n\n```rust\nimpl AgentRegistry {\n    pub fn new() -\u003e Self {\n        Self {\n            agents: vec![\n                AgentConfig {\n                    id: \"claude_code\",\n                    display_name: \"Claude Code\",\n                    config_dir_env: Some(\"CLAUDE_CONFIG_DIR\"),\n                    default_config_dir: \"~/.config/claude-code\",\n                    config_file: \"settings.json\",\n                    version_command: Some(\"claude --version\"),\n                    hook_support: HookSupport::Full {\n                        format: HookFormat::ClaudeCode,\n                    },\n                },\n                AgentConfig {\n                    id: \"gemini_cli\",\n                    display_name: \"Gemini CLI\",\n                    config_dir_env: Some(\"GEMINI_CONFIG_DIR\"),\n                    default_config_dir: \"~/.gemini\",\n                    config_file: \"settings.json\",\n                    version_command: Some(\"gemini --version\"),\n                    hook_support: HookSupport::Full {\n                        format: HookFormat::GeminiCli,\n                    },\n                },\n                AgentConfig {\n                    id: \"codex_cli\",\n                    display_name: \"Codex CLI\",\n                    config_dir_env: Some(\"CODEX_CONFIG_DIR\"),\n                    default_config_dir: \"~/.codex\",\n                    config_file: \"config.toml\",\n                    version_command: Some(\"codex --version\"),\n                    hook_support: HookSupport::Full {\n                        format: HookFormat::CodexCli,\n                    },\n                },\n                AgentConfig {\n                    id: \"continue_dev\",\n                    display_name: \"Continue.dev\",\n                    config_dir_env: None,\n                    default_config_dir: \"~/.continue\",\n                    config_file: \"config.json\",\n                    version_command: None,\n                    hook_support: HookSupport::Partial {\n                        format: HookFormat::ContinueDev,\n                        notes: \"Requires IDE restart after hook installation\",\n                    },\n                },\n                AgentConfig {\n                    id: \"cursor\",\n                    display_name: \"Cursor\",\n                    config_dir_env: None,\n                    default_config_dir: \"~/.cursor\",\n                    config_file: \"settings.json\",\n                    version_command: None,\n                    hook_support: HookSupport::DetectionOnly {\n                        reason: \"Hook API not publicly documented\",\n                    },\n                },\n                AgentConfig {\n                    id: \"windsurf\",\n                    display_name: \"Windsurf\",\n                    config_dir_env: None,\n                    default_config_dir: \"~/.codeium/windsurf\",\n                    config_file: \"settings.json\",\n                    version_command: None,\n                    hook_support: HookSupport::DetectionOnly {\n                        reason: \"Hook API not publicly documented\",\n                    },\n                },\n                AgentConfig {\n                    id: \"aider\",\n                    display_name: \"Aider\",\n                    config_dir_env: Some(\"AIDER_CONFIG_DIR\"),\n                    default_config_dir: \"~/.aider\",\n                    config_file: \".aider.conf.yml\",\n                    version_command: Some(\"aider --version\"),\n                    hook_support: HookSupport::DetectionOnly {\n                        reason: \"Aider does not support pre-execution hooks\",\n                    },\n                },\n                AgentConfig {\n                    id: \"cline\",\n                    display_name: \"Cline\",\n                    config_dir_env: None,\n                    default_config_dir: \"~/.cline\",\n                    config_file: \"settings.json\",\n                    version_command: None,\n                    hook_support: HookSupport::DetectionOnly {\n                        reason: \"Hook API not publicly documented\",\n                    },\n                },\n            ],\n        }\n    }\n}\n```\n\n## Hook Installation\n\n```rust\n// rch/src/agents/hooks.rs\n\npub struct HookInstaller {\n    rch_binary_path: PathBuf,\n}\n\nimpl HookInstaller {\n    /// Install hook for a specific agent\n    pub fn install(\u0026self, agent: \u0026DetectedAgent) -\u003e Result\u003cInstallResult\u003e {\n        match \u0026agent.config.hook_support {\n            HookSupport::Full { format } | HookSupport::Partial { format, .. } =\u003e {\n                self.install_hook(agent, format)\n            }\n            HookSupport::DetectionOnly { reason } =\u003e {\n                Ok(InstallResult::NotSupported(reason.to_string()))\n            }\n        }\n    }\n\n    fn install_hook(\u0026self, agent: \u0026DetectedAgent, format: \u0026HookFormat) -\u003e Result\u003cInstallResult\u003e {\n        let config_path = agent.config_path.as_ref()\n            .ok_or_else(|| anyhow!(\"Config path not found\"))?;\n\n        // 1. Read existing config\n        let content = std::fs::read_to_string(config_path)?;\n\n        // 2. Check if hook already exists\n        if self.hook_exists(\u0026content, format)? {\n            return Ok(InstallResult::AlreadyInstalled);\n        }\n\n        // 3. Create timestamped backup\n        let backup_path = self.create_backup(config_path)?;\n\n        // 4. Add hook to config\n        let updated = self.add_hook(\u0026content, format)?;\n\n        // 5. Atomic write\n        let temp_path = config_path.with_extension(\"tmp\");\n        std::fs::write(\u0026temp_path, \u0026updated)?;\n        std::fs::rename(\u0026temp_path, config_path)?;\n\n        Ok(InstallResult::Installed { backup_path })\n    }\n\n    fn hook_exists(\u0026self, content: \u0026str, format: \u0026HookFormat) -\u003e Result\u003cbool\u003e {\n        match format {\n            HookFormat::ClaudeCode =\u003e {\n                let config: serde_json::Value = serde_json::from_str(content)?;\n                Ok(config.pointer(\"/hooks/PreToolUse\")\n                    .and_then(|h| h.as_array())\n                    .map(|hooks| hooks.iter().any(|h|\n                        h.get(\"command\")\n                            .and_then(|c| c.as_str())\n                            .map(|c| c.contains(\"rch\"))\n                            .unwrap_or(false)\n                    ))\n                    .unwrap_or(false))\n            }\n            // Similar for other formats...\n            _ =\u003e Ok(false)\n        }\n    }\n}\n\n#[derive(Debug)]\npub enum InstallResult {\n    Installed { backup_path: PathBuf },\n    AlreadyInstalled,\n    Updated { backup_path: PathBuf },\n    NotSupported(String),\n}\n```\n\n## Output Examples\n\n### Human Output\n```\nAI Coding Agent Status\n══════════════════════\n\nAgent           Status       Hook        Version\n────────────────────────────────────────────────────\nClaude Code     ✓ Detected   ✓ Active    1.0.34\nGemini CLI      ✓ Detected   ○ Ready     2.1.0\nCodex CLI       ✓ Detected   ✓ Active    0.9.2\nContinue.dev    ✓ Detected   ○ Ready     -\nCursor          ✓ Detected   ⊘ Manual    -\nWindsurf        ○ Not found  -           -\nAider           ✓ Detected   ⊘ N/A       0.50.1\nCline           ○ Not found  -           -\n\nLegend: ✓ Active  ○ Ready  ⊘ Manual/N/A  - Not applicable\n\nTip: Run 'rch agents install' to install hooks for all ready agents.\n```\n\n### JSON Output\n```json\n{\n  \"agents\": [\n    {\n      \"id\": \"claude_code\",\n      \"display_name\": \"Claude Code\",\n      \"detected\": true,\n      \"version\": \"1.0.34\",\n      \"config_path\": \"/home/user/.config/claude-code/settings.json\",\n      \"hook_status\": \"active\",\n      \"hook_supported\": true\n    },\n    {\n      \"id\": \"cursor\",\n      \"detected\": true,\n      \"version\": null,\n      \"config_path\": \"/home/user/.cursor/settings.json\",\n      \"hook_status\": \"not_supported\",\n      \"hook_supported\": false,\n      \"manual_instructions\": \"Hook API not publicly documented. See docs for manual setup.\"\n    }\n  ],\n  \"summary\": {\n    \"total_detected\": 5,\n    \"hooks_active\": 2,\n    \"hooks_ready\": 2,\n    \"manual_required\": 1\n  }\n}\n```\n\n## Implementation Files\n\n```\nrch/src/\n├── agents/\n│   ├── mod.rs           # Public API, AgentRegistry\n│   ├── detect.rs        # Detection logic\n│   ├── hooks.rs         # Hook installation/uninstallation\n│   ├── formats/\n│   │   ├── mod.rs\n│   │   ├── claude.rs    # Claude Code hook format\n│   │   ├── gemini.rs    # Gemini CLI hook format\n│   │   ├── codex.rs     # Codex CLI hook format (TOML)\n│   │   └── continue.rs  # Continue.dev format\n│   └── verify.rs        # Hook verification\n├── commands/\n│   └── agents.rs        # CLI command\n```\n\n## Testing Requirements\n\n### Unit Tests (rch/src/agents/tests/)\n\n**detect_test.rs**\n```rust\n#[test]\nfn test_detect_claude_code() {\n    let tmp = TempDir::new().unwrap();\n    let config_dir = tmp.path().join(\".config/claude-code\");\n    std::fs::create_dir_all(\u0026config_dir).unwrap();\n    std::fs::write(config_dir.join(\"settings.json\"), \"{}\").unwrap();\n\n    let registry = AgentRegistry::new();\n    let result = registry.detect_with_base(tmp.path());\n\n    let claude = result.iter().find(|a| a.config.id == \"claude_code\").unwrap();\n    assert!(claude.detected);\n}\n\n#[test]\nfn test_detect_respects_env_override() {\n    let tmp = TempDir::new().unwrap();\n    let custom_dir = tmp.path().join(\"custom-claude\");\n    std::fs::create_dir_all(\u0026custom_dir).unwrap();\n    std::fs::write(custom_dir.join(\"settings.json\"), \"{}\").unwrap();\n\n    std::env::set_var(\"CLAUDE_CONFIG_DIR\", \u0026custom_dir);\n    let registry = AgentRegistry::new();\n    let result = registry.detect();\n\n    let claude = result.iter().find(|a| a.config.id == \"claude_code\").unwrap();\n    assert_eq!(claude.config_path, Some(custom_dir.join(\"settings.json\")));\n}\n```\n\n**hooks_test.rs**\n```rust\n#[test]\nfn test_hook_installation_idempotent() {\n    let tmp = TempDir::new().unwrap();\n    let config_path = tmp.path().join(\"settings.json\");\n    std::fs::write(\u0026config_path, r#\"{\"hooks\": {}}\"#).unwrap();\n\n    let installer = HookInstaller::new(\"/usr/local/bin/rch\");\n\n    // First install\n    let result1 = installer.install_claude_hook(\u0026config_path).unwrap();\n    assert!(matches!(result1, InstallResult::Installed { .. }));\n\n    // Second install (should be idempotent)\n    let result2 = installer.install_claude_hook(\u0026config_path).unwrap();\n    assert!(matches!(result2, InstallResult::AlreadyInstalled));\n}\n\n#[test]\nfn test_hook_creates_backup() {\n    let tmp = TempDir::new().unwrap();\n    let config_path = tmp.path().join(\"settings.json\");\n    std::fs::write(\u0026config_path, r#\"{\"existing\": \"config\"}\"#).unwrap();\n\n    let installer = HookInstaller::new(\"/usr/local/bin/rch\");\n    let result = installer.install_claude_hook(\u0026config_path).unwrap();\n\n    if let InstallResult::Installed { backup_path } = result {\n        assert!(backup_path.exists());\n        let backup_content = std::fs::read_to_string(backup_path).unwrap();\n        assert!(backup_content.contains(\"existing\"));\n    } else {\n        panic!(\"Expected Installed result\");\n    }\n}\n\n#[test]\nfn test_uninstall_removes_only_rch_hooks() {\n    let tmp = TempDir::new().unwrap();\n    let config_path = tmp.path().join(\"settings.json\");\n    std::fs::write(\u0026config_path, r#\"{\n        \"hooks\": {\n            \"PreToolUse\": [\n                {\"matcher\": \"Bash\", \"command\": \"/usr/local/bin/rch hook\"},\n                {\"matcher\": \"Write\", \"command\": \"/other/tool\"}\n            ]\n        }\n    }\"#).unwrap();\n\n    let installer = HookInstaller::new(\"/usr/local/bin/rch\");\n    installer.uninstall_claude_hook(\u0026config_path).unwrap();\n\n    let content = std::fs::read_to_string(\u0026config_path).unwrap();\n    assert!(!content.contains(\"rch hook\"));\n    assert!(content.contains(\"/other/tool\"));\n}\n```\n\n### Integration Tests (rch/tests/agents_integration.rs)\n\n```rust\n#[test]\nfn test_agents_command_output() {\n    let tmp = TempDir::new().unwrap();\n    setup_mock_agents(\u0026tmp);\n\n    Command::cargo_bin(\"rch\")\n        .unwrap()\n        .env(\"HOME\", tmp.path())\n        .arg(\"agents\")\n        .assert()\n        .success()\n        .stdout(predicate::str::contains(\"Claude Code\"))\n        .stdout(predicate::str::contains(\"Detected\"));\n}\n\n#[test]\nfn test_agents_json_output() {\n    let tmp = TempDir::new().unwrap();\n    setup_mock_agents(\u0026tmp);\n\n    let output = Command::cargo_bin(\"rch\")\n        .unwrap()\n        .env(\"HOME\", tmp.path())\n        .args([\"agents\", \"--json\"])\n        .output()\n        .unwrap();\n\n    let json: serde_json::Value = serde_json::from_slice(\u0026output.stdout).unwrap();\n    assert!(json.get(\"agents\").is_some());\n    assert!(json.get(\"summary\").is_some());\n}\n\n#[test]\nfn test_agents_install_all() {\n    let tmp = TempDir::new().unwrap();\n    setup_mock_agents(\u0026tmp);\n\n    Command::cargo_bin(\"rch\")\n        .unwrap()\n        .env(\"HOME\", tmp.path())\n        .args([\"agents\", \"install\", \"--all\"])\n        .assert()\n        .success();\n\n    // Verify hooks were installed\n    let claude_config = tmp.path().join(\".config/claude-code/settings.json\");\n    let content = std::fs::read_to_string(claude_config).unwrap();\n    assert!(content.contains(\"rch hook\"));\n}\n```\n\n### E2E Test Script (scripts/e2e_agents_test.sh)\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nlog() { echo \"[$(date -Iseconds)] $*\" \u003e\u00262; }\npass() { log \"✓ PASS: $*\"; }\nfail() { log \"✗ FAIL: $*\"; exit 1; }\n\nTEST_DIR=$(mktemp -d)\ntrap 'rm -rf \"$TEST_DIR\"' EXIT\nexport HOME=\"$TEST_DIR\"\n\n# Setup mock agent configs\nsetup_mock_agents() {\n    mkdir -p \"$HOME/.config/claude-code\"\n    echo '{\"hooks\":{}}' \u003e \"$HOME/.config/claude-code/settings.json\"\n\n    mkdir -p \"$HOME/.gemini\"\n    echo '{}' \u003e \"$HOME/.gemini/settings.json\"\n\n    mkdir -p \"$HOME/.codex\"\n    echo '' \u003e \"$HOME/.codex/config.toml\"\n}\n\nsetup_mock_agents\n\n# Test 1: Detection finds agents\nlog \"Test 1: Agent detection\"\nOUTPUT=$(\"$RCH\" agents --json)\necho \"$OUTPUT\" | jq -e '.agents | length \u003e 0' \u003e /dev/null || fail \"Should detect agents\"\npass \"Agent detection\"\n\n# Test 2: Install hooks\nlog \"Test 2: Hook installation\"\n\"$RCH\" agents install --all --yes 2\u003e\u00261\ngrep -q \"rch hook\" \"$HOME/.config/claude-code/settings.json\" || fail \"Hook not installed\"\npass \"Hook installation\"\n\n# Test 3: Idempotent install\nlog \"Test 3: Idempotent install\"\n\"$RCH\" agents install --all --yes 2\u003e\u00261 | grep -q \"Already installed\" || fail \"Should report already installed\"\npass \"Idempotent install\"\n\n# Test 4: Backup created\nlog \"Test 4: Backup creation\"\nls \"$HOME/.config/claude-code/\"*.bak \u003e/dev/null 2\u003e\u00261 || fail \"Backup not created\"\npass \"Backup creation\"\n\n# Test 5: Uninstall\nlog \"Test 5: Hook uninstall\"\n\"$RCH\" agents uninstall --all --yes 2\u003e\u00261\ngrep -q \"rch hook\" \"$HOME/.config/claude-code/settings.json\" \u0026\u0026 fail \"Hook not removed\"\npass \"Hook uninstall\"\n\nlog \"All agent E2E tests passed!\"\n```\n\n## Logging Requirements\n\n- DEBUG: Config path resolution for each agent\n- DEBUG: Hook existence check results\n- INFO: Agent detection summary\n- INFO: Hook installation/uninstallation results\n- WARN: Agent detected but hook not supported\n- WARN: Config file parse errors (continue with detection)\n- ERROR: Hook installation failures with remediation\n\n## Success Criteria\n\n- [ ] Detects all 8 listed agents when installed\n- [ ] Respects environment variable overrides\n- [ ] Hook installation is fully idempotent\n- [ ] Creates timestamped backups before modifications\n- [ ] Uninstall removes only RCH hooks\n- [ ] JSON output matches schema\n- [ ] Clear guidance for unsupported agents\n- [ ] Unit test coverage \u003e 80%\n- [ ] E2E tests pass\n\n## Dependencies\n\n- remote_compilation_helper-0dl: Uses idempotent primitives\n\n## Blocks\n\n- remote_compilation_helper-3d1: Setup wizard uses agent detection\n","status":"open","priority":2,"issue_type":"feature","owner":"jeff141421@gmail.com","created_at":"2026-01-16T13:52:58.641114657-05:00","created_by":"Dicklesworthstone","updated_at":"2026-01-16T15:27:57.983687695-05:00","dependencies":[{"issue_id":"remote_compilation_helper-xi5","depends_on_id":"remote_compilation_helper-0dl","type":"blocks","created_at":"2026-01-16T15:22:40.046832957-05:00","created_by":"Dicklesworthstone"}]}
